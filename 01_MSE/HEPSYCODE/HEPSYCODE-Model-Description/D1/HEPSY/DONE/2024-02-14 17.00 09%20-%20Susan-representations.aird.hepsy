At the core of the system is a central BehaviorSpecification that interconnects three key components: Stimulus, SUSAN, and Display. The process begins with the Stimulus node, which captures raw image data via its output port “stim_system_out_port.” This data is transmitted to the SUSAN node through the “stim_acq_channel,” a dedicated communication link configured with a specific queue size and rendezvous semantics to ensure synchronized delivery. Within the SUSAN node, the image processing pipeline is decomposed into several sequential processes that collectively implement the algorithm. The first process, “preproc,” receives the raw image data and performs initial conditioning, such as grayscale conversion and noise reduction, and then passes the preprocessed data through the “preproc_susan_channel.” Next, the “nucleus” process analyzes the conditioned image to determine the nucleus of each region by calculating local similarity measures; its output is forwarded via the “nucleus_channel.” Following this, the “masking” process applies a predefined mask to the pixel neighborhood to isolate regions with similar intensity, transmitting its results over the “mask_channel.” Finally, the “edgeDetect” process evaluates the masked output to detect edges and features based on the SUSAN principle, and sends its final processed data through the “edge_channel.” The consolidated output then exits the SUSAN node via the “system_display_out_port” and is conveyed through the “disp_channel” to the Display node’s input port “system_display_in_port,” where the final edge-enhanced image is rendered. Each process and channel is precisely defined with dedicated message payloads and synchronization parameters, ensuring that data integrity, timing, and buffering requirements are rigorously maintained throughout the processing pipeline.