The system is defined by a central BehaviorSpecification that interconnects three key components: Stimulus, Roberts, and Display. The process begins with the Stimulus node, which produces raw image data through its output port named “stim_system_out_port.” This data is transmitted to the Roberts node via the “stim_preproc_channel,” a dedicated communication link configured with a specific queue size and rendezvous semantics to ensure synchronized delivery.

Inside the Roberts node, the image processing pipeline is divided into several sequential and parallel processes. The first process, “preproc,” receives the raw image data from the Stimulus node and performs initial conditioning, such as grayscale conversion and noise reduction, preparing the image for edge detection. The output of the preproc process is then split and concurrently forwarded via two separate channels: “preproc_cross1_channel” and “preproc_cross2_channel.” These channels deliver the conditioned data to two parallel processes, “roberts_cross1” and “roberts_cross2,” respectively, each applying one of the two Roberts convolution kernels to compute diagonal gradient components of the image.

Following the parallel computations, the outputs of “roberts_cross1” and “roberts_cross2” are merged by the “roberts_merge” process via the “cross_merge_channel.” This merge process combines the two gradient maps to produce a final edge magnitude image. The fully processed image is then sent out of the Roberts node through its output port “system_display_out_port” and delivered to the Display node via the “roberts_display_channel.” The Display node, equipped with an input port “system_display_in_port,” renders the final edge-detected image.

Each channel and process in the system is explicitly defined with specific message payloads and synchronization parameters, ensuring that data integrity, timing, and buffering requirements are rigorously maintained across the entire processing pipeline.