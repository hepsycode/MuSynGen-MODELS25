The system is defined by a central BehaviorSpecification that interconnects three key components: Stimulus, RastaPlp, and Display. The operation begins with the Stimulus node, which produces raw audio data through its output port named “stim_system_out_port.” This data is transmitted to the RastaPlp node via the “stim_preproc_channel,” a dedicated communication link configured with a defined queue size and rendezvous semantics to ensure synchronized delivery. Within the RastaPlp node, the processing pipeline is segmented into distinct stages. The first stage is the “preproc” process, which receives the raw audio and performs initial conditioning—such as noise reduction and normalization—delivering its output via the “preproc_rasta_channel.” Next, the “rasta” process applies the Relative Spectral Transform filtering to enhance spectral features under varying noise conditions; its output is forwarded through the “rasta_plp_channel” to the “plp” process. The “plp” process then executes Perceptual Linear Prediction analysis, extracting cepstral coefficients that encapsulate the key auditory features of the speech signal. The processed data is subsequently conveyed through the “plp_postproc_channel” to a merging stage if needed, before being emitted from the RastaPlp node through the “system_display_out_port.” Finally, the data reaches the Display node via the “display_channel,” where it enters through the “system_display_in_port” and is rendered for further analysis or visualization. Each channel and process is explicitly defined with precise message payloads and synchronization parameters, ensuring that data integrity, timing, and buffering constraints are rigorously maintained throughout the entire processing pipeline.