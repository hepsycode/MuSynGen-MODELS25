{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5841d78-9230-49e8-b9fc-ec27e72288af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1af2c39-c132-4c07-8b7d-cc6fc8cb75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 URLs from 'config/BASE_URL.csv'.\n",
      "The folder 'faiss' already exists.\n",
      "Loading existing FAISS index from disk...\n",
      "The graph has been saved as 'graph.png'.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### LangGraph Visualization ###"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "###################################\n",
    "#           LIBRARIES             #\n",
    "###################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import uuid\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import textdistance\n",
    "import httpx\n",
    "from py4j.java_gateway import JavaGateway\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET  # For parsing the Ecore file\n",
    "\n",
    "from codecarbon import EmissionsTracker  # Import CodeCarbon\n",
    "\n",
    "# LangChain and related libraries\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.llms import Ollama\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.tools.base import Tool\n",
    "from typing import Callable\n",
    "\n",
    "from pytextdist.edit_distance import levenshtein_distance, levenshtein_similarity\n",
    "from pytextdist.vector_similarity import cosine_similarity\n",
    "\n",
    "###################################\n",
    "#         CONFIGURATION           #\n",
    "###################################\n",
    "\n",
    "# Configuration file paths (llm_config_anthropic, llm_config_google, llm_config_groq, llm_config_mistral, llm_config_ollama, llm_config_openai)\n",
    "CONFIG_FILE = \"config/llm_config_mistral.json\"\n",
    "MODELS_FILE = \"config/llm_models.json\"\n",
    "CONFIG_RAG_FILE = \"config/llm_config_openai_rag.json\"\n",
    "CONFIG_RAG_TAVILY_FILE = \"config/secrets-master-llm.json\"\n",
    "VECTOR_DB_TYPE = \"FAISS\" # FAISS, CHROMA\n",
    "CSV_FILE_PATH = \"config/BASE_URL.csv\"\n",
    "LLM_TYPE = 'Others' # 'Others', 'Ollama' (\n",
    "RAG_CHAT = 'LangChain' # 'OpenAI', 'LangChain' (Same Model as the model Generation)\n",
    "\n",
    "# Define an array with all the topics/tools for retrieval\n",
    "vectorstore_topics = [\n",
    "    # \"CAEX/AutomationML\",\n",
    "    \"BPMN Designer\",\n",
    "    \"HEPSYCODE\",\n",
    "    # \"Additional Tool 1\",\n",
    "    # \"Additional Tool 2\",\n",
    "    # Add more topics as needed\n",
    "]\n",
    "\n",
    "###################################\n",
    "#         UTILITY FUNCTIONS       #\n",
    "###################################\n",
    "\n",
    "# Function to load configuration from a JSON file\n",
    "def load_config(config_file):\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file {config_file} not found.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Function to load file content\n",
    "def load_file_content(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to save content to a file\n",
    "def save_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Function to save metadata to a file (in JSON format)\n",
    "def save_metadata(file_path, metadata):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "###################################\n",
    "#         LLM CONFIGURATION       #\n",
    "###################################\n",
    "\n",
    "# Load LLM configuration\n",
    "config = load_config(CONFIG_FILE)\n",
    "models_config = load_config(MODELS_FILE)\n",
    "\n",
    "# Extract LLM parameters from configuration\n",
    "LLM = config.get(\"llm\")\n",
    "if not LLM:\n",
    "    raise ValueError(\"LLM name must be specified in the configuration file.\")\n",
    "\n",
    "PRICE_PER_INPUT_TOKEN = config.get(\"price_per_input_token\")\n",
    "PRICE_PER_OUTPUT_TOKEN = config.get(\"price_per_output_token\")\n",
    "temperature = config.get(\"temperature\")\n",
    "max_retries = config.get(\"max_retries\")\n",
    "api_key = config.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "base_url = config.get(\"base_url\")\n",
    "\n",
    "# Determine LLM type and initialize LLM instance\n",
    "llm_config = models_config.get(LLM, None)\n",
    "if llm_config and LLM_TYPE != 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"max_retries\"] = max_retries\n",
    "    llm_params[\"api_key\"] = api_key\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    # Dynamically initialize the LLM class\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM  # Use LLM name as the model name\n",
    "elif LLM_TYPE == 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM\n",
    "else:\n",
    "    raise ValueError(f\"Model configuration for '{LLM}' not found in {MODELS_FILE}.\")\n",
    "\n",
    "###################################\n",
    "#     FEW-SHOT CONFIGURATION      #\n",
    "###################################\n",
    "\n",
    "# Define file paths for static resources and output directories\n",
    "example_model_path = \"../../01_MSE/HEPSYCODE/HEPSYCODE-Models/D1/HEPSY/2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\"\n",
    "\n",
    "# Path to the metamodel (Ecore file)\n",
    "metamodel_path = \"../../01_MSE/HEPSYCODE/workspace/org.univaq.hepsy/model/hepsy.ecore\"\n",
    "\n",
    "# Path to the model folders (Hepsy file)\n",
    "base_model_path = \"../../01_MSE/HEPSYCODE/HEPSYCODE-Model-Description/D1/HEPSY/\"\n",
    "\n",
    "# Path to the Output Directory\n",
    "base_output_dir = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}\"\n",
    "base_output_json_dir = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "\n",
    "# Profiling Folder\n",
    "PROFILING_FOLDER = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(PROFILING_FOLDER):\n",
    "    os.makedirs(PROFILING_FOLDER)\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"profiling.csv\")\n",
    "\n",
    "# CodeCarbon Folder\n",
    "CODECARBON_FOLDER  = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(CODECARBON_FOLDER ):\n",
    "    os.makedirs(CODECARBON_FOLDER )\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"codecarbon_summary.csv\")\n",
    "\n",
    "# Folder to save evaluation results per file\n",
    "EVALUATION_FOLDER = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(EVALUATION_FOLDER):\n",
    "    os.makedirs(EVALUATION_FOLDER)\n",
    "\n",
    "# Global variable to force context regeneration regardless of REFINED_CONTEXT_PATH presence\n",
    "FORCE_CONTEXT_GEN = False  # Set to True to force context generation even if REFINED_CONTEXT_PATH exists\n",
    "\n",
    "# File path to save the refined context (persistent cache)\n",
    "REFINED_CONTEXT_PATH = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/HEPSYCODE_refined_context.json\"\n",
    "#REFINED_CONTEXT_PATH = \"config/HEPSYCODE_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/CAEX_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/BPMN_Designer_refined_context.json\"\n",
    "\n",
    "###################################\n",
    "#         GLOBAL PROFILING        #\n",
    "###################################\n",
    "\n",
    "# Global list to collect CodeCarbon metrics for each node call (per file)\n",
    "cc_metrics_for_file = []  # This will be reset for each file\n",
    "\n",
    "# Global list for overall CodeCarbon summary per file\n",
    "cc_summary_records = []\n",
    "\n",
    "# Global list to save profiling data\n",
    "profiling_records = []\n",
    "\n",
    "###################################\n",
    "#      TIMING NODE PROFILING      #\n",
    "###################################\n",
    "\n",
    "def timing_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator to profile a node function.\n",
    "    Appends a record with the node name and its execution time (in seconds) to profiling_records.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        profiling_records.append({\"node\": func.__name__, \"execution_time\": elapsed})\n",
    "        print(f\"[Profiling] {func.__name__} took {elapsed:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#    CODECARBON NODE DECORATOR    #\n",
    "###################################\n",
    "\n",
    "# os.environ[\"CODECARBON_API_KEY\"] = \"CODECARBON_API_KEY\"\n",
    "# os.environ[\"CODECARBON_API_URL\"] = \"https://api.codecarbon.io\"\n",
    "# os.environ[\"CODECARBON_EXPERIMENT_ID\"] = \"UUID\"\n",
    "\n",
    "def cc_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator that wraps a node function with CodeCarbon tracking.\n",
    "    It starts a tracker before calling the node and stops it right after.\n",
    "    The resulting metrics are appended to the global cc_metrics_for_file list.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        # Create a CodeCarbon tracker for this node\n",
    "        tracker = EmissionsTracker(\n",
    "            project_name=f\"cc_{func.__name__}\",\n",
    "            measure_power_secs=1,\n",
    "            output_dir=CODECARBON_FOLDER,  # You can adjust output_dir as needed (\".\")\n",
    "            allow_multiple_runs=True\n",
    "            # api_call_interval=4,\n",
    "            # experiment_id=experiment_id,\n",
    "            # save_to_api=True\n",
    "        )\n",
    "        tracker.start()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        emissions = tracker.stop()\n",
    "        # Try to extract detailed metrics if available (from the internal attribute)\n",
    "        if hasattr(tracker, \"_final_emissions_data\"):\n",
    "            metrics = tracker._final_emissions_data\n",
    "        else:\n",
    "            metrics = {\"total_emissions\": emissions}\n",
    "        # Append the node's CodeCarbon metrics to the global list\n",
    "        cc_metrics_for_file.append({\n",
    "            \"node\": func.__name__,\n",
    "            **metrics  # Flatten the metrics dictionary\n",
    "        })\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#       PROFILE & CC DECORATORS   #\n",
    "###################################\n",
    "\n",
    "# (Assuming you already have a @profile_node decorator for timing, as in your code.)\n",
    "# Here we combine both decorators so that each node is profiled for time and CodeCarbon metrics.\n",
    "# The order of decorators means that cc_profile_node will wrap the function first.\n",
    "def profile_node(func):\n",
    "    return timing_profile_node(cc_profile_node(func))\n",
    "\n",
    "###################################\n",
    "#       LOAD URLS FROM CSV        #\n",
    "###################################\n",
    "\n",
    "def load_urls_from_csv(csv_file_path):\n",
    "    urls = []\n",
    "    try:\n",
    "        with open(csv_file_path, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if row:  # Ensure the row is not empty\n",
    "                    urls.append(row[0].strip())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file '{csv_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "    return urls\n",
    "\n",
    "# Load base URLs for the vector database from CSV\n",
    "BASE_URLS = load_urls_from_csv(CSV_FILE_PATH)\n",
    "if not BASE_URLS:\n",
    "    raise ValueError(\"No URLs were loaded from the CSV file.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(BASE_URLS)} URLs from '{CSV_FILE_PATH}'.\")\n",
    "\n",
    "###################################\n",
    "# RAG AGENT SETUP (Chroma/FAISS)  #\n",
    "###################################\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "if VECTOR_DB_TYPE == \"CHROMA\":\n",
    "    # Directory for persisting the Chroma vector store.\n",
    "    CHROMA_PERSIST_DIR = \"chroma_db\"\n",
    "    \n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    # Initialize OpenAIEmbeddings\n",
    "    embd = OpenAIEmbeddings(openai_api_key=api_key_rag)\n",
    "    \n",
    "    # Build or load the Chroma vector store\n",
    "    if os.path.exists(CHROMA_PERSIST_DIR) and os.listdir(CHROMA_PERSIST_DIR):\n",
    "        print(\"Loading existing Chroma vector store from disk...\")\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=CHROMA_PERSIST_DIR,\n",
    "            embedding_function=embd,\n",
    "            collection_name=\"rag-chroma\"\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "    else:\n",
    "        print(\"Creating new Chroma vector store...\")\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=500, chunk_overlap=0\n",
    "        )\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=doc_splits,\n",
    "            collection_name=\"rag-chroma\",\n",
    "            embedding=embd,\n",
    "            persist_directory=CHROMA_PERSIST_DIR\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "elif VECTOR_DB_TYPE == \"FAISS\":\n",
    "\n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"  \n",
    "    HUGGINGFACE_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    \n",
    "    faiss_folder = \"faiss\"\n",
    "    if not os.path.exists(faiss_folder):\n",
    "        os.makedirs(faiss_folder)\n",
    "        print(f\"Folder '{faiss_folder}' created.\")\n",
    "    else:\n",
    "        print(f\"The folder '{faiss_folder}' already exists.\")\n",
    "    \n",
    "    DATABASE_PATH = os.path.join(faiss_folder, \"faiss_index.index\")\n",
    "    METADATA_PATH = os.path.join(faiss_folder, \"metadata.json\")\n",
    "    \n",
    "    embedding = HuggingFaceEmbeddings(model_name=HUGGINGFACE_MODEL_NAME)\n",
    "    \n",
    "    if os.path.exists(DATABASE_PATH):\n",
    "        print(\"Loading existing FAISS index from disk...\")\n",
    "        vectorstore = FAISS.load_local(DATABASE_PATH, embedding, allow_dangerous_deserialization=True)\n",
    "        if os.path.exists(METADATA_PATH):\n",
    "            with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                metadata = json.load(f)\n",
    "    else:\n",
    "        print(\"Creating new FAISS vector store...\")\n",
    "        from langchain_community.document_loaders import WebBaseLoader\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = FAISS.from_documents(doc_splits, embedding)\n",
    "        vectorstore.save_local(DATABASE_PATH)\n",
    "        metadata = [doc.metadata for doc in doc_splits]\n",
    "        with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        \n",
    "    retriever = vectorstore.as_retriever()    \n",
    "\n",
    "###################################\n",
    "#         ROUTER NODE             #\n",
    "###################################\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model for routing the user query\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Route the user query to either a vectorstore or web search.\"\n",
    "    )\n",
    "\n",
    "# Initialize RAG LLM and router\n",
    "LLM_RAG = config_rag.get(\"llm\")\n",
    "LLM_RAG_TEMP = config_rag.get(\"temperature\")\n",
    "\n",
    "if RAG_CHAT == 'OpenAI':\n",
    "    llm_rag = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "elif RAG_CHAT == 'Ollama':\n",
    "    llm_rag = OllamaFunctions(model=LLM) \n",
    "elif RAG_CHAT == 'LangChain':\n",
    "    llm_rag = llm_LangChain\n",
    "\n",
    "structured_llm_router = llm_rag.with_structured_output(RouteQuery)\n",
    "\n",
    "# Join the topics into a single string, separated by commas\n",
    "topics_str = \", \".join(vectorstore_topics)\n",
    "\n",
    "# Create router prompt\n",
    "router_system_prompt = (\n",
    "    \"You are an expert at routing user queries to either a vectorstore or web search. \"\n",
    "    \"The vectorstore contains documents related to {topics_str}.\"\n",
    "    \"Use the vectorstore for questions on these topics; otherwise, use web search.\"\n",
    "    \"Based on the query, respond with a JSON object that contains a key 'datasource'\"\n",
    "    \"whose value is either 'vectorstore' or 'web_search'. Do not include any additional keys or text.\"\n",
    ")\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", router_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "###################################\n",
    "#      RETRIEVAL GRADER NODE      #\n",
    "###################################\n",
    "\n",
    "# Data model for grading document relevance\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates whether the document is relevant ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm_rag.with_structured_output(GradeDocuments)\n",
    "\n",
    "grader_system_prompt = (\n",
    "    \"You are a grader assessing the relevance of a retrieved document to a user query. \"\n",
    "    \"If the document contains keywords or semantic content related to the user query, grade it as relevant. \"\n",
    "    \"Output a binary score 'yes' or 'no'.\"\n",
    ")\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grader_system_prompt),\n",
    "        (\"human\", \"Retrieved document:\\n\\n{document}\\n\\nUser query:\\n{question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "###################################\n",
    "#        GENERATION CHAIN         #\n",
    "###################################\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# Set up in-memory cache to avoid repeating expensive LLM calls.\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "\"\"\"\n",
    "context_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an expert in information retrieval and content synthesis. Your task is to refine and enhance context \"\n",
    "                \"from multiple sources by generating a cohesive, well-structured, and detailed context that combines information \"\n",
    "                \"from various retrieved documents.\\n\\n\"\n",
    "                \"Responsibilities:\\n\"\n",
    "                \"1. Synthesize information from multiple sources into a unified explanation.\\n\"\n",
    "                \"2. Expand on the query with relevant details from the retrieved content.\\n\"\n",
    "                \"3. Format the refined context with clear structure and professional language.\\n\"\n",
    "                \"4. Incorporate metadata for traceability.\\n\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            (\n",
    "                \"Question: {question}\\n\\n\"\n",
    "                \"The following are the retrieved documents and metadata:\\n\\n{context}\\n\\n\"\n",
    "                \"Using this information, generate a refined and comprehensive context.\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Load static content files\n",
    "metamodel_text = load_file_content(metamodel_path)\n",
    "\n",
    "context_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are a domain model expert with deep knowledge of metamodeling and semantic model interpretation.\"\n",
    "                \"Your task is to analyze a given Ecore metamodel and extract a structured and comprehensive domain context.\"\n",
    "                \"This context will be used as background knowledge to guide synthetic model generation.\\n\\n\"\n",
    "                \"Instructions:\\n\"\n",
    "                \"1. Identify and describe the key domain concepts (classes, attributes, references, enumerations).\\n\"\n",
    "                \"2. Explain the relationships and constraints implied by the metamodel structure.\\n\"\n",
    "                \"3. Enrich the context with relevant external domain knowledge.\\n\"\n",
    "                \"4. Structure the output clearly with sections like 'Domain Overview', 'Key Concepts', 'Relationships', 'Behavioral Semantics', and 'External Domain Background'.\\n\"\n",
    "                \"5. When possible, infer the real-world domain (e.g., hardware modeling, system behavior, message passing) and include related terminology.\\n\"\n",
    "                \"6. Use professional and academic language, suitable for expert systems.\\n\"\n",
    "                \"7. Incorporate any relevant metadata such as names, types, multiplicities, and containment relationships.\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            (\n",
    "                \"Here is the Ecore metamodel to analyze:\\n\\n\"\n",
    "                \"{metamodel_text}\\n\\n\"\n",
    "                \"Question: {question}\\n\\n\"\n",
    "                \"The following are the retrieved documents and metadata:\\n\\n{context}\\n\\n\"\n",
    "                \"Using this, generate a refined and detailed context about the domain it represents.\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if RAG_CHAT == 'OpenAI':\n",
    "    llm_for_context = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "elif RAG_CHAT == 'LangChain':\n",
    "    llm_for_context = llm_LangChain\n",
    "    \n",
    "rag_chain = context_prompt_template | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#     HALLUCINATION GRADER        #\n",
    "###################################\n",
    "\n",
    "# Data model for grading hallucination\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer is grounded in facts ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_hallucination = llm_rag.with_structured_output(GradeHallucinations)\n",
    "\n",
    "hallucination_system_prompt = (\n",
    "    \"You are a grader assessing whether the LLM generation is grounded in the retrieved facts. \"\n",
    "    \"Output a binary score 'yes' if the answer is supported by the facts, otherwise 'no'.\"\n",
    ")\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", hallucination_system_prompt),\n",
    "        (\"human\", \"Facts:\\n\\n{documents}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "hallucination_grader = hallucination_prompt | structured_llm_hallucination\n",
    "\n",
    "###################################\n",
    "#         ANSWER GRADER           #\n",
    "###################################\n",
    "\n",
    "\"\"\"\n",
    "# Data model for grading answer relevance\n",
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer addresses the question ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_answer = llm_rag.with_structured_output(GradeAnswer)\n",
    "\n",
    "answer_system_prompt = (\n",
    "    \"You are a grader assessing whether an LLM-generated answer addresses the user query. \"\n",
    "    \"Output a binary score 'yes' if it does, otherwise 'no'.\"\n",
    ")\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_system_prompt),\n",
    "        (\"human\", \"User Query:\\n{question}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "answer_grader = answer_prompt | structured_llm_answer\n",
    "\"\"\"\n",
    "\n",
    "###################################\n",
    "#       QUESTION REWRITER         #\n",
    "###################################\n",
    "\n",
    "rewrite_system_prompt = (\n",
    "    \"You are a question rewriter. Given an input question, produce an improved version optimized for vectorstore retrieval. \"\n",
    "    \"Focus on the underlying semantic intent.\"\n",
    ")\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rewrite_system_prompt),\n",
    "        (\"human\", \"Original question:\\n{question}\\n\\nRewrite the question:\"),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = rewrite_prompt | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#           WEB SEARCH            #\n",
    "###################################\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "config_tavily = load_config(CONFIG_RAG_TAVILY_FILE)\n",
    "os.environ[\"TAVILY_API_KEY\"] = config_tavily.get(\"tavily_api_key\")\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "###################################\n",
    "#       GRAPH STATE DEFINITION    #\n",
    "###################################\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict, total=False): \n",
    "    # Retrieval and model generation branch keys\n",
    "    question: str                         # The user's search question or refined query\n",
    "    generation: str                       # The generated answer or refined query output\n",
    "    documents: List[Any]                  # List of retrieved documents\n",
    "    file_name: str                        # For model generation node\n",
    "    context_llm: str                      # The refined context generated by the LLM\n",
    "    model_status: str                     # Status of the processing model\n",
    "    model_out: str                        # The output model\n",
    "    metadata: Dict[str, Any]              # Additional metadata related to the process\n",
    "    branch: str                           # Indicates the branch: \"retrieve\" or \"web_search\"\n",
    "    evaluation_metrics: Dict[str, float]  # Metrics evaluating the generated results\n",
    "    bert_score: Dict[str, float]          # BERTScore metrics for evaluating document support\n",
    "    web_bert_score: Dict[str, float]      # BERTScore metrics for evaluating web search branch results\n",
    "    skip_router: bool                     # If True, skip the routing and proceed directly to cache_context_node\n",
    "    model_val: bool                       # Flag indicating whether the model should be refined or not\n",
    "    validation_attempts: int              # Number of validation/correction attempts\n",
    "    next_step: str                        # Next transition key for conditional routing\n",
    "    val_cycles: int                     # Number of generation-validation cycles\n",
    "\n",
    "###################################\n",
    "# FUNCTION: GENERATE QUERY FROM METAMODEL #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_from_metamodel(metamodel_path):\n",
    "    \"\"\"\n",
    "    Reads the metamodel (Ecore file), extracts basic information (package name, nsURI, and classifiers),\n",
    "    and constructs a query based solely on the extracted information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(metamodel_path)\n",
    "        root = tree.getroot()\n",
    "        # The root is typically an EPackage with attributes\n",
    "        package_name = root.attrib.get(\"name\", \"UnknownPackage\")\n",
    "        ns_uri = root.attrib.get(\"nsURI\", \"Unknown nsURI\")\n",
    "        # Extract all classifiers (e.g., EClass, EEnum, etc.)\n",
    "        classifiers = []\n",
    "        for classifier in root.findall(\"{http://www.eclipse.org/emf/2002/Ecore}eClassifiers\"):\n",
    "            classifiers.append(classifier.attrib.get(\"name\", \"UnnamedClassifier\"))\n",
    "        classifiers_str = \", \".join(classifiers) if classifiers else \"None\"\n",
    "        # Build a generic query based solely on the metamodel information\n",
    "        query = (\n",
    "            f\"Metamodel Analysis Query:\\n\"\n",
    "            f\"Package Name: {package_name}\\n\"\n",
    "            f\"Namespace URI: {ns_uri}\\n\"\n",
    "            f\"Classifiers: {classifiers_str}\\n\"\n",
    "            \"Based solely on the metamodel information provided above, generate a context for a tool based on this metamodel. \"\n",
    "            \"The context should include the tool's name, which must be directly derived from the package name.\"\n",
    "        )\n",
    "        return query\n",
    "    except Exception as e:\n",
    "        print(\"Error generating query from metamodel:\", e)\n",
    "        return \"Metamodel analysis query could not be generated.\"\n",
    "\n",
    "# The query for generating the context is now created based on the metamodel\n",
    "# question = generate_query_from_metamodel(metamodel_path)\n",
    "# print(question)\n",
    "\n",
    "###################################\n",
    "#        EVALUATION NODES         #\n",
    "###################################\n",
    "\n",
    "# (1) LLM-based Evaluation for RAG output (vectorstore branch)\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RAGEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the facts.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the question.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the context used.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved context.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of the context.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the context.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_rag_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the RAG output (vectorstore branch) based on metrics such as:\n",
    "    Faithfulness, Answer Relevance, Context Precision, Context Accuracy,\n",
    "    Context Recall, and Context F1.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE RAG OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of RAG outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, and Context F1. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer:\\n{generation}\\n\\nContext:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(RAGEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during evaluation of RAG output:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (2) BERTScore Evaluation for RAG output (vectorstore branch)\n",
    "@profile_node\n",
    "def evaluate_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty. Skipping BERTScore evaluation.\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    bert_precision = P[0].item()\n",
    "    bert_recall = R[0].item()\n",
    "    bert_f1 = F1[0].item()\n",
    "    state[\"bert_score\"] = {\"precision\": bert_precision, \"recall\": bert_recall, \"f1\": bert_f1}\n",
    "    print(\"BERTScore metrics:\", state[\"bert_score\"])\n",
    "    return state\n",
    "\n",
    "# (3) LLM-based Evaluation for Web Search output\n",
    "# Here, we introduce an additional metric \"accuracy\" along with the previous ones.\n",
    "class WebEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the web sources.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the query.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the web search results.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved web content.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of relevant web information.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the web search results.\")\n",
    "    accuracy: float = Field(..., description=\"Score (0-1) indicating the overall accuracy of the generated context based on web sources.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_web_search_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the output of the web search branch.\n",
    "    It uses the same metrics as the RAG evaluation plus an extra metric 'accuracy'.\n",
    "    The reference is the concatenated web search source content.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE WEB SEARCH OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of web search outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, Context F1, and Accuracy. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1, accuracy.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer/Context:\\n{generation}\\n\\nWeb Search Sources:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(WebEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Web search evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during web search evaluation:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (4) BERTScore Evaluation for Web Search output\n",
    "@profile_node\n",
    "def evaluate_web_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE WEB BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty for web search. Skipping BERTScore evaluation.\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    web_bert_precision = P[0].item()\n",
    "    web_bert_recall = R[0].item()\n",
    "    web_bert_f1 = F1[0].item()\n",
    "    state[\"web_bert_score\"] = {\"precision\": web_bert_precision, \"recall\": web_bert_recall, \"f1\": web_bert_f1}\n",
    "    print(\"Web BERTScore metrics:\", state[\"web_bert_score\"])\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#        DECIDE TO GENERATE       #\n",
    "###################################\n",
    "\n",
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    print(\"--- DECIDE TO GENERATE ---\")\n",
    "    filtered_documents = state.get(\"documents\", [])\n",
    "    if not filtered_documents:\n",
    "        branch = state.get(\"branch\", \"retrieve\")  # Fallback default to \"retrieve\"\n",
    "        if branch == \"retrieve\":\n",
    "            print(\"--- No relevant documents found in vectorstore; transforming query to improve retrieval ---\")\n",
    "            return \"transform_query\"\n",
    "        else:  # branch == \"web_search\"\n",
    "            print(\"--- No documents found via web search; proceeding with generation using empty context ---\")\n",
    "            return \"generate\"\n",
    "    else:\n",
    "        print(\"--- Relevant documents found, generating answer ---\")\n",
    "        return \"generate\"\n",
    "\n",
    "###################################\n",
    "#        CACHE NODE (LangGraph)   #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def cache_context_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that checks if a refined context is already available.\n",
    "    If present in the state or in the file cache, it uses that value.\n",
    "    Otherwise, it generates the refined context using the rag_chain,\n",
    "    caches it (in state and on disk), and returns the state.\n",
    "    \"\"\"\n",
    "    if \"context_llm\" in state and state[\"context_llm\"]:\n",
    "        print(\"Using refined context already present in state.\")\n",
    "        return state\n",
    "\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        try:\n",
    "            with open(REFINED_CONTEXT_PATH, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            state[\"context_llm\"] = data.get(\"context\", \"\")\n",
    "            print(\"Loaded refined context from file cache (LangGraph node).\")\n",
    "            return state\n",
    "        except Exception as e:\n",
    "            print(\"Error loading refined context from file in cache node:\", e)\n",
    "\n",
    "    print(\"Generating refined context in LangGraph cache node...\")\n",
    "    refined_context = rag_chain.invoke({\"question\": state[\"question\"], \"context\": \"\", \"metamodel_text\": metamodel_text})\n",
    "    state[\"context_llm\"] = refined_context\n",
    "    try:\n",
    "        with open(REFINED_CONTEXT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"context\": refined_context}, f, indent=4, ensure_ascii=False)\n",
    "        print(\"Refined context cached to file from LangGraph node.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error caching refined context to file in cache node:\", e)\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#          GRAPH NODES            #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that generates the query from the metamodel.\n",
    "    If the refined context file exists, skip query generation and mark state to bypass router.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        print(\"Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\")\n",
    "        state[\"skip_router\"] = True  # Flag to skip routing\n",
    "    else:\n",
    "        state[\"skip_router\"] = False  # Flag to skip routing\n",
    "        state[\"question\"] = generate_query_from_metamodel(metamodel_path)\n",
    "        print(\"Generated query from metamodel:\", state[\"question\"])\n",
    "    return state\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# Node: Retrieve documents using the vectorstore\n",
    "@profile_node\n",
    "def retrieve(state: GraphState) -> GraphState:\n",
    "    print(\"--- RETRIEVE ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = retriever.invoke(question_val)\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "# Node: Perform web search (remains separate)\n",
    "@profile_node\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    print(\"--- WEB SEARCH ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    docs = web_search_tool.invoke({\"query\": question_val})\n",
    "\n",
    "    # Combine web search results into a single Document\n",
    "    \"\"\"\n",
    "    web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state\n",
    "    \"\"\"\n",
    "    # Check the type of docs and extract content accordingly.\n",
    "    if isinstance(docs, str):\n",
    "        # If docs is a string, use it directly.\n",
    "        web_results_content = docs\n",
    "    elif isinstance(docs, list):\n",
    "        # If docs is a list, check the type of its elements.\n",
    "        if docs and isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "            web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "        else:\n",
    "            # Assume it's a list of strings.\n",
    "            web_results_content = \"\\n\".join(docs)\n",
    "    else:\n",
    "        # Fallback: convert docs to string.\n",
    "        web_results_content = str(docs)\n",
    "    \n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state    \n",
    "\n",
    "# Merged Node: Generate answer using the RAG chain (used for both branches)\n",
    "def generate(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question_val, \"metamodel_text\": metamodel_text})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Generate answer using web search results\n",
    "@profile_node\n",
    "def generate_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question, \"metamodel_text\": metamodel_text})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Grade documents for relevance\n",
    "@profile_node\n",
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    print(\"--- GRADE DOCUMENTS ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        \"\"\"\n",
    "        score = retrieval_grader.invoke({\"question\": question_val, \"document\": d.page_content})\n",
    "        if score.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Document is relevant ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- Document is not relevant ---\")\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        attempts = 0\n",
    "        max_attempts = 3\n",
    "        score = None\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                print(\"Calling retrieval_grader with input:\", {\"question\": question_val, \"document\": d.page_content})\n",
    "                output = retrieval_grader.invoke({\"question\": question_val, \"document\": d.page_content})\n",
    "                print(\"Raw score output:\", output)\n",
    "                if isinstance(output, dict):\n",
    "                    score = output.get(\"binary_score\")\n",
    "                else:\n",
    "                    print(\"Unexpected output format:\", output)\n",
    "                    score = output.get(\"binary_score\")\n",
    "                break  # Exit loop if the call is successful\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    wait_time = 10  # seconds to wait; adjust if needed\n",
    "                    print(f\"Rate limit exceeded, waiting for {wait_time} seconds before retrying...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    attempts += 1\n",
    "                else:\n",
    "                    raise  # Re-raise the error if it's not a 429\n",
    "            except httpx.ReadTimeout as e:\n",
    "                wait_time = 10  # seconds to wait; adjust if needed\n",
    "                print(f\"Read timeout occurred, waiting for {wait_time} seconds before retrying...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempts += 1\n",
    "        if score is None:\n",
    "            print(\"The retrieval_grader did not return a valid result for this document, skipping it.\")\n",
    "            continue\n",
    "        if score.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Document is relevant ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- Document is not relevant ---\")\n",
    "        \"\"\"\n",
    "        attempts = 0\n",
    "        max_attempts = 3\n",
    "        score = None\n",
    "\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                input_data = {\"question\": question_val, \"document\": d.page_content}\n",
    "                # print(f\"\\n[Grade Attempt] Input:\\n{json.dumps(input_data, indent=2)}\")\n",
    "\n",
    "                raw_output = retrieval_grader.invoke(input_data)\n",
    "                # print(f\"[Grade Output] Raw result:\\n{raw_output}\")\n",
    "\n",
    "                # Check if we received a proper object or dict\n",
    "                if hasattr(raw_output, 'binary_score'):\n",
    "                    binary = raw_output.binary_score.lower()\n",
    "                elif isinstance(raw_output, dict) and \"binary_score\" in raw_output:\n",
    "                    binary = raw_output[\"binary_score\"].lower()\n",
    "                else:\n",
    "                    print(\"Unexpected output format, skipping document.\")\n",
    "                    break  # Skip this doc\n",
    "\n",
    "                if binary == \"yes\":\n",
    "                    print(\"Document is relevant.\")\n",
    "                    filtered_docs.append(d)\n",
    "                else:\n",
    "                    print(\"Document is not relevant.\")\n",
    "\n",
    "                break  # Done with this document\n",
    "\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code in [429, 502, 503]:\n",
    "                    wait_time = 10\n",
    "                    print(f\"HTTP {e.response.status_code} error, retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    attempts += 1\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error {e.response.status_code}: {e}\")\n",
    "                    break  # Exit loop for other HTTP errors\n",
    "            except httpx.ReadTimeout as e:\n",
    "                wait_time = 10\n",
    "                print(f\"Read timeout, waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempts += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error grading document: {e}\")\n",
    "                break  # Don't loop forever on unknown errors\n",
    "\n",
    "    state[\"documents\"] = filtered_docs\n",
    "    return state\n",
    "    \n",
    "\n",
    "# Merged Node: Transform the query (for both branches)\n",
    "@profile_node\n",
    "def transform_query(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question_val})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Node: Transform the query for web search\n",
    "@profile_node\n",
    "def transform_query_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Conditional routing after transformation: based on branch in state\n",
    "\"\"\"\n",
    "def route_after_transform(state: GraphState) -> str:\n",
    "    if state.get(\"branch\") == \"retrieve\":\n",
    "        return \"retrieve\"\n",
    "    elif state.get(\"branch\") == \"web_search\":\n",
    "        return \"web_search\"\n",
    "    return \"retrieve\"\n",
    "\"\"\"\n",
    "\n",
    "# Node: Grade the generation against the documents and question\n",
    "@profile_node\n",
    "def grade_generation_v_documents_and_question(state: GraphState) -> str:\n",
    "    print(\"--- GRADE GENERATION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # Evaluate if the generation is supported by the retrieved documents.\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    if score.binary_score.lower() == \"yes\":\n",
    "        print(\"--- Generation is grounded in documents ---\")\n",
    "        # score_answer = answer_grader.invoke({\"question\": question_val, \"generation\": generation})\n",
    "        # if score_answer.binary_score.lower() == \"yes\":\n",
    "        #     print(\"--- Generation addresses the question ---\")\n",
    "        return \"useful\"\n",
    "        # else:\n",
    "        #     print(\"--- Generation does not address the question ---\")\n",
    "        #     return \"not useful\"\n",
    "    else:\n",
    "        print(\"--- Generation is not supported by documents, retrying ---\")\n",
    "        return \"not useful\"\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# Node: model Generation – generate model and JSON metadata from a single file.\n",
    "# TODO: change this function to model generation and feedback with Eclipse EMF\n",
    "@profile_node\n",
    "def model_generation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node for generating the model and JSON metadata\n",
    "    from a single file using the refined context.\n",
    "    \n",
    "    Expected state:\n",
    "      - \"file_name\": the file to process.\n",
    "      - \"context_llm\": the refined context.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = state[\"file_name\"]\n",
    "    context_llm = state[\"context_llm\"]\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    \n",
    "    output_model_path = os.path.join(base_output_dir, file_name)\n",
    "    metadata_path = os.path.join(base_output_json_dir, file_name)\n",
    "\n",
    "    attempts = state.get(\"validation_attempts\", 0)\n",
    "    \n",
    "    # Skip processing if the output files already exist\n",
    "    if os.path.exists(output_model_path) and os.path.exists(metadata_path) and attempts < 2:\n",
    "        print(f\"Skipping {file_name} as output files already exist.\")\n",
    "        state[\"model_status\"] = \"skipped\"\n",
    "        return state\n",
    "    # else if \n",
    "\n",
    "    # Load the model file description\n",
    "    input_file_path = os.path.join(base_model_path, file_name)\n",
    "    model_description = load_file_content(input_file_path)\n",
    "    \n",
    "    # Load static content files\n",
    "    metamodel_content = load_file_content(metamodel_path)\n",
    "    example_model_content = load_file_content(example_model_path)\n",
    "    \n",
    "    # Define system prompt for model generation\n",
    "    system_prompt = (\n",
    "        \"You are an expert in Model-Driven Engineering and EMF (Eclipse Modeling Framework). \"\n",
    "        \"Your task is to generate a valid model instance that conforms to a given Ecore metamodel. \"\n",
    "        \"You will receive:\\n\"\n",
    "        \"- A context extracted using Retrieval-Augmented Generation (RAG) to provide relevant background information.\\n\\n\"\n",
    "        \"- A metamodel definition (in Ecore format).\\n\"\n",
    "        \"- An example model that demonstrates the structure and syntax of a valid instance.\\n\"\n",
    "        \"- A text-based description of the desired model (in natural language).\\n\"\n",
    "        \"You must return a syntactically correct and complete model file that adheres to the metamodel structure,\"\n",
    "        \"accurately represents the input description, and follows the style of the example provided.\"\n",
    "        #\"The output should be in plain text, without any explanations, comments, or extra formatting.\"\n",
    "        \"**Do not** add comments, backticks (```), or markdown formatting like ```xml. \"\n",
    "        \"The output must be pure XML text, starting directly with the XML declaration `<?xml version=\\\"1.0\\\" ...>` and ending with the last closing tag. \"\n",
    "        \"Do not prepend or append anything outside the model content.\"\n",
    "        \"Only return the model file content.\"\n",
    "    )\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", (\n",
    "                f\"Context:\\n{context_llm}\\n\\n\"\n",
    "                \"This is the metamodel:\\n\\n{metamodel_content}\\n\\n\"\n",
    "                \"(Input example) This is an example model based on the given metamodel:\\n\\n{example_model_content}\\n\\n\"\n",
    "                \"(Input) Generate the model file for the following text description:\\n\\n{model_description}\\n\\n\"\n",
    "                \"Do not add comments or extra quotation marks at the beginning and end of the model file.\"\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Invoke the LLM chain for model generation\n",
    "    start_time_llm = time.time()\n",
    "    response_chain = chat_prompt | llm_LangChain\n",
    "    # print(f\"Final Prompt:{response_chain}\")\n",
    "    result = response_chain.invoke({\n",
    "        \"context\": context_llm,\n",
    "        \"metamodel_content\": metamodel_content,\n",
    "        \"example_model_content\": example_model_content,\n",
    "        \"model_description\": model_description,\n",
    "    })\n",
    "    print(f\"Final Results:{result}\")\n",
    "    end_time_llm = time.time()\n",
    "    execution_time = end_time_llm - start_time_llm\n",
    "    \n",
    "    # Extract the model from the result\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        model_output = result.content.strip()\n",
    "    else:\n",
    "        # model_output = result.strip()\n",
    "        # Extract the model from the result\n",
    "        if hasattr(result, \"content\"):\n",
    "            model_output = result.content.strip()\n",
    "        else:\n",
    "            model_output = str(result).strip()\n",
    "    \n",
    "    # Build metadata for the response\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        metadata = {\n",
    "            \"response_length\": len(model_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"usage\": result.usage_metadata,\n",
    "            \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN +\n",
    "                         result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    else:\n",
    "        metadata = {\n",
    "            \"response_length\": len(model_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "\n",
    "    # Check if metadata file already exists\n",
    "    if os.path.exists(metadata_path):\n",
    "        try:\n",
    "            with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_metadata = json.load(f)\n",
    "            print(f\"[INFO] Loaded existing metadata from {metadata_path}\")\n",
    "    \n",
    "            # Increment numeric fields if they exist\n",
    "            for key in [\"execution_time\", \"response_length\", \"price_usd\"]:\n",
    "                if key in metadata and key in existing_metadata:\n",
    "                    if isinstance(metadata[key], (int, float)) and isinstance(existing_metadata[key], (int, float)):\n",
    "                        metadata[key] += existing_metadata[key]\n",
    "    \n",
    "            # Optionally merge nested 'usage' dictionaries if present\n",
    "            if \"usage\" in metadata and \"usage\" in existing_metadata:\n",
    "                for token_key in [\"input_tokens\", \"output_tokens\", \"total_tokens\"]:\n",
    "                    if token_key in metadata[\"usage\"] and token_key in existing_metadata[\"usage\"]:\n",
    "                        metadata[\"usage\"][token_key] += existing_metadata[\"usage\"][token_key]\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not read or parse existing metadata: {e}\")\n",
    "    \n",
    "    # Save the model and metadata to output files\n",
    "    save_to_file(output_model_path, model_output)\n",
    "    save_metadata(metadata_path, metadata)\n",
    "    \n",
    "    print(f\"Processed: {file_name}\")\n",
    "    print(f\"Model saved to: {output_model_path}\")\n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    state[\"model_status\"] = \"processed\"\n",
    "    state[\"model_out\"] = model_output\n",
    "    state[\"metadata\"] = metadata\n",
    "    state[\"validation_attempts\"] = 0\n",
    "    return state\n",
    "\n",
    "# Node: model Generation – generate model and JSON metadata from a single file.\n",
    "# TODO: change this function to model generation and feedback with Eclipse EMF\n",
    "@profile_node\n",
    "def model_validation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    file_name = state[\"file_name\"]\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the generated model file description\n",
    "    output_model_path_val = os.path.join(base_output_dir, file_name)\n",
    "    output_model_path_val_abs = os.path.abspath(output_model_path_val)\n",
    "\n",
    "    # Connect to the running Java EMF Validator\n",
    "    gateway = JavaGateway()\n",
    "    validator = gateway.entry_point\n",
    "\n",
    "    # Paths to the BPMN Model and Ecore Metamodel\n",
    "    file_extension = \"hepsy\"  # \"hepsy\", \"caex\", etc.\n",
    "\n",
    "    # Model Validation\n",
    "    metamodel_path_val_abs = os.path.abspath(metamodel_path)\n",
    "\n",
    "    print(\"[DEBUG] Validating with:\")\n",
    "    print(\" - Model:\", output_model_path_val_abs)\n",
    "    print(\" - Metamodel:\", metamodel_path_val_abs)\n",
    "    \n",
    "    result = validator.validateModel(output_model_path_val_abs, metamodel_path_val_abs, file_extension)\n",
    "    print(result)\n",
    "    \n",
    "    state[\"model_val\"] = True\n",
    "    return state\n",
    "    \"\"\"\n",
    "    file_name = state[\"file_name\"]\n",
    "    name_val = \"refined\"\n",
    "\n",
    "    # Split the filename into name and extension\n",
    "    file_base, file_ext = os.path.splitext(file_name)\n",
    "    print(f\"file_base: {file_base}, file_ext: {file_ext}\")\n",
    "\n",
    "    # Append the index to the base name\n",
    "    file_name_metadata = f\"{file_base}_{name_val}{file_ext}\"\n",
    "    print(f\"file_name_metadata: {file_name_metadata}\")\n",
    "\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    output_model_path_val = os.path.join(base_output_dir, file_name)\n",
    "    output_model_path_val_abs = os.path.abspath(output_model_path_val)\n",
    "    metamodel_path_val_abs = os.path.abspath(metamodel_path)\n",
    "\n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    metadata_path_val = os.path.join(base_output_json_dir, file_name_metadata)\n",
    "\n",
    "    # Connect to the Java EMF Validator\n",
    "    gateway = JavaGateway()\n",
    "    validator = gateway.entry_point\n",
    "    file_extension = \"hepsy\"\n",
    "\n",
    "    print(\"[DEBUG] Validating with:\")\n",
    "    print(\" - Model:\", output_model_path_val_abs)\n",
    "    print(\" - Metamodel:\", metamodel_path_val_abs)\n",
    "\n",
    "    validation_result = validator.validateModel(output_model_path_val_abs, metamodel_path_val_abs, file_extension)\n",
    "    print(\"[VALIDATION RESULT]\", validation_result)\n",
    "\n",
    "    # CASE 1: VALID MODEL\n",
    "    if \"Validation successful\" in validation_result:\n",
    "        print(\"Model is valid.\")\n",
    "        state[\"model_val\"] = True\n",
    "        state[\"next_step\"] = \"validated\"\n",
    "        return state\n",
    "    else:\n",
    "        attempts = state.get(\"validation_attempts\", 0) + 1\n",
    "        state[\"validation_attempts\"] = attempts\n",
    "\n",
    "        if attempts >= 3:\n",
    "            state[\"next_step\"] = \"regenerate\"\n",
    "        else:\n",
    "            state[\"next_step\"] = \"continue\"\n",
    "        state[\"model_val\"] = False\n",
    "\n",
    "    # CASE 2: INVALID MODEL — Need to correct with LLM\n",
    "    print(\"Model is invalid. Sending to LLM for correction.\")\n",
    "\n",
    "    model_content = load_file_content(output_model_path_val_abs)\n",
    "    context_llm = state.get(\"context_llm\", \"\")\n",
    "    metamodel_content = load_file_content(metamodel_path)\n",
    "    example_model_content = load_file_content(example_model_path)\n",
    "\n",
    "    correction_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are a Model-Driven Engineering (MDE) and Eclipse Modeling Framework (EMF) expert. \"\n",
    "            \"A model file failed validation against an Ecore metamodel. Your job is to fix the model.\\n\\n\"\n",
    "            \"You will be given:\\n\"\n",
    "            \"- The validation error message.\\n\"\n",
    "            \"- The metamodel definition (Ecore).\\n\"\n",
    "            \"- An example valid model.\\n\"\n",
    "            \"- The model that failed.\\n\\n\"\n",
    "            \"Correct the model so that it becomes valid. Return only the corrected model, with no comments or explanations.\"\n",
    "            \"Do not add extra text or quotation marks at the beginning and end of the model file.\"\n",
    "        )),\n",
    "        (\"user\", (\n",
    "            f\"Validation error:\\n{validation_result}\\n\\n\"\n",
    "            f\"Metamodel:\\n{metamodel_content}\\n\\n\"\n",
    "            f\"Example model:\\n{example_model_content}\\n\\n\"\n",
    "            f\"Invalid model:\\n{model_content}\\n\\n\"\n",
    "            \"Provide the corrected model:\"\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    correction_chain = correction_prompt | llm_LangChain\n",
    "\n",
    "    # Invoke the LLM chain for model refinement\n",
    "    start_time_llm = time.time()\n",
    "    result = correction_chain.invoke({\n",
    "        \"validation_result\": validation_result,\n",
    "        \"metamodel_content\": metamodel_content,\n",
    "        \"example_model_content\": example_model_content,\n",
    "        \"model_content\": model_content,\n",
    "    })\n",
    "    end_time_llm = time.time()\n",
    "    execution_time = end_time_llm - start_time_llm\n",
    "\n",
    "    corrected_model_partial = result.content.strip() \n",
    "\n",
    "    # corrected_model = corrected_model_partial.strip()\n",
    "    #if not corrected_model.startswith(\"<?xml\"):\n",
    "    #    corrected_model = \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\" + corrected_model\n",
    "\n",
    "    # Pulisce il modello rimuovendo righe con ```\n",
    "    lines = corrected_model_partial.strip().splitlines()\n",
    "    cleaned_lines = [line for line in lines if not line.strip().startswith(\"```\")]\n",
    "    corrected_model = \"\\n\".join(cleaned_lines).strip()\n",
    "\n",
    "    # Build metadata for the response\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        metadata = {\n",
    "            \"response_length\": len(corrected_model),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"usage\": result.usage_metadata,\n",
    "            \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN +\n",
    "                         result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    else:\n",
    "        metadata = {\n",
    "            \"response_length\": len(corrected_model),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "\n",
    "    # Check if metadata file already exists\n",
    "    if os.path.exists(metadata_path_val):\n",
    "        try:\n",
    "            with open(metadata_path_val, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_metadata = json.load(f)\n",
    "            print(f\"[INFO] Loaded existing metadata from {metadata_path_val}\")\n",
    "    \n",
    "            # Increment numeric fields if they exist\n",
    "            for key in [\"execution_time\", \"response_length\", \"price_usd\"]:\n",
    "                if key in metadata and key in existing_metadata:\n",
    "                    if isinstance(metadata[key], (int, float)) and isinstance(existing_metadata[key], (int, float)):\n",
    "                        metadata[key] += existing_metadata[key]\n",
    "    \n",
    "            # Optionally merge nested 'usage' dictionaries if present\n",
    "            if \"usage\" in metadata and \"usage\" in existing_metadata:\n",
    "                for token_key in [\"input_tokens\", \"output_tokens\", \"total_tokens\"]:\n",
    "                    if token_key in metadata[\"usage\"] and token_key in existing_metadata[\"usage\"]:\n",
    "                        metadata[\"usage\"][token_key] += existing_metadata[\"usage\"][token_key]\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not read or parse existing metadata: {e}\")\n",
    "\n",
    "    # Save the corrected model (overwrite original file)\n",
    "    save_to_file(output_model_path_val_abs, corrected_model)\n",
    "    save_metadata(metadata_path_val, metadata)\n",
    "\n",
    "    print(f\"Processed: {file_name}\")\n",
    "    print(f\"Corrected model saved to: {output_model_path_val_abs}\")\n",
    "    print(f\"Metadata saved to: {metadata_path_val}\")\n",
    "\n",
    "    # Track number of validation attempts\n",
    "    \"\"\"\n",
    "    attempts = state.get(\"validation_attempts\", 0) + 1\n",
    "    state[\"validation_attempts\"] = attempts\n",
    "    \n",
    "    # If attempts exceed max, restart from model_generation\n",
    "    MAX_ATTEMPTS = 3\n",
    "    if attempts >= MAX_ATTEMPTS:\n",
    "        print(f\"[INFO] Max validation attempts ({MAX_ATTEMPTS}) reached. Re-generating model.\")\n",
    "        return \"regenerate\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flag model as corrected (will be revalidated on next iteration)\n",
    "    state[\"model_val\"] = False  # For now mark as not valid (you can revalidate if desired)\n",
    "    return state    \n",
    "\n",
    "def model_to_MSE_node(state: GraphState) -> GraphState:\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#       GRAPH WORKFLOW SETUP      #\n",
    "###################################\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Initialize the state graph using our GraphState type\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "\n",
    "# Add the new node to the workflow\n",
    "workflow.add_node(\"generate_query\", generate_query_node)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)             # Merged generate node\n",
    "workflow.add_node(\"generate_web\", generate_web)\n",
    "workflow.add_node(\"transform_query\", transform_query) # Merged transform node\n",
    "workflow.add_node(\"transform_query_web\", transform_query_web)\n",
    "\n",
    "# Add evaluation nodes for vectorstore branch\n",
    "workflow.add_node(\"evaluate_rag_output\", evaluate_rag_output)\n",
    "workflow.add_node(\"evaluate_bert_score\", evaluate_bert_score)\n",
    "\n",
    "# Add evaluation nodes for web search branch\n",
    "workflow.add_node(\"evaluate_web_search_output\", evaluate_web_search_output)\n",
    "workflow.add_node(\"evaluate_web_bert_score\", evaluate_web_bert_score)\n",
    "\n",
    "workflow.add_node(\"cache_context\", cache_context_node)  # Caching node\n",
    "workflow.add_node(\"model_generation\", model_generation_node)\n",
    "workflow.add_node(\"model_validation\", model_validation_node)\n",
    "workflow.add_node(\"model_to_MSE\", model_to_MSE_node)\n",
    "\n",
    "\n",
    "def custom_parse_router_output(raw_output: str) -> RouteQuery:\n",
    "    try:\n",
    "        data = json.loads(raw_output)\n",
    "        # If the output contains \"datasource\", use it directly.\n",
    "        if \"datasource\" in data:\n",
    "            return RouteQuery(**data)\n",
    "        # Alternatively, if the output contains a \"tool\" key and it equals \"HEPSYCODE\",\n",
    "        # you might decide to map it to one of your expected values.\n",
    "        elif data.get(\"tool\") == \"HEPSYCODE\":\n",
    "            # Here you can choose what \"HEPSYCODE\" should map to.\n",
    "            # For example, if HEPSYCODE is related to vectorstore, then:\n",
    "            return RouteQuery(datasource=\"vectorstore\")\n",
    "        else:\n",
    "            raise ValueError(\"Output does not contain a valid routing decision.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse router output: {e}\")\n",
    "\n",
    "# Starting node: route question decides between web_search and vectorstore (retrieve)\n",
    "def route_question(state: GraphState) -> str:\n",
    "    # If the flag is present, skip the routing and return a special key (\"skip\")\n",
    "    if state.get(\"skip_router\", False):\n",
    "        print(\"Skipping routing; moving directly to cache_context.\")\n",
    "        return \"skip\"\n",
    "        \n",
    "    print(\"--- ROUTE QUESTION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question_val, \"topics_str\": topics_str})\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = custom_parse_router_output(source)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing router output:\", e)\n",
    "        # Fallback to a default value\n",
    "        parsed = RouteQuery(datasource=\"web_search\")\n",
    "    \"\"\"\n",
    "        \n",
    "    # Normalize the datasource value.\n",
    "    datasource = source.datasource.lower().strip()\n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"--- Routing to vectorstore ---\")\n",
    "        state[\"branch\"] = \"retrieve\"\n",
    "        return \"vectorstore\"\n",
    "    elif datasource == \"web_search\":\n",
    "        print(\"--- Routing to web search ---\")\n",
    "        state[\"branch\"] = \"web_search\"\n",
    "        return \"web_search\"\n",
    "    state[\"branch\"] = \"retrieve\"\n",
    "    return \"vectorstore\"\n",
    "\n",
    "# Add an edge from the START node to the new \"generate_query\" node\n",
    "workflow.add_edge(START, \"generate_query\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"skip\": \"cache_context\", # If the flag is active, go directly to cache_context_node\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"vectorstore\": \"retrieve\",  # Key now matches the returned normalized value\n",
    "    },\n",
    ")\n",
    "\n",
    "# For the web search branch, send directly to generate.\n",
    "workflow.add_edge(\"web_search\", \"generate_web\")\n",
    "\n",
    "# For the retrieve branch, first go to grade_documents.\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# After grading, decide whether to generate or transform.\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    lambda state: decide_to_generate(state),\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"transform_query_web\", \"web_search\")\n",
    "\n",
    "# After generate/generate_web, grade the generation.\n",
    "# If the generation is \"useful\", route to the caching node.\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate\",\n",
    "        \"useful\": \"evaluate_rag_output\",\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_rag_output\", \"evaluate_bert_score\")\n",
    "workflow.add_edge(\"evaluate_bert_score\", \"cache_context\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_web\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate_web\",\n",
    "        \"useful\": \"evaluate_web_search_output\",\n",
    "        \"not useful\": \"transform_query_web\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_web_search_output\", \"evaluate_web_bert_score\")\n",
    "workflow.add_edge(\"evaluate_web_bert_score\", \"cache_context\")\n",
    "\n",
    "# After caching, flow to model generation.\n",
    "workflow.add_edge(\"cache_context\", \"model_generation\")\n",
    "# workflow.add_edge(\"model_generation\", END)  # End the workflow after model validation\n",
    "workflow.add_edge(\"model_generation\", \"model_validation\")  # End the workflow after model validation\n",
    "\n",
    "# If model_validation sets model_val = False, redirect to model_generation\n",
    "\"\"\"\n",
    "workflow.add_conditional_edges(\n",
    "    \"model_validation\",\n",
    "    lambda state: \"validated\" if state.get(\"model_val\") else \"continue\",\n",
    "    {\n",
    "        \"validated\": \"model_to_MSE\",  \n",
    "        \"continue\": \"model_validation\"  \n",
    "    },\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"model_validation\",\n",
    "    lambda state: state.get(\"next_step\", \"continue\"),  # Usa direttamente il campo\n",
    "    {\n",
    "        \"validated\": \"model_to_MSE\",\n",
    "        \"continue\": \"model_validation\",\n",
    "        \"regenerate\": \"model_generation\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# workflow.add_edge(\"model_validation\", END)  # End the workflow after model generation\n",
    "workflow.add_edge(\"model_to_MSE\", END)\n",
    "\n",
    "# Compile the workflow graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Optionally visualize the graph (requires additional dependencies)\n",
    "try:\n",
    "    from IPython.display import display, Markdown, Image\n",
    "    # Retrieve the graph and set its configuration\n",
    "    graph = app.get_graph()\n",
    "    graph.mermaid_config = {\"graph_direction\": \"TD\"}\n",
    "\n",
    "    # Generate the PNG image bytes from the graph\n",
    "    png_bytes = graph.draw_mermaid_png()\n",
    "\n",
    "    # Save the image to disk as 'graph.png'\n",
    "    with open(\"graph.png\", \"wb\") as f:\n",
    "        f.write(png_bytes)\n",
    "    print(\"The graph has been saved as 'graph.png'.\")\n",
    "    \n",
    "    display(Markdown(\"### LangGraph Visualization ###\"))\n",
    "    display(Image(graph.draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Graph rendering failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f643811-682a-4136-aa1a-e638d0aa2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Generating Model for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0743 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.0564 seconds\n",
      "Skipping 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy as output files already exist.\n",
      "[Profiling] wrapper took 5.0556 seconds\n",
      "file_base: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation successful: No errors found.\n",
      "Model is valid.\n",
      "[Profiling] wrapper took 5.1580 seconds\n",
      "Profiling file D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\profiling_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv already exists. Skipping save.\n",
      "CodeCarbon file D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\codecarbon_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv already exists. Skipping save.\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0089 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.0425 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.2/@ports.1\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\"/>\\n    <ports name=\"ccdpp_in_port\" portExtension=\"//@nodes.2/@processes.0\"/>\\n    <ports name=\"codec0_in_port\" portExtension=\"//@nodes.2/@processes.1\"/>\\n    <ports name=\"codec1_in_port\" portExtension=\"//@nodes.2/@processes.2\"/>\\n    <ports name=\"codec2_in_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <ports name=\"codec3_in_port\" portExtension=\"//@nodes.2/@processes.4\"/>\\n    <ports name=\"codec4_in_port\" portExtension=\"//@nodes.2/@processes.5\"/>\\n    <ports name=\"codec5_in_port\" portExtension=\"//@nodes.2/@processes.6\"/>\\n    <ports name=\"codec6_in_port\" portExtension=\"//@nodes.2/@processes.7\"/>\\n    <ports name=\"codec7_in_port\" portExtension=\"//@nodes.2/@processes.8\"/>\\n    <ports name=\"merge_out_port\" portExtension=\"//@nodes.2/@processes.9\"/>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <processes name=\"merge\" processExtension=\"//@nodes.2/@ports.1\"/>\\n    <nChannels name=\"stim_ccdpp_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.4\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.5\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.6\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.7\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.8\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.2/@processes.9\" nTo=\"//@nodes.2/@ports.10\" queueSize=\"8\" rendezVous=\"true\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 6618, 'total_tokens': 7922, 'completion_tokens': 1304}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'} id='run-b69a6fe2-d73f-4e3e-a328-2e5c9fc09eb5-0' usage_metadata={'input_tokens': 6618, 'output_tokens': 1304, 'total_tokens': 7922}\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 34.7018 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@2f84aa44 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@18c57e52 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 30.4090 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@7f0e7b8e (eClass: org.eclipse.emf.ecore.impl.EClassImpl@54c1158b (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 44, 135)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 30.7384 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@48272c81 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@9ae6b70 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 44, 134)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 30.6282 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.2/@ports.1\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\"/>\\n    <ports name=\"ccdpp_in_port\" portExtension=\"//@nodes.2/@processes.0\"/>\\n    <ports name=\"codec0_in_port\" portExtension=\"//@nodes.2/@processes.1\"/>\\n    <ports name=\"codec1_in_port\" portExtension=\"//@nodes.2/@processes.2\"/>\\n    <ports name=\"codec2_in_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <ports name=\"codec3_in_port\" portExtension=\"//@nodes.2/@processes.4\"/>\\n    <ports name=\"codec4_in_port\" portExtension=\"//@nodes.2/@processes.5\"/>\\n    <ports name=\"codec5_in_port\" portExtension=\"//@nodes.2/@processes.6\"/>\\n    <ports name=\"codec6_in_port\" portExtension=\"//@nodes.2/@processes.7\"/>\\n    <ports name=\"codec7_in_port\" portExtension=\"//@nodes.2/@processes.8\"/>\\n    <ports name=\"merge_out_port\" portExtension=\"//@nodes.2/@processes.9\"/>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <processes name=\"merge\" processExtension=\"//@nodes.2/@ports.1\"/>\\n    <nChannels name=\"stim_ccdpp_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.4\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.5\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.6\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.7\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.8\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.2/@processes.9\" nTo=\"//@nodes.2/@ports.10\" queueSize=\"8\" rendezVous=\"true\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 6618, 'total_tokens': 7922, 'completion_tokens': 1304}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'} id='run-b69a6fe2-d73f-4e3e-a328-2e5c9fc09eb5-0' usage_metadata={'input_tokens': 6618, 'output_tokens': 1304, 'total_tokens': 7922}\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.1919 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@64b20313 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@fc80538 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 30.6415 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@272a059a (eClass: org.eclipse.emf.ecore.impl.EClassImpl@176d3db3 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 35.8040 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@2a0cd0d3 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4d7a6480 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 111)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 32.7333 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.2/@ports.1\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\"/>\\n    <ports name=\"ccdpp_in_port\" portExtension=\"//@nodes.2/@processes.0\"/>\\n    <ports name=\"codec0_in_port\" portExtension=\"//@nodes.2/@processes.1\"/>\\n    <ports name=\"codec1_in_port\" portExtension=\"//@nodes.2/@processes.2\"/>\\n    <ports name=\"codec2_in_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <ports name=\"codec3_in_port\" portExtension=\"//@nodes.2/@processes.4\"/>\\n    <ports name=\"codec4_in_port\" portExtension=\"//@nodes.2/@processes.5\"/>\\n    <ports name=\"codec5_in_port\" portExtension=\"//@nodes.2/@processes.6\"/>\\n    <ports name=\"codec6_in_port\" portExtension=\"//@nodes.2/@processes.7\"/>\\n    <ports name=\"codec7_in_port\" portExtension=\"//@nodes.2/@processes.8\"/>\\n    <ports name=\"merge_out_port\" portExtension=\"//@nodes.2/@processes.9\"/>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <processes name=\"merge\" processExtension=\"//@nodes.2/@ports.1\"/>\\n    <nChannels name=\"stim_ccdpp_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.4\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.5\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.6\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.7\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.8\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.2/@processes.9\" nTo=\"//@nodes.2/@ports.10\" queueSize=\"8\" rendezVous=\"true\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 6618, 'total_tokens': 7922, 'completion_tokens': 1304}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'} id='run-b69a6fe2-d73f-4e3e-a328-2e5c9fc09eb5-0' usage_metadata={'input_tokens': 13236, 'output_tokens': 2608, 'total_tokens': 15844}\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.6975 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@6328170e (eClass: org.eclipse.emf.ecore.impl.EClassImpl@92fed70 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 34.7564 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@5b810369 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@419c0b09 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 34, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 32.0786 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@1868cdca (eClass: org.eclipse.emf.ecore.impl.EClassImpl@2db00a64 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 34, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 31.7181 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.2/@ports.1\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\"/>\\n    <ports name=\"ccdpp_in_port\" portExtension=\"//@nodes.2/@processes.0\"/>\\n    <ports name=\"codec0_in_port\" portExtension=\"//@nodes.2/@processes.1\"/>\\n    <ports name=\"codec1_in_port\" portExtension=\"//@nodes.2/@processes.2\"/>\\n    <ports name=\"codec2_in_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <ports name=\"codec3_in_port\" portExtension=\"//@nodes.2/@processes.4\"/>\\n    <ports name=\"codec4_in_port\" portExtension=\"//@nodes.2/@processes.5\"/>\\n    <ports name=\"codec5_in_port\" portExtension=\"//@nodes.2/@processes.6\"/>\\n    <ports name=\"codec6_in_port\" portExtension=\"//@nodes.2/@processes.7\"/>\\n    <ports name=\"codec7_in_port\" portExtension=\"//@nodes.2/@processes.8\"/>\\n    <ports name=\"merge_out_port\" portExtension=\"//@nodes.2/@processes.9\"/>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <processes name=\"merge\" processExtension=\"//@nodes.2/@ports.1\"/>\\n    <nChannels name=\"stim_ccdpp_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.4\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.5\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.6\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.7\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.8\" queueSize=\"8\" rendezVous=\"true\"/>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.2/@processes.9\" nTo=\"//@nodes.2/@ports.10\" queueSize=\"8\" rendezVous=\"true\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 6618, 'total_tokens': 7922, 'completion_tokens': 1304}, 'model': 'mistral-large-latest', 'finish_reason': 'stop'} id='run-b69a6fe2-d73f-4e3e-a328-2e5c9fc09eb5-0' usage_metadata={'input_tokens': 26472, 'output_tokens': 5216, 'total_tokens': 31688}\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0662 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@2f314a7e (eClass: org.eclipse.emf.ecore.impl.EClassImpl@3e8e521e (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "[INFO] Loaded existing metadata from D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-mistral-large-latest-0.7/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[Profiling] wrapper took 31.6878 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_refined.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-mistral-large-latest-0.7\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@45270483 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@68c2f21 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-mistral-large-latest-0.7/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 35, 129)\n",
      "Model is invalid. Sending to LLM for correction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m file_name         \u001b[38;5;66;03m# Provide file name for model generation\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# state[\"question\"] = question           # The query generated from the metamodel\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Run the workflow using stream() and take the final output state\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m result_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Record end time for this file and calculate overall time\u001b[39;00m\n\u001b[0;32m     65\u001b[0m file_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[116], line 211\u001b[0m, in \u001b[0;36mtiming_profile_node.<locals>.wrapper\u001b[1;34m(state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    210\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 211\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    213\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "Cell \u001b[1;32mIn[116], line 245\u001b[0m, in \u001b[0;36mcc_profile_node.<locals>.wrapper\u001b[1;34m(state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m tracker \u001b[38;5;241m=\u001b[39m EmissionsTracker(\n\u001b[0;32m    236\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    237\u001b[0m     measure_power_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# save_to_api=True\u001b[39;00m\n\u001b[0;32m    243\u001b[0m )\n\u001b[0;32m    244\u001b[0m tracker\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 245\u001b[0m result \u001b[38;5;241m=\u001b[39m func(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    246\u001b[0m emissions \u001b[38;5;241m=\u001b[39m tracker\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Try to extract detailed metrics if available (from the internal attribute)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[116], line 1405\u001b[0m, in \u001b[0;36mmodel_validation_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;66;03m# Invoke the LLM chain for model refinement\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m start_time_llm \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 1405\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcorrection_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetamodel_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetamodel_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexample_model_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_model_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1411\u001b[0m end_time_llm \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1412\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m end_time_llm \u001b[38;5;241m-\u001b[39m start_time_llm\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:3016\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3014\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3015\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3016\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    285\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    691\u001b[0m                 m,\n\u001b[0;32m    692\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    693\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    694\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    695\u001b[0m             )\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    926\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    927\u001b[0m         )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_mistralai\\chat_models.py:545\u001b[0m, in \u001b[0;36mChatMistralAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    544\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 545\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    546\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    547\u001b[0m )\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_mistralai\\chat_models.py:464\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m         _raise_on_error(response)\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m--> 464\u001b[0m rtn \u001b[38;5;241m=\u001b[39m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rtn\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_mistralai\\chat_models.py:460\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iter_sse()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     _raise_on_error(response)\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:1145\u001b[0m, in \u001b[0;36mClient.post\u001b[1;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1126\u001b[0m     url: URLTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     },\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1259\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#       model GENERATION LOOP     #\n",
    "###################################\n",
    "\n",
    "# Global CodeCarbon tracker for the entire application\n",
    "global_cc_tracker = EmissionsTracker(\n",
    "    project_name=\"global_app\",\n",
    "    measure_power_secs=1,\n",
    "    output_dir=CODECARBON_FOLDER,\n",
    "    allow_multiple_runs=True\n",
    "    # api_call_interval=4,\n",
    "    # experiment_id=experiment_id,\n",
    "    # save_to_api=True\n",
    "    # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard\n",
    "    # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "    # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    ")\n",
    "global_cc_tracker.start()\n",
    "\n",
    "# Reset the overall summary for CodeCarbon per file\n",
    "cc_global_summary = []\n",
    "\n",
    "# List to collect summary records for each file (for final summary CSV)\n",
    "summary_records = []\n",
    "\n",
    "app_start_time = time.time()\n",
    "\n",
    "# For each file, add file name and the query to the state.\n",
    "# The cache_context node in the workflow will ensure the refined context is present.\n",
    "input_files = [file_name for file_name in os.listdir(base_model_path) if file_name.endswith(\".hepsy\")]\n",
    "\n",
    "for file_name in input_files:\n",
    "    # Record start time for this file\n",
    "    print(f\"Start Generating Model for {file_name}\")\n",
    "    file_start = time.time()\n",
    "    \n",
    "    # Record the starting index of the global profiling_records list\n",
    "    start_index = len(profiling_records)\n",
    "\n",
    "    # Start a file-level CodeCarbon tracker\n",
    "    file_cc_tracker = EmissionsTracker(\n",
    "        project_name=\"global_file_\" + file_name,\n",
    "        measure_power_secs=1,\n",
    "        output_dir=CODECARBON_FOLDER,\n",
    "        allow_multiple_runs=True,\n",
    "        api_call_interval=4\n",
    "        # experiment_id=experiment_id,\n",
    "        # save_to_api=True\n",
    "        # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard for each file\n",
    "        # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "        # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    "    )\n",
    "    file_cc_tracker.start()\n",
    "    \n",
    "    # Reset the per-node CodeCarbon metrics for this file\n",
    "    cc_metrics_for_file = []\n",
    "    \n",
    "    state = GraphState()\n",
    "    state[\"file_name\"] = file_name         # Provide file name for model generation\n",
    "    # state[\"question\"] = question           # The query generated from the metamodel\n",
    "    # Run the workflow using stream() and take the final output state\n",
    "    result_state = list(app.stream(state, config={\"recursion_limit\": 25}))[-1]\n",
    "    \n",
    "    # Record end time for this file and calculate overall time\n",
    "    file_end = time.time()\n",
    "    overall_time = file_end - file_start\n",
    "\n",
    "    # Stop the file-level CodeCarbon tracker and get global metrics for the file\n",
    "    file_emissions = file_cc_tracker.stop()\n",
    "    # Try to get detailed metrics if available\n",
    "    if hasattr(file_cc_tracker, \"_final_emissions_data\"):\n",
    "        file_metrics = file_cc_tracker._final_emissions_data\n",
    "    else:\n",
    "        file_metrics = {\"total_emissions\": file_emissions}\n",
    "\n",
    "    # Extract profiling records corresponding to this file\n",
    "    file_records = profiling_records[start_index:].copy()\n",
    "    # Append an additional record for the overall file execution time\n",
    "    file_records.append({\"node\": f\"FILE_{file_name}\", \"execution_time\": overall_time})\n",
    "    \n",
    "    # Save the profiling data for this file in a dedicated CSV file if it doesn't already exist\n",
    "    csv_file_path = os.path.join(PROFILING_FOLDER, f\"profiling_{file_name}.csv\")\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "            fieldnames = [\"node\", \"execution_time\"]\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for record in file_records:\n",
    "                writer.writerow(record)\n",
    "        print(f\"Profiling data for {file_name} saved to {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"Profiling file {csv_file_path} already exists. Skipping save.\")\n",
    "    \n",
    "    # Add a summary record for this file\n",
    "    summary_records.append({\"file_name\": file_name, \"execution_time\": overall_time})\n",
    "\n",
    "    ############ CODE CARBON ##############\n",
    "    # Save per-node CodeCarbon metrics along with file-level metrics into a dedicated CSV file,\n",
    "    # with file name starting with \"codecarbon_\"\n",
    "    cc_csv_file = os.path.join(CODECARBON_FOLDER, f\"codecarbon_{file_name}.csv\")\n",
    "    if not os.path.exists(cc_csv_file):\n",
    "        # Prepare a list of rows: one row per node metric, plus one row for overall file metrics.\n",
    "        # We merge the per-node metrics (from cc_metrics_for_file) into a list.\n",
    "        # Note: Each metric row is a dictionary. We also add a row for the file global metrics.\n",
    "        rows = []\n",
    "        for record in cc_metrics_for_file:\n",
    "            # record already contains \"node\" and various CodeCarbon metrics\n",
    "            rows.append(record)\n",
    "        # Append a row for overall file CodeCarbon metrics:\n",
    "        overall_record = {\"node\": f\"FILE_{file_name}\"}\n",
    "        overall_record.update(file_metrics)\n",
    "        rows.append(overall_record)\n",
    "        \n",
    "        # Determine all possible keys across all rows\n",
    "        all_keys = set()\n",
    "        for r in rows:\n",
    "            all_keys.update(r.keys())\n",
    "        all_keys = list(all_keys)\n",
    "        \n",
    "        with open(cc_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=all_keys)\n",
    "            writer.writeheader()\n",
    "            for r in rows:\n",
    "                writer.writerow(r)\n",
    "        print(f\"CodeCarbon metrics for {file_name} saved to {cc_csv_file}\")\n",
    "    else:\n",
    "        print(f\"CodeCarbon file {cc_csv_file} already exists. Skipping save.\")\n",
    "    \n",
    "    # Append summary record for this file (global CodeCarbon metrics)\n",
    "    cc_global_summary.append({\"file_name\": file_name, **file_metrics})\n",
    "\n",
    "    ############## RAG EVALUATION ################\n",
    "    \n",
    "    skip_router_value = result_state[\"model_to_MSE\"][\"skip_router\"]\n",
    "    # skip_router_value = result_state.get(\"skip_router\", False)\n",
    "    print(\"skip_router:\", skip_router_value)\n",
    "\n",
    "    evaluation_metrics = result_state[\"model_to_MSE\"].get(\"evaluation_metrics\")\n",
    "    # evaluation_metrics = result_state.get(\"evaluation_metrics\", {})\n",
    "    print(\"evaluation_metrics:\", evaluation_metrics)\n",
    "\n",
    "    bert_score_metrics = result_state[\"model_to_MSE\"].get(\"bert_score\")\n",
    "    # bert_score_metrics = result_state.get(\"bert_score\", {})\n",
    "    print(\"bert_score_metrics:\", bert_score_metrics)\n",
    "\n",
    "    web_bert_score_metrics = result_state[\"model_to_MSE\"].get(\"web_bert_score\")\n",
    "    # web_bert_score_metrics = result_state.get(\"web_bert_score\", {})\n",
    "    print(\"evaluation_metrics:\", web_bert_score_metrics)\n",
    "\n",
    "    if not skip_router_value:\n",
    "        # Save evaluation results to CSV for this file (if evaluation metrics exist)\n",
    "        evaluation_data = {\"file_name\": file_name}\n",
    "        \n",
    "        # Use get() with a default empty dict to ensure we update with available metrics\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"evaluation_metrics\", {}))\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"bert_score\", {}))\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"web_bert_score\", {}))\n",
    "        \n",
    "        eval_csv_file = os.path.join(EVALUATION_FOLDER, f\"evaluation_{file_name}.csv\")\n",
    "        with open(eval_csv_file, \"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=evaluation_data.keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerow(evaluation_data)\n",
    "        print(f\"Evaluation results for {file_name} saved to {eval_csv_file}\")\n",
    "    \n",
    "    print(f\"Model generation result for {file_name}: {result_state.get('model_status', 'unknown')}\")\n",
    "\n",
    "# Record end time of the entire application and calculate total time\n",
    "app_end_time = time.time()\n",
    "total_app_time = app_end_time - app_start_time\n",
    "summary_records.append({\"file_name\": \"TOTAL_APP\", \"execution_time\": total_app_time})\n",
    "\n",
    "global_summary = global_cc_tracker.stop()\n",
    "if hasattr(global_cc_tracker, \"_final_emissions_data\"):\n",
    "    global_metrics = global_cc_tracker._final_emissions_data\n",
    "else:\n",
    "    global_metrics = {\"total_emissions\": global_summary}\n",
    "cc_global_summary.append({\"file_name\": \"TOTAL_APP\", **global_metrics})\n",
    "print(\"END model GENERATION PROCESS!!!\")\n",
    "\n",
    "# Save the final summary CSV with overall times per file if it doesn't already exist\n",
    "final_csv_file = os.path.join(PROFILING_FOLDER, \"profiling_summary.csv\")\n",
    "if not os.path.exists(final_csv_file):\n",
    "    with open(final_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        fieldnames = [\"file_name\", \"execution_time\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in summary_records:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Summary profiling data saved to {final_csv_file}\")\n",
    "else:\n",
    "    print(f\"Summary profiling CSV {final_csv_file} already exists. Skipping save.\")\n",
    "\n",
    "# Save the global CodeCarbon summary into a CSV file\n",
    "global_csv_file = os.path.join(CODECARBON_FOLDER, \"codecarbon_summary.csv\")\n",
    "if not os.path.exists(global_csv_file):\n",
    "    fieldnames = set()\n",
    "    for record in cc_global_summary:\n",
    "        fieldnames.update(record.keys())\n",
    "    fieldnames = list(fieldnames)\n",
    "    with open(global_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in cc_global_summary:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Global CodeCarbon summary saved to {global_csv_file}\")\n",
    "else:\n",
    "    print(f\"Global CodeCarbon summary file {global_csv_file} already exists. Skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e31d-edf7-4c87-b023-2585e61c183b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
