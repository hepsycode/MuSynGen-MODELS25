{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5841d78-9230-49e8-b9fc-ec27e72288af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1af2c39-c132-4c07-8b7d-cc6fc8cb75de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRICE_PER_INPUT_TOKEN: 2.5e-06 $\n",
      "PRICE_PER_OUTPUT_TOKEN: 1e-05 $\n",
      "Model Name: gpt-4o-2024-08-06\n",
      "Model Temperature: 1.0\n",
      "Loaded 9 URLs from 'config/BASE_URL.csv'.\n",
      "The folder 'faiss' already exists.\n",
      "Loading existing FAISS index from disk...\n",
      "The graph has been saved as 'graph.png'.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### LangGraph Visualization ###"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8YAAATeCAIAAACE0aruAAAAAXNSR0IArs4c6QAAIABJREFUeJzs3XdAU1fjPvCbAUkIEKZsGSKiuFAQN7WoiIC4xVVxr7orzqq1tlqt2trWStWKC0VwULXiQAHFVfcCZCMIIpuEBMj4/XHfH69fXysqFw4hz+evzHOfYKsPJ+eey1KpVBQAAAAAAHwqNukAAAAAAADqDZUaAAAAAKBeUKkBAAAAAOoFlRoAAAAAoF5QqQEAAAAA6gWVGgAAAACgXrikAwBAY1DIVa+yZZUVisoKuVJOVVcpSSeqG0/A5mixhHpcgR7H3JZPOg4AAMC/YmFfaoBmrLpKmfxPRfoTcW6q1NyWL9Dl6OhxRaZa1VI1qNTafHbJq2pJhZzDYWUmVjq0Fzq0F7buokc6FwAAwNtQqQGarVvnitIfiy0cBA7tdVs665COUy/yamX6E0nmM0l2UmVPf5N2HvqkEwEAAPwXKjVAM5T6sOLioYKu/Q27eRuRzsIwqVhx/XRhYW7VwC/MDVtok44DAABAoVIDNEM3/y6SlMs9R5hytZrt+cdlhTWn/3jZfbCxY2dd0lkAAABQqQGal1vnitgclvvA5jY5/U7nQvPa9xTZOKn3mhYAAGgGmu0kFoAGunAwn2JRGtKnKYryCbJ4fK3s0dVS0kEAAEDToVIDNBP3LpcIRVyPQcakgzSqwVMsUh+Ic9OkpIMAAIBGQ6UGaA6ykyUVxfJeQ0xIByFg+DzruxdLZBI56SAAAKC5UKkBmoP4E4Ud+4hIpyCmdRfda1FFpFMAAIDmQqUGUHuJt8vNbfmGZpq7o1zbbvr5WbKSV9WkgwAAgIZCpQZQe6kPxL2GaNYS6v/Vd5jpo2tlpFMAAICGQqUGUG95GdIqqVKgyyUdhLCWzjqPE8pUSuwKCgAABKBSA6i39McShw7CRj7osmXLTp8+/Qlv7N+//8uXLxsgEUVRlEN7YfoTSQMNDgAA8B6o1ADqrSivqlXHxr6CYGJi4ie8Kz8/v7S0AfeQbu2q+xK76QEAAAm4eiKAevt1cercH1ux2KyGGPzUqVNhYWG5ubl8Pr9Lly5fffWVmZmZm5sb/ayurm5sbKxCodi9e3d0dHRBQYFIJPL09FywYIFAIKAns1kslp2d3aFDh6ZMmbJz5076jZ6enlu3bmU8bV6mNOFU0ciF1oyPDAAA8H6avv4SQK1JxQq+DruB+vT9+/c3bNiwatUqd3f30tLSn3/+efny5fv27fv7778HDx68dOnSQYMGURQVFhYWGhq6fv16Z2fnly9ffvPNN1wu96uvvqIoSktLKykpSSaT7dixo2XLljY2NitWrDh06JCNjU1DBBbqcyXl2J0aAAAIQKUGUGOV5XId/Yb6vzgtLY3H4/n7+3O5XGtr602bNuXl5VEUJRKJKIrS0dGhb/j4+PTo0cPR0ZGiqJYtWw4cODAhIaF2kJycnL1799KvFAqFFEXp6+vTNxiHSg0AAKSgUgOoMYVCJRA21BkRbm5uLBZr2rRpAQEBHh4elpaWxsbv2KrPwMDg7NmzGzZsKCgokMvllZWVOjo6tc/a2trSfboRsDkUT4ejUqlYrAaZtgcAAPg3OD0RQI0J9bklBTUNNLidnd2+ffusra1/+eWXIUOGBAUFPXny5H9ftmXLlj179owePXr37t1hYWHDhg1781ld3cY7dVJSpmCzKfRpAABofKjUAGpMR49TWaFouPFbt269YcOGixcvhoSEcDichQsXVlf/nysUKhSKqKioSZMmDR482MrKysTERCwWN1ye92vQZTAAAADvgUoNoMZYbJats46kvEEmqp88efLo0SOKojgcTteuXWfPnl1aWlpUVEQ/S28WpFQqFQpF7dIOiUQSHx///n2EGm6XoUqJwsKO30CDAwAAvAcqNYB60zXkZjyubIiRr1+/vnjx4piYmJycnOTk5KNHj1pYWJibm/N4PB6Pd+/eveTkZBaL1aZNmzNnzuTk5KSkpCxcuLBXr17l5eWZmZly+dtnCurr61MUde3atfT09IYInHpfbGrNa4iRAQAA3g+VGkC9NdwlA6dMmTJs2LCffvpp5MiRc+fOValUO3bsoFcqBwUFXbp0ac6cOVKpdM2aNQqFYvTo0StWrAgMDJw7d665ufkXX3xRUFDw1oBt27bt2bPn9u3bN2/e3BCBiVxIEgAAAJd6AWgOTvySM3SuFbthdqdWF3mZ0qfXy/uPMyMdBAAANBFmqQHUnm1b4c2/i0inIOzmmeK23fRJpwAAAA2Fs+MB1F7X/oZ/rEjv6mXIE3De+QJvb++qqqr/fVyhUHA4734LRVFRUVENtKX0gwcPFi5c+M6nqqurtbW13/mUvb39vn373vlUVqKEo8WychQwGhMAAOBDYeEHQHOQ9E95WWGNh887LsVCUZRYLH7n/+lyuZzD4fzbRs66uroNtMezXC6XSqXvfKqqqkpbW/udx2Wz2f922cULB/O7ehkaW+LcRAAAIAOVGqCZuBxeYNaS59KjkS5V2HTEHHll4SBo54FVHwAAQAzWUgM0E5+PafHsZnnmswbZ/aPJunGmUIvPRp8GAACyMEsN0Kyc2f3SuZueYyc90kEaw82/i/i6nM59DUgHAQAATYdZaoBmxW+65fO74nuXS0gHaXB//5nHYlHo0wAA0BRglhqgGbpzsfjZrfKe/iaOnXRJZ2Heg9jSuzEln40ybdWxGX46AABQR6jUAM1TWWHN9dOFSiXV0lnH3kWoa6D2O2YW5VVlPpU8iCtz6qrb09eYo4Uv2QAAoKlApQZozvKzZEm3yzOeSnT0uGYteTr6XKE+R9eAq1CQTvYBuByqrEguLpMrFaq0h2KuNtuho7Bjb5GOntr/egAAAM0MKjWARih4IXv1QlZZppCUKzhclrhUzuDg1dXVSUlJHTt2ZHBMiqL0jbQUCqWuiKtrwLVwEIiMtZgdHwAAgCmo1ABQXwUFBZMmTTp37hzpIAAAAGRgMSIAAAAAQL2gUgMAAAAA1AsqNQAwoHXr1qQjAAAAEINKDQAMSElJIR0BAACAGFRqAGCASCQiHQEAAIAYVGoAYEBZWRnpCAAAAMSgUgMAA8zNzUlHAAAAIAaVGgAYkJ+fTzoCAAAAMajUAMCAtm3bko4AAABADCo1ADAgMTGRdAQAAABiUKkBAAAAAOoFlRoAGGBkZEQ6AgAAADGo1ADAgOLiYtIRAAAAiEGlBgAGmJiYkI4AAABADCo1ADCgsLCQdAQAAABiUKkBAAAAAOoFlRoAGGBvb086AgAAADGo1ADAgIyMDNIRAAAAiEGlBgAAAACoF1RqAKgvFovl5OREOgUAAAAxqNQAUF8qler58+ekUwAAABCDSg0AAAAAUC+o1ADAgLZt25KOAAAAQAwqNQAwIDExkXQEAAAAYlCpAQAAAADqBZUaABjQunVr0hEAAACIQaUGAAakpKSQjgAAAEAMKjUAAAAAQL2gUgMAA0QiEekIAAAAxKBSAwADysrKSEcAAAAgBpUaABjg4OBAOgIAAAAxqNQAwID09HTSEQAAAIhBpQYAAAAAqBdUagBgQIsWLUhHAAAAIAaVGgAYUFBQQDoCAAAAMajUAFBfLBbL2dmZdAoAAABiUKkBoL5UKlVSUhLpFAAAAMSgUgNAfWGWGgAANBwqNQDUF2apAQBAw6FSA0B9sVgsKysr0ikAAACIYalUKtIZAEAtTZo0qbi4mKIopVJZUlJiYmKiUqnkcvm5c+dIRwMAAGhUmKUGgE80atSooqKivLy8V69eVVdXv3z5Mi8vj83G3yoAAKBx8I8fAHwiPz8/Ozu7Nx9RqVRdu3YllwgAAIAMVGoA+HTjxo0TCoW1d83MzCZOnEg0EQAAAAGo1ADw6fz8/GxsbGrvuru7t27dmmgiAAAAAlCpAaBeJkyYQE9Ut2jRYvz48aTjAAAAEIBKDQD1MmjQIBsbG5VK5ebm5uTkRDoOAAAAAVzSAQA0WklBdVlhjVJJOkf9DPOexZZF+XgGpT+RkM5SL1wuZWimrWeoRToIAACoGexLDUBG6kPxo/hSSbnCspWOpExOOg5QFEUJDbjZiRJjS+1e/sbGFjzScQAAQG2gUgMQkPZI/PBqmdc4SzabRToLvE1cVnPp4Ev/mZYGJpiuBgCAD4K11ACNLSup8v6V0gETrNCnmyZdkdbQL23Df8yulqn5ihwAAGgsqNQAje1BbEmvoS1Ip4A69AxocetcEekUAACgHlCpARqVQq7KTZXqGmiTDgJ10DfSzkmVkk4BAADqAZUaoFGVF9eY2wlIp4C66RlqUxRW5gAAwAdBpQZoZCzs76EWVCpVRXEN6RQAAKAeUKkBAAAAAOoFlRoAAAAAoF5QqQEAAAAA6gWVGgAAAACgXlCpAQAAAADqBZUaAAAAAKBeUKkBAAAAAOoFlRoAAAAAoF5QqQEAAAAA6gWVGgAAAACgXlCpAQAAAADqBZUaAAAAAKBeUKkB4FNkZKQFjvMjnQIAAKBJQKUGgE/x/Hki6QgAAABNBSo1QFMnl8t3/LJ5yNDPff37/rD5m2vXYvt5uZWUFNPPxlw+P2v2RB/f3sNHDvz1t60ymYx+/Jv1y79Zv/xc9F8TJw0f7Ndn5qwJz549rh0wdH/IF0EjvH16TvhiWNRfkbXHGjq8f+TxsGUr5g8c1EMsFisUin2huyZMHOrt03PUGJ+fft4klUopigrdH7Jp87pXr/L7eblFHg+jKOp5SlLwsi8Dhnn5+vf9es1X+fl5H/LRov6KHDPWd9DgXvMWTH2ektTPy+1STDRFUStWLVyxamHtyy5e/Lufl1tlZeX7P/Kb4a8lxPXzcnvy5GHtIKmpz/t5uRUVFdb7DwQAAOBtqNQATV3k8bDTZ07MmD7v998OmJiY7vrjZ4qi2Gw2RVHXrsVu+G5V164eu/84Erx0bfzVmK3bv6PfxeFyHz95kJj45I9dh09EXhSJDH7Y8g391K6Qn8OPHRw/dvLePeGjRo7/9bcfz/59in6Ky+WePnPCwd5x+9YQPp8feTws7EjolClz9u4+Grx0bcL1uD1//kZRVOCYScOHB7ZoYXbqxCV/vxGvXuUvXjKTxWZv3xqy9cdd5RVlS5bOrq6ufv/nevjw3k8/b+rbx+uPXYfHBQZt3/49HeD973rPR34zvEe3npYWVhcv/V37xvirMSYmpkZGxvX4owAAAHg3VGqApu78hTO9e33m5zusZUu7qVPmmLUwr30q7Ghop05dpk/70trKprtHr+nT5l26dK6g4BX9rEwmnTN7sUAg4PP5/b18srMzZTKZWCyO+itizOiJ3t5+1lY2AUNGeg/0CzsSSr+FxWLxefyZM+a7uHTkcrn9vXxCfj/0eb+B1tYt3d269/ts4J07NymK4vP5PG0ei8USiQx4PN5fpyNZLNbqVd85ODg6t2m3cvm3eXm5cfEx7/9cFy/9bWhoNHvWwpYt7Xr06DM0YPSH/DTe85HfDK+lpTVo0JArVy7U1NTQb4yLjxk4wJfFYn3qnwMAAMC/QqUGaNJUKlVOTnZ7l061j/Tu3Y++oVQqnz9PdOvavfapzp26UhSVnp5C37WytOHz+fRtPT19iqIqKsrT0p7L5fI339WpU9eXL3Nql1W4uHSsfUokMrh1O2HOl0GjAwcPHznw9JnjFRXl/xsyMfGJcxsXPV09+q6ZmbmFhVVqavL7P1pWdkYrh9b0dDtFUS7tO73/9R/ykd8M7zNoiKRScvPWNfpkyuzszEHe/nUeAgAA4BPU8R0rAJBVVVUll8sFOjq1j+jri+gbMplMoVCE7g85cHD3m28pKv7PcmFtHu+t0VQqVWWlhKKoRUtm1s7XqlQqiqKKS4p0dHQoihIKdWtf/8uvWy5e+nvRghUu7TvxtHlHju6/fOX8/4aUSMQpqckDB/WofaSmpqY2xr+prJQYGf53GYaOQOe9L/+gj/xmeBMT027del64cLZP735x8TEuLh1tbGzrPAQAAMAnQKUGaNLotcW1Z+DRM830DT6fz+Vyhw8L9B089M23GBgavWdAunSuWrnBwd7xzcdbmJq99UqFQvH3uaiJE6YNGDCYfkQiEf/bmB06dF6yaNWbDwrqqsh8vkAmk9beFYsr/u2VVdVV//8tH/eRfX2Grt+wQiKRxF+NGT4s8P15AAAAPhkqNUCTxuVyW7QwS0p+WvvItWtX6BtsNrt1a+dXr/JatrSjH6mpqSl4/UpfT/89Azo4tNbS0iopKW7p+Z93lZaWsFgsbW3tt16pVCoVCkXtpLhEIrl+I752ncab2rZtf/7CGUtL69qTC1+8yDI2Nnn/R7Oxtr1z96ZSqaTHfPjoXu1TukLd/Ff/3TMkLe35p33k7t176+uLjhwNffky5zPPAe/PAwAA8MmwlhqgqfPs2z8u7tLlKxdyX+aE7g95XVhQ+1TgmC/ir14OOxL64kVWSmry9xu/nr9gqkQiec9ourq6fn7DQ/eHXL5y4WVe7v0Hd74KnrNp87r/faWWllZrxzbnL5zJfZmTlpaycvVCD49eFRXl2dmZcrlcV1evqKjw0aP7+fl5/n4jpNLKHzavS0lNzsnJPnBwz+Spo5OSnr7j8G/w8hpUVFT4686taWkpl69cOH36eO1TrVs7JyU9TUtLUalUt25f/+efG5/2kblcrvdAv6PhB3r37qerq/vO1wAAANQfKjVAUzc5aFbfPp9v+XH93C+DKsQVE8ZNoSiKy9WiKKpvn89Xrvg25nL0lGljlgbPrZHXbN8aIhQK3z/gnFmLhgaM+mP3jklBIzb9sLZD+86rVmx45yuXfrVGqVBMmTp6/YYVw4cFTpsy16yF+ey5X7wuLPD6fJClpfWSpbPPRUeZm1ts2xpSXFw0f8HUWXMm3v7n+oZvt7Vr1+H9Mdzdus+ZvSg+Pmb23C+Onzgyd86S2qeG+I/09Oy/cNH0ocP7X7r097RpX9Kz5p/wkXv37qdQKAb7BNT1YwYAAPh0LPrMJABoHCUFNWd2vxz65UecJyeXy8XiCgMDQ/rugYN7Tpw8eurEpQbLSEZZWenQ4f3Xrtn0mWd/BocN+WPHzVvX9u099rFvrJYpj/+UOWOjA4NhAACgucIsNUBTdzhs37gJQ2LjLuW+zLmWEHvi5FHvgX6kQ6mB7OzMEyfDj0Ucmj71S9JZAACgmcPpiQBN3fhxk6urq3aF/FRcXNTC1Mx38NAvJk4nHeqDrFi18MmTB+98ynfwsFkzFzTo0WfNmSgU6s6Zvbhnz76fNoJKpcrMzLSxseFwOEynAwCAZgULPwAa1Scs/FBfRUWF1TXvviy5jo5Q9P/3EmmaqmXKY1vTL6UtGzdu3IgRI/bt2/f06dNJkyZ16NDh2bNnSqXS0dGx9ko6AACg4TBLDQANpc599Jo4Dod9/Ph/9iHx8fGxs7Ojr4bz9OnTM2fOTJgwYcCAATt27EhOTp4zZ46Li8vdu3cpinJxcUHVBgDQNKjUAAB1Mzc3Nzc3p2+PGjVq1KhR9O1x48alpqaKRCKKolJTUy9fvjxlyhQPD481a9ZkZ2evXLnSyckpLi6Ooih3d3cdnbqvEAkAAOoIlRoA4NOZmJiYmPxnMn7MmDFjxoyhby9ZsiQ7O9vIyIiiqFevXt28ebNFixZt27adM2dOUVHRpk2b7O3t//77bw6H07dvX4FAQPRDAABAfaFSAzQGsVisq6sbGxv7d1R8O4MJpONAgxOJRB06/Gdn7tGjR48ePZq+vW3btpycHGNjY/qClPfv32/Tpo2dnd348ePLyspCQkKsrKzCwsJ4PJ6vry+fz5fJZFhGAgDQ9GETPQDmVVdX37t3LzExkaKow4cP9+zZMyEhgaIoFovl5eXFxvYRGozP5zs6Ourr69MLSL7//ns7Ozv6v5Pdu3fTVZvP5ycnJ4vFYoqivvjii379+hUXF1MUFRIScvjw4erqaoqiSkpKSH8UAAD4L8xSAzAjOzv7zJkztra2vr6+YWFhCQkJ06ZNoyjKy8tr5MiRPB6PoihPT8+SgpozD1+SDgtNkYWFBX1j+PDhtQ8eO3asvLycXoRtbm6elpZWVVWlra09Y8aMFy9exMTECIXCjRs3GhkZTZs2jcPhvHjxwszMTFtbm9znAADQRKjUAB+tvLy8sLDQwcHh8ePHW7Zsad++fXBw8IsXL3g8nouLC0VRQUFBQUFB9Itrz2kD+DT0lDZFUQEB/72sekRERE1NDb1hdqdOnXJycugdURctWpSbm3vjxg2FQrFixQpra+v58+crlcrU1FQLCws9PT1ynwMAoDlDpQaom0wmu3r1qlQqHTJkyO3bt5ctWzZmzJhZs2YZGhouW7asTZs2FEX16tWrV69epJOCBtHS0qJvDB48uPbByMhI+gaHw/H29n79+jVFUUqlcu3ateXl5WfPnpVIJCtWrLC3t1+0aFFlZWVycnLLli3pBScAAPDJUKkB3lZRUaGnp1daWvrzzz8rlcpvvvkmMzMzJiamX79+9IzglStX6FdaW1tbW1uTzgvwbl5eXvQNLpd75MgR+rZAIBgzZkxpaSlFUVKp9LfffjMyMtq8efPNmzd3797t7e09evTonJycrKysVq1a4TsWAIAPhEoNQGVkZGRmZvbr16+0tHTs2LGmpqYHDhyQy+Wurq7t27enKMrZ2XnTpk30i+lV0QBqis1m136dYmxsvGfPHvp2586d582bR9+uqKgIDw+3s7NbvHjx3bt3f/zxRzc3tyVLluTm5j59+rRdu3b4TRIA4C24IDloqCNHjqSmpn799ddSqXTixImurq6rVq2qqqoqKytr0aJFwx23rLAm/njhZ4EWDXcIYERVpfLaybyhc6xIByFMLpenp6dXVFR07do1Kytr165d9vb2M2bMOHnyZGho6Lhx48aMGfP48eP09PTOnTvb2toqlUo2G3tJAYDGwSw1NH9paWnGxsYGBgY7duw4e/bsqVOnBALBq1evXF1d6e/Ba5ef8ni8Bu3TFEWJTLReZlRWVym1eagdTVpRnoxikQ7RBHC5XCcnJ/q2ra3txo0b6dsBAQHu7u5KpZLeHfLhw4cymczW1vbcuXM///yzv7//vHnznj179vjxYzc3t1atWlVXV2MfEgBoxjBLDc3Qs2fP7t271717d0dHx7lz575+/Xrr1q02NjYPHz60srKqvdYdKbGRBS1aCm3aCMnGgPd7GFcsMmJ36G1AOoj6KSoqqqystLGxSUtLO378uJOT09ChQw8dOvTHH38sXLhw+PDhcXFxmZmZnp6ednZ2EolEKMT/CwCg9lCpQe2VlZWJRKJLly5FRUVNnDixW7duW7duZbPZEyZMMDU1JZ3u3f5cmzHwCyuRCSbtmqhnt0pev5D5TcX6HCZJJJLq6mpDQ8MnT55cvny5U6dOnp6eBw4c+PXXXxcsWDB+/Phbt249fPiwb9++zs7OZWVlQqGQy8VXqQCgHlCpQc1UV1c/fvxYJBI5OjoeOHDgt99+W79+vbe3d0JCAovFcnNzU4svl+XVykObsl16GOoaco3MtFUqrDBoElQqVWFuVWlhVUle1ZCZlqTjaAqFQiEWi0UiUXp6+sWLF52cnPr16xcaGvr777+vXr3a39//xIkTOTk5AQEBtra2BQUFenp6AoGAdGoAgP8DlRrUQElJSXh4uIGBQWBgYGho6I0bN+bNm9e+ffv8/HwTExP1nce6d7kkJ0WqUlElr6oJxpDJZHw+n2CApsPEisfmUHbtdNp5iEhnAar2P86nT5/euXPH1dW1Y8eOv/zyS3h4+Ndff+3t7X38+PHs7Gx/f39HR8f8/HwdHZ3ay+IAADQyVGpoWhQKRVpampOTU1lZ2ZIlSxQKxb59+1JSUmJjY/v27UtfVAUYNHXq1J9//llXV5d0EICPQJ/smJSUdOfOnfbt23fu3Hn37t1hYWHffvtt7969d+zYIZVKZ86caWBgkJqaamxsbGhoSDoyADRzqNRAmEqlunv3bkZGxqhRoyoqKry8vDw8PH755ReJRPL8+fN27dphH2gA+EByuZzL5T58+DA5OdnLy8vY2Hjx4sWPHj2KjIw0MDBYsmSJsbHxypUrlUrls2fPLCwscNlIAGAKKjUQIBaLjxw5UlRUtHz58tevX69evdrV1XXWrFkKhYLD4ZBOpym2b98+fPhwW1tb0kEAGsmNGzdevnw5YsQIuVw+derUsrKyU6dOSSSS4OBgBweHJUuWyOXyZ8+eWVlZoWoDwMdCpYYGl5mZaWdnJ5PJFi9eXFVVtXfv3hcvXpw9e9bV1dXDw4N0Og31888/f/755x06dCAdBIAwpVJ5+/btwsJCPz8/mUw2e/bs8vLy48eP039ltWzZcvny5RRFPXjwwMLCwszMjHReAGiiUKmBeS9evHj48GGfPn1EIpGvry+fz6f/fXr48KGLiwuW7QJA06dSqW7fvv3q1ashQ4bQZx3k5eWdOnVKW1v7q6++opeRCASCZ8+emZqaNtn9OgGg0aBSAzMSEhKuXbs2ZswYOzu7r776SigUBgcHC4VC7CbR1ERFRRkYGHh6epIOAqCu7t69m52d7e3traOj89VXXz158iQyMlJXV3fRokWmpqa1a7Wtra0NDHCpIABNgUoNn6KyslJHR+fw4cPnz59fsGBB165dQ0NDdXR0/P39sV9sU3bnzh2FQoH1NgAN4datWzk5ObVrtcvLy0+ePFlaWrp27do2bdrMmTNHJpNlZmba2NjggpEAzQ8qNXyQ1NRUAwMDExOT77777tSpUwcOHGjbtm18fLyxsbGLiwvpdPBBampqFAoFvjQAaEwKheLGjRulpaV+fn4lJSVffvklRVGHDx9++fLltm3bOnbs+MUXX1RWVubn51tZWWGDIwD1hUoN71ZaWnrr1i1ra2sXF5fg4OCsrKwffvjBzs4uIyPD1taWzWaTDggfJz4+/uTJk9u3bycdBAAoemvthISEyspKX1/fvLy8+fNLairwAAAgAElEQVTnC4XC0NDQ7OzskJAQV1fXkSNHSiSS0tJSKysr0mEBoG6o1PBfL168+OuvvxwcHHx8fPbu3ZuWljZt2jQHBwd6q1fS6eDTFRUV3bhxw8/Pj3QQAKiDTCaLjY2trq4eMmRIVlbWvHnzDAwMDhw4kJGRcejQoS5duvj6+lZWVkqlUuz0B9CkoFJrLvryY8+fPw8JCXFycpo5c+bly5czMzMHDRpkaWlJOh0AAPyXWCy+dOmSQqEYMWJEWlra7Nmz7e3tQ0JCsrKyIiMjO3fu7OXlJZPJWCwWVo8AEIFKrVlyc3OtrKwSExPXrFnTsWPHr7/+OjEx8dWrV25ubtjbrrmaMGHCnj17sIQaoJmhp0XKy8vPnDnDYrHGjh2blJQ0ZcqU7t27b9u2LSMjIzo6ulOnTj179qRfSTovQDOHSt3MFRUVZWdnu7q60n/VDhs2bOnSpXl5eVKp1MHBgXQ6aHChoaGDBg0yNzcnHQQAGkl5ebm+vn5xcfGJEye0tLQmTZr04MGDWbNmDR48eM2aNRkZGdevX+/UqVP79u1VKhWLxSKdF6CZQKVuhhITEzMzM318fFJTU+fMmRMQEDB37tzy8nIej4cvBAEANFBNTU1RUZG5uXl+fn5YWJhIJJo6dWp8fPzGjRsDAgJmzZqVnp7+/Pnz9u3bW1tbkw4LoJZQqZsDlUoVHx+fmppKX99r6dKl/fr1mzp1ak1NjZaWFul0QEZkZOSrV6/mzp1LOggANF0FBQUSicTe3j41NXXfvn0ODg5Tp049e/bswYMHAwMDhw4dmpqaWlxc3LZtWz09PdJhAZo0VGo19tdff925c2f9+vUymWzlypXdunULDAwkHQqahKysrCtXrgQFBZEOAgDqRy6XZ2RkUBTVunXrW7duhYaG9u7de/z48YcOHbp582ZQUJCbm1tqaiqHw8GeqgC1UKnVzMmTJ2NjY9euXWtkZLRly5Z27dr5+vqSDgUAAM1faWlpYmKiiYlJ69atT5w4ERYWNnz48HHjxkVFRT169Mjf379z587FxcUCgQCX0QUNxFm3bh3pDPCv5HI5m82OiorasmWLk5OTqanpvXv3evbs6eTkxGKxevXq5eTkRDojNDmbN2+2srIyMDAgHQQAmhU+n29jY0Pvh922bdvRo0d36NCBoig9PT25XK6jo2NlZXXp0qWZM2eyWCxXV9cbN25cunRJV1fX2NiY/ueM9CcAaECYpW5yZDIZn8+PiYnZu3fv1KlTvby8zp8/b2Zm1rlzZ9LRQA3s3LlTKBROmjSJdBAA0FwSiUQoFKampkZHRzs4OAwePDg8PHzPnj2zZs0aMWLEgwcPXr9+7erqamJiQjopAGNQqZsEqVQqEAguX77822+/TZgwYdiwYXfv3tXV1W3Tpg3paAAAAAwoLi6urq42Nze/e/duRESEu7v7iBEj/vzzz+vXr0+fPt3DwyMpKYnNZrdq1YrD4ZAOC/DRUKmJoX+Jv3bt2rZt20aNGjV27NjHjx/r6enZ2dmRjgbqKjw8fNSoUfh2FQDUhUQief78uUgkcnBwOH78eGRk5LRp07y8vH799deKiorp06ebmJi8fPnSwsICW2hDE4dK3ajo2ehHjx6tX7/e29t7+vTpycnJfD7f1taWdDRQeytXrvT09PT29iYdBACgvpKTkx8/ftyrVy8LC4s5c+bcvn07Li5OKBRu27bN1tZ2+PDhaNjQ1KBSNzi5XM7lcrOzs1esWNGmTRv64lUURdnb25OOBs2HWCwWi8W4SiIANFdKpZLNZh8+fDgrK2v58uVsNvvzzz+3sLDYv38/l8u9cOGCjY1N27ZtSccEzYVK3YAqKyvnzZsnl8v379+fn59fWlrq7OxMOhQ0T2lpaa1atSKdAgCg8chksszMTCcnJzab/fXXX2dkZBw6dKi6unrhwoVt27adN2+eTCYrLS3FXAM0DlRqJtFXK/zhhx/OnDkTGxtbXV2dnJyMnTqgoa1bt65r167+/v6kgwAAkHfr1q38/PyAgIDXr18HBQWZm5vv3bs3Ly/v9OnTHTt27N69O+mADUupVFZVVZFOQZ62tnYjn+eKSl1fKpWKxWLt27cvKirqxx9/dHR0vHnzZseOHXV0dEhHA42Qk5Nz69atESNGkA4CANAU0bNdFRUVYWFhlZWVixYtyszMXLBgQY8ePZYvX15WVpadne3o6NhsLk9TU1NTUlJCOgV5QqFQKBQ25hFRqT9dTEzM8ePH58+f7+zsfPHiRWdnZxsbG9KhAAAAoA45OTn03tj5+fnLly/X0dHZuXPn06dPz5496+np6eHhUVVVxePxSMf8FKjUNFTqpi4lJeXkyZPe3t6dOnU6evSovb29h4cH6VCgua5evVpcXBwQEEA6CACA2isrK4uOjhYIBEOGDImKivr111+DgoLGjx+fmZlZVFTk7OzcyBXt06BS01Cpm6Lq6uoLFy4YGhr26tUrNDRUIBAEBATw+XzSuQAoNze3O3fukE4BANAMFRcXV1RU2NraPn78+JdffnF0dAwODr5582Z8fPyAAQNcXV3pJSWkY74NlZqGSt2EZGZmZmVleXp6HjlyJCkpafr06dbW1qRDAfyXWCxms9lYtQ8A0GgKCwtjYmIMDAy8vb3Dw8MPHDiwaNGi/v37P378mM/nt27dmnRAVOr/QKUm7/nz505OTmlpacHBwTNmzMCFM6BpksvlOTk5uNYmAABB+fn5crnc2tr6+PHjERERkyZN8vHxiYqKKisrGzhwIJH9+xq0Up8+fTolJWXx4sVMDfj999+7u7sPGDCAqQFrNX6lxoWL/0MqlVIUNWvWrO+//56iKBsbm+PHj6NPQ5P1ww8/3Lt3j3QKAACNZm5uTn+DPWLEiKNHj/r4+FAU5eDgUFJS8vz5c4qifvrpp9mzZyclJVEU9fLlS9J56ys1NZXZAVNSUpgdkCDMUlMnTpzYs2fPzp077ezsXr9+bWpqSjoRQB3EYvGff/45f/580kEAAOB9pFLp48ePW7RoYWdnt3nz5oiIiGPHjtnb258+fdre3r59+/aMH/GtWeolS5YIBIINGzbUPrJmzRqxWLxt2za5XH706NH4+PiCggITE5Nhw4b5+vrWDnL48OGYmBixWNyqVaspU6a0a9du2bJljx8/pl/wyy+/tGrV6unTp6GhoXTPdnZ2DgoKatOmDT33zGKxrK2tT5w4sXz5cg8Pj+jo6KioqPz8fB6P1759+5kzZ5qamg4ePJgeTSgURkREVFdXHzhwID4+vrS01MjI6LPPPpswYQKXy6UoauzYsWPGjLl3797Dhw/DwsKEQmFsbOzJkyezs7MFAoGnp+ekSZPeOskNs9SNpLi4+Ndff42JiaEoytDQcN++ffQX6OjToBZ0dXXRpwEAmj6BQNCtWze6YwQHB9+6dcvCwoK+5O2WLVtycnIoitq5c2d4eLhMJmuIAH379n306JFEIqHvSiSSBw8eeHp6UhS1d+/eEydOjB49eufOncOGDQsJCYmOjqZftmfPnvPnz0+fPn3z5s2WlparV6/Oy8tbs2aNo6MjfY6ZnZ1dTk7OqlWrTExMtm3btm3bNj6fv3LlytevX1MUxeVyMzMz09LS1q9f7+zs/OTJkx07dgQEBOzcuXPdunXl5eUbN26kKOrAgQP0AoG9e/fSP4eLFy9OnTo1JCRk0qRJp0+f/vPPP+k8HA7n3LlzdnZ2mzZt4vF4N27c2Lx5s6ur62+//bZo0aKEhIRffvmlIX56H0WzKnVhYeGVK1coioqLixMKhT169KAoql+/fmZmZqSjAXwouVxO/2UEAADqhc1m05OpCxcu3L9/P71oxMXFJSsrq7S0lKKoOXPmrF+/XqFQyOVyRo7Yp08fhULxzz//0Hdv3LihVCr79u0rkUjOnj07fPjw/v37W1pa+vr6enl5RUREUBRVWVl5/vz5sWPH9u3bt3Xr1vPmzevatWteXp5QKORwOFpaWiKRiMPhnD17ViAQLFmyxN7e3t7ePjg4WKFQ0JOVFEXl5eUtXry4Q4cOIpEoKyuLx+P179/fwsLC2dl5xYoVM2bMoChKT0+P/q1DX1+/rKwsJiZm7Nixnp6eFhYW/fr1GzJkyLlz52pqaiiKYrFYPB5vypQpbdu25XK5x44d69ChQ1BQkKWlpbu7++TJk69cuUK3eYI0qFKnpaWNHz++srKSoqhhw4ZNnjwZWyWAOjp48CD91xAAADQDnp6ewcHB9LmMwcHBnTp1UqlUYrHYw8Pj66+/plePfPI6bCMjow4dOly/fp2+m5CQ0LlzZ0NDw/T0dLlc3qVLl9pXduzYMS8vTyqVZmVlVVdXOzk50Y9raWmtWrXqzVfSUlNTW7VqRS/MoJuxlZVVeno6fdfKykpfX792ZBaLtXTp0ujo6Pz8fENDQ2dn57dGy8jIUCgUbz7u5ORUVVWVm5tL323bti19Q6lUpqamurq61r6yQ4cO9Aif9iNiCpfs4RuaSqXauHHjw4cPw8PDzczMzp8/TzoRQH25u7v/719GAADQDNjZ2dGrRAwMDBISEtLS0iiKqqqqmjlzpoGBwcGDB8vKytLT0zt37sxisT5wzD59+uzZs6eqqkqhUNy/f//LL7+kp6Ipilq+fHntOPTJdSUlJRUVFRRF1XnxyMrKSiMjozcf0dHRoYellzLXPm5jY7N169aIiIh9+/ZVVFS0adNm5syZb/1DRu8S8eZl4enbtethaqdB6Q9y+PDhI0eOvDlCcXHxB/5AGkjzrNQqler48eO9e/c2NjZu06ZNcHAwvfyUdC4ABjTE6SwAANDUcLlc+mw/AwOD06dP0ytDlErlb7/9xuVyd+3a9ezZs9evX3t4eLz/8nO9evX6/fff79+/T9dTetUrXXmXLl361masJiYmdKWmO+57CIXC2iXaNIlE8lbJrlW7MuTp06cHDhz45ptv9u/f/+YL6Mb85kHpdv6/Cwp4PB6Xyx0yZMhb27IZGBi8P3BDa24LP8rKyiiK2rRpU0pKirGxsZaW1ogRI2q/lQBQd+vXr69dEgcAAJqDroyGhoZ79uzZtWsXXS6joqJCQ0Mpirp79250dLRYLH7nGzt16nT79u2bN2+6u7vTZdre3l5LS6u0tNTm/9PT09PX19fW1ra2tubz+bWbeyiVyuDg4EuXLtF3a3eKa926dWpqKr3Wmd6KKicnp3a5yJuSkpISExPpsww7duw4ceLEsrKy2m1J6AHt7e05HM6zZ89q35WYmCgUCi0tLd8ajc1mt2rVqqCgoDa5ubk5l8slviSSs27dOrIJmJKbmxscHCwQCJycnPr06dOnTx8Oh0M6FACTSktLN2/evGLFCtJBAACAPCMjI29vbzc3N3p+NyoqKjs729XVtby8XC6XvzmfWFNTc/HixaysrMDAwJYtW1IUpa2tXVZWdvr0aVNTUx6Pl56evmXLlkePHn322Wfa2trFxcV//fWXiYkJvcTi/v37QUFBenp6CQkJubm5zs7OHA7H3t7+r7/+ys3NtbW1pTdSq6iomDdvHp/PT0hIkEgkAwcOpI9+/vz53bt3m5uba2lpFRQUREZG1tTUjBs3jsvlRkZGCgSCFi1amJqaFhcXR0dHW1lZ0Xt6hIWFDRs2rHPnzhRFnTx50sHBgb5Nn9cYFhZGnyj5+vXr3bt3Hzp0yMfH583rw2tra2trazfmH0dz2Jc6Njb2s88+S0hI0NbWdnd3Jx0HoKHI5XKVSvXmXxkAAABvqqmpef36tVQq5fF42traMpmMw+HIZLLx48fzeLzDhw/XFk25XH7kyJGYmJji4mJDQ0MPD49JkybRc9hVVVWhoaFxcXEymczW1nby5MkdO3akKOqff/7ZunVrVVXV6tWru3bt+vTp03379qWmprLZbBcXl6lTp9LLSDZv3lxQUPDjjz/WHujQoUNxcXFFRUVCobBt27ZBQUF0sw8LC4uMjNTW1t6zZw+Px9u/f39sbGxZWZmJicmgQYNGjx5NL/WeOHFi//79J02aVPsxr1y5EhERkZOTQw84efJkGxubN38OuCD5R/P09JwxY8b48eNJBwFocGKxmM/nYyETAAD8m7cu9VJVVVVVVSUQCLS0tKqqqrhcroZ8h49LvXwQlUr1+++/06fBnj9/Hn0aNEFJScnQoUPRpwEA4MPxeDx9fX36602VSlVeXq5SqVQqVXV1NelozY1aVurVq1draWm1atWKoqj3n+UK0Gw8evRo7NixpFMAAIC64vP5hoaGLBaLxWLJZDJ61zl1X63QdKjTwo9Dhw69fPmS3hEPAAAAAN7y1sKPOqlUquLiYoFA0Myuf4eFH+9WVVVVWFj4+vXrpUuXks4CQMbNmzfV6BdgAABQCywWy9jYmD5nUSqVlpeXKxQK0qHUUlOv1Pn5+VOnTq2pqTEyMlq0aNGHXysIoDl59OhRSEgI/vsHAICGQJ+oIxAI+Hw+XamrqqrkcjnpXOqkqVfqY8eOzZs3T1dXl81u6lEBGk5JSQkWUgMAQEOr3c6Zw+FIJBLMWH+4JrqW+vLlyzExMd999x3pIAAAAABqQ6lUMji7rFAoOBzOsmXL3N3dR44cydSwjYDD4TTydoFNdEOuc+fObdy4kXQKgKYiOjq6f//+2EEPAADej81mM37VwO3bt586dUpbW/vJkydcLtfZ2ZnZ8ZuHpjVLfePGjerqak9PT9JBAJqQ7OzsBQsWnDx5knQQAADQaIWFhQsWLBg1atTQoUNJZ2lymtAC5dTU1MOHD6NPA7ylvLz8zauwAgAAEGFiYnL48GH64uT79u2rqqoinagJaRKz1NXV1RUVFVKp1NramnQWAAAAAKhDQkLC0qVLr169qiFXOK8T+VnqnJwcT09PkUiEPg3wTrdu3SosLCSdAgAA4L969ep1/fp1lUp169Yt0lmaBPKVOi4u7saNGzjvCuDfrF27til8mwQAAPAWLpfr6Ojo4eEhkUhIZyGMZKUODw+nKGr8+PEEMwA0cTKZzN/f39TUlHQQAACAdzA2Nk5ISHjx4gXpIIQRW0sdHR1dWloaGBhI5OgAAAAAwKDLly+3a9fO3NycdBAyiM1Sm5qaok8D1CklJSU+Pp50CgAAgDp8/vnngYGBFRUVpIOQQaBSnz59+u7du127dm38QwOonZiYmOTkZNIpAAAA6nb58mWNPfmnsU8KjIqK0tXVRZ8G+EBt2rTBZjgAAKAW2Gx2ZWWlSqUSiUSkszS2JrEvNQAAAAA0AxcvXoyJidm0aRPpII2t8RZ+JCYm/vHHH412OIDm4dChQ2KxmHQKAACAD9KnTx8dHR3SKQhopFnq0tLSGTNmHDt2rBGOBdCceHh4JCQkYON2AACApqyRZqkNDAzQpwE+lkwmmz9/Pvo0AACokevXr8tkMtIpGltjzFL/888/QqGwXbt2DX0gAAAAACDL398/JCTE0tKSdJBG1eCV+unTpz/88MOBAwca9CgAzVJubu6DBw98fX1JBwEAAKjDyJEjeTweh8PJy8szNDTU0tLicDg8Hm/37t2kozWGBv9C2djY+M8//2zoowA0S0+fPr127RoqNQAANH0ZGRksFou+XVJSQt+YPXs20VCNp2HXUpeXl2tra2MlKMCnsbS0HDx4MOkUAAAAdevRo4dSqXzzERsbm3HjxpFL1KgatlL7+fnxeLwGPQRAM9a+ffs+ffqQTgEAAFC3KVOmGBgYvPmIn5+fQCAgl6hRNWCljouLW758uVAobLhDADRvt2/ffvbsGekUAAAAdevSpYuLi0vtSXotW7YcP3486VCNpwErtaenJ76zBqiPv//+Oy0tjXQKAACADzJlyhRjY2OKojgcztChQ/l8PulEjaehKvXz589jY2MbaHAADdGtWzcXFxfSKQAAAD6Iq6tr+/btKYqytrYeNWoU6TiNqqFOHNy8efPcuXMbaHAADYHveQAAoP5qqpSySuUHvJABY0YEPX/2IsB3tFymVSGTN8IR2RxKqE9+J4wG2ZdaKpU+ePCgR48ejI8MoFGio6Pd3NxMTExIBwEAALX0+FrZg/jSGpmSzWGRztJQRCZaJa+q27jr9fIn+c9lY1w9EQA+zZgxY7777jtHR0fSQQAAQP0knC6UlCvb9zTUM9IinaVhVVbIX6ZVptwtG7nAmtQvDw2ylnrdunU4pwqg/gYMGGBqako6BQAAqJ/4k4U11VQPvxbNvk9TFKWjx3XsrN/R0zjipxxSGZifpRaLxb6+vnFxccwOCwAAAAAfIj9L+iCuvFeAGekgje3x1WJ9Q077XqLGPzTzs9RsNjsyMpLxYQE00KlTp2pqakinAAAANVP4sprNbraLp99DR5/7MkNG5NDMV2odHR18VQ3AiM2bN791cVcAAIA6VVYojK00aE/oWobmPKWCzFmCzFfq5cuXP3r0iPFhATSQn58fj8cjnQIAANRMVaVSXq2JMzJKBVX6msy3u8xX6lu3btnZ2TE+LIAGWrlyJekIAAAAUDeGK7VKpTp37py+vj6zwwJoILlcfubMGdIpAAAAoG4MV2oWi6VR13MHaDgymWzLli2kUwAAAEDdGK7UFy9eXL9+PbNjAmgmDofj6+tLOgUAAADUjeFKnZeXJxIR2AsQoPkRCATBwcGkUwAAAEDduMwON2bMGBZLE/dBBGBcVVVVXFzcwIEDSQcBAACAOjA8S83j8bS1tZkdE0AzVVRUbN26lXQKAAAAqBvDlXrdunXXrl1jdkwAzcTj8by9vUmnAAAAgLoxXKkLCws5HA6zYwJoJj09vcWLF5NOAQAAAHVjuFJ/99137u7uzI4JoJkqKysvXLhAOgUAAADUjeFKLRKJuFyGT3kE0ExlZWU7duwgnQIAAADqxnClnjlzZlpaGrNjAmgmHR0dHx8f0ikAAAA+QsAwrwMH95BOQQDDlbq0tFSlUjE7JoBmEolEc+fOJZ0CAADg/8jISAsc5/dvz86Ztah7996Nm6hJYLhS//nnnw4ODsyOCaCZJBJJVFQU6RQAAAD/x/Pnie951tvbz6m1cyPGaSoYrtRCoZDNZnhMAM1UXl6+e/du0ikAAEAjDB3eP/J42LIV8wcO6iEWiymKirl8ftbsiT6+vYePHPjrb1tlMhlFUaH7QzZtXvfqVX4/L7fI42EnTx0bNmJAQkLcsBEDft/101sLP56nJAUv+zJgmJevf9+v13yVn59HUdQ/d27283J79uxx7aGfJT7p5+X2z52b//YWtcBw/Q0KCkpPT2d2TADNpKurO3LkSNIpAABAI3C53NNnTjjYO27fGsLn869di93w3aquXT12/3EkeOna+KsxW7d/R1FU4JhJw4cHtmhhdurEJX+/EVpaWjKZ9MTJo8uC1wUEjHpzwFev8hcvmclis7dvDdn6467yirIlS2dXV1d3cXU3MDC8eu1K7Svj42MMDAy7uLr/21tI/Dw+GsOVWiqVKpVKZscE0Ex6enpBQUGkUwAAgEZgsVh8Hn/mjPkuLh25XG7Y0dBOnbpMn/altZVNd49e06fNu3TpXEHBKz6fz9PmsVgskciAx+OxWCyZTDZyxLjuHr0sLazeHPCv05EsFmv1qu8cHByd27RbufzbvLzcuPgYDofj2dfrzUp99erlfp8N4HA473xLwvU4Ej+Pj4a11ABNFNZSAwBAY3Jx6UjfUCqVz58nunXtXvtU505dKYpKT0955xvbtevwvw8mJj5xbuOip6tH3zUzM7ewsEpNTaYo6jPPAbm5LzIy0uiVHi/zcr0+H/Rvb8nISG2Az8o8hveQFgqFzA4IoLHotdQBAQGkgwAAgEYQCnXpGzKZTKFQhO4POXDw/5zSU1Rc+P43vkkiEaekJg8c1KP2kZqaGnqEjh1djY1Nrl67Ym/fKj4+xtzMgm7z73xLcXERcx+xATFcqRcsWLBkyZKWLVsyOyyABsK+1AAAQASfz+dyucOHBfoOHvrm4waGRh8+iFCo26FD5yWLVr35oECgQ1EUm8329Ox/7dqVLyZOi796+fPPvd/zFh0d9ZiuZbhS5+fnq8sqcoAmDvtSAwAAEWw2u3Vr51ev8lq2tKMfqampKXj9Sl9P/8MHadu2/fkLZywtrWuvq/3iRZaxsQl9u5/ngBMnjt69d/vFiyx61ce/vcXIyJjRD9dQGF5LvXHjRhsbG2bHBNBMUqn00qVLpFMAAIAmChzzRfzVy2FHQl+8yEpJTf5+49fzF0yVSCQURenq6hUVFT56dP/9O9z5+42QSit/2LwuJTU5Jyf7wME9k6eOTkp6Sj/r4tLRzMz8913bHRwcHRwc3/OW5Pdug910MFypHRwceDwes2MCaKbS0tKffvqJdAoAANBEfft8vnLFtzGXo6dMG7M0eG6NvGb71hD6lDmvzwdZWlovWTr7XPT7zqE3N7fYtjWkuLho/oKps+ZMvP3P9Q3fbqs9kZHFYnn27Z+WllI7Rf1vb2nr7NLwH5cBLGavH7527doZM2ZYWVl9wGsB4H1KS0tDQ0MXLlxIOggAAKiZq6cKtQXcdt0NSAdpbIUvq26dLQj8isCKCYZnqZOSkqRSKbNjAmgmAwMD9GkAAAC1wHClXr16NaaoARhRWVl54cIF0ikAAACgbgxX6g4dOggEAmbHBNBMZWVlO3bsIJ0CAAAA6sb8jh95ee87/RMAPpBQKMR1XgAAANQCw5X6wYMH9AYrAFBP+vr606dPJ50CAAAA6sZwpV62bJmFhQWzYwJoJrFYHB4eTjoFAAAA1I3hSt2lSxd6z0IAqKeKioqDBw+STgEAAAB1w1pqgCZKR0fHx8eHdAoAAACoG9ZSAzRRIpFo7ty5pFMAAABA3bAvNUATJZVKY2NjSacAAACAumFfaoAmqrS09McffySdAgAA1I9YLCYdQeMwXKnXrl2bm5vL7JgAmkkgEPTt25d0CgAAUCeXL1+ePXv2zbahXSQAACAASURBVJs3SQfROFxmh0tKSpJKpcyOCaCZDAwMgoODSacAAAA1UFxcHBkZGRER0blz58mTJ1e9dCCdSOMwXKl/+OEH7EsNwAipVHrr1q3PPvuMdBAAAGi6bt++HRkZef/+/ZEjR4aHhxsZGVEU9c+FErYWi3Q0AtgsyrCFFpFDM1yp7ezsmB0QQGPRa6lRqQEA4H/V1NRERERERkaamZmNHDly8+bNbz4rFHGyk6VOXUTkApJRnF/F4ZL5XYLhtdRffvllVlYWs2MCaCYdHR1vb2/SKQAAoGlJTExcv359nz598vLytm/f/vvvv3t5eb31mhY2PJVCRSggSZLyGitHPpFDMzxL/fr165qaGmbHBNBMIpFo3rx5pFMAAEBTcebMmQsXLhQXF48aNWrNmjXveaWJJc/IQvv66Vc9/c0aMSBhKQ/KX7+Q9R5CZjdnlkrF5C8xEolEIBCw2QxPfgNoILFYHB0dPXLkSNJBAACApNzc3IiIiIiIiP79+48ZM6Zdu3Yf+MYHsaUvUqUuPQ2NLXhsdnNeWl1SUJWfXpmfKfWfYcFikfmkDFdqAGBKXl7e9OnTz5w5QzoIAACQcfXq1WvXrt24cWPUqFGjRo3i8z96SUPK/YoHcaWlr2tUyoaJWG81cjmXy2FRn96DDcy05VVKp666bv2NGI32cRiu1OPGjfv2229btWrF4JgAmqmsrOzQoUO4JjkAgKaRyWQRERHh4eGOjo7jxo3r1q1bfUdUUVWyptip8/LyFixYoFKpAgICJkyY8GmDcLRYXEKnJL6J4bXUCoUC094AjBCJROjTAAAaJSkp6dixY+fPnx81atTu3bsZ25iYRfEETXFRrpGJHosjz83J2btv1/WbcYsXL3ZxcSEd6hMxPEstk8m0tbWxlhqg/mQy2d27d3v16kU6CAAANLiLFy8ePXpUJpONHj06ICCAdJzG4+/vn5eXR1GUUqm0tLT08fFR0+kkrKUGaKKwlhoAoNmTSqVHjx49cuRIly5dAgMDO3fuTDpRYxs/fnxycnLtXT6fb2tre/jwYaKhPgXD08nTpk3LzMxkdkwAzcTn87t37046BQAANIjnz5+vX79+wIABEonkyJEjmzZt0sA+TVGUrq7um3dlMllSUtKwYcPIJfpEDK+lrqiokMvlzI4JoJkMDQ1Xr15NOgUAADDs6tWrhw4dKi8vDwwMfP/20pqAx+OpVKrane/09PSuXLlCOtSnYLhSh4SEvPXbBgB8GqylBgBoZk6cOHHo0KGWLVtOnz7dzc2NdJwmQU9Pj67UPB6va9euO3bsIJ3oEzG88MPAwIDLZbimA2imkpKSjRs3kk4BAAD1JRaLd+3a1bt378TExO3bt//000/o07VMTU3ZbLa1tXVCQkKnTp127txJOtEnYvj0xDlz5gQHB9vZ2TE4JoBmwr7UAADqLicn59SpUxERERMmTJgwYYJAICCdqKkbM2bMzp07jY2NSQf5aAzPKBcVFWEtNQAjsC81AID6SkpK2rdvX1JS0syZM+Pi4kjHURvTpk3bvn37hg0bSAf5aAzPUhcVFYlEIqz9AKg/sVh88eJFdTzrGQBAk925c+fPP/8sKyubPHly//79ScdRP+PHj//666+dnZ1JB/k42JcaoInCvtQAAOrl2rVru3fv5vP5U6ZM8fDwIB1HXV27di0iIuLnn38mHeTjMHx64pw5c7AvNQAjBAJB7969SacAAIC6XblyJTAw8MaNG0uXLg0JCUGfro/evXtzOJw3r/+iFrCWGqCJMjAwWL58OekUAADwPleuXAkJCbG2tv72229bt25NOk4z4ePjs2/fvk2bNpEO8hEYXvhRWlqqq6uLtdQA9VdVVfXkyZOuXbuSDgIAAO9QW6ZnzpyJMs24adOmffvttxYWFqSDfCispQZoorCWGgCgabp582ZUVFRNTQ3KdMM5cOBASUnJggULSAf5UAyvpZ42bRrWUgMwgs/nd+vWjXQKAAD4r9TU1Llz5x48eHDq1Kk//vgj+nTDGTZs2MmTJ0mn+AgMr9CoqKjAWmoARhgaGq5Zs4Z0CgAAoOilrdu3b09KSlq0aFH37t1Jx2n+9PT0Bg4ceOXKlX79+pHO8kEYnqXes2ePvb09s2MCaKbKysoLFy6QTgEAANSvv/46YsQId3f38PBw9OlG06tXr9OnT5NO8aEYrtR6enocDofZMQE0U1lZWWRkJOkUAAAaLTY21tPTUygUxsTE+Pn5kY6jWTw9PW/evFlVVUU6yAdhuFJPmjQpIyOD2TEBNJOOjk6nTp1IpwAA0FAVFRWLFy8+ffr02bNnJ0+eTDqOhhowYMDFixdJp/ggDFdqmUymUCiYHRNAM4lEorlz55JOAQCgicLCwvz9/QMCArZu3aqrq0s6juYaOHDg3bt3Saf4IAxvoldTU8PlclksFoNjAmgmmUz2+PFjd3d30kEAADRIYWHhTz/9ZGhouOT/sXffUVEdbx/AZytLr0qXLkhHLFgQFRXBFoMVxR6NvbeIFTtibxCMGhV7l1gCVowNlSqCgCJIkbb07fv+cZP98aogwoXZ8nxOTs6yu3f2C+rcYe5zZxYvxp0FIB6P5+Xl9eTJE9xBvo/kWWoGgwHjaQBIUVZWtn79etwpAABAgURFRY0bN27SpEkwnpYSTCbT0dHx1atXuIN8H8lD6lWrVmVmZpLbJgCKSUlJCbZOBACAVrNhw4bMzMzbt29bW1vjzgL+x8PD4+nTp7hTfB/JQ+qMjAzYjhEAUujo6MAsNQAAtI758+e7uLjMmzcPdxDwJXd3d5kopya5llooFMIiegCQora29vHjx/369cMdBAAA5BmHw/H29j5x4oSlpSXuLOAb+Hy+p6en9E9UkzxLDeNpAMjCZrN3796NOwUAAMgzDoczf/78mJgYGE9LLQaDYWFhkZ6ejjvId5A8pA4ICIBaagBIoaKi4uPjgzsFAADIrYqKip9//jksLIzFYuHOAhri4OCQkpKCO8V30MltTigUQi01AKTQ1NScO3cu7hQAACC3+vbtGxcXhzsF+D5nZ+fs7GzcKb6D5FnqyMhIuE8WAFJwuVyZuCEDAABk0eLFi69du4Y7BWgUQ0ND6Z+lhlpqAKRUaWnp2rVrcacAAAA5FBoa6uPjY2RkhDsIaJR27dp9/PgRd4rvgFpqAKSUsrJyr169cKcAAAB5c+/evfz8/AEDBuAOAhpLX1+/vLycw+HgDtIQkofUUEsNAFm0tLSWLVuGOwUAAMib/fv3r1u3DncK8GMcHR1zcnJwp2gI1FIDIKWqq6tv3LiBOwUAAMiVCxcuDB06VE1NDXcQ8GPU1NQ+ffqEO0VDoJYaAClVUVFx+PBh3CkAAECuxMbGDhkyBHcK8MPatm37+fNn3CkaArXUAEgpFovVpUsX3CkAAEB+xMXFaWlp6ejo4A4CfpjCDamhlhoAsmhra69ZswZ3CgAAkB8vXrxwdnbGnQI0hcINqaGWGgCyVFVVXb58GXcKAACQH1lZWe3bt8edAjSFvr5+ZWUl7hQNgVpqAKRUZWXlkSNHcKcAAAD5wWazTU1NcacATaGlpZWXl4c7RUOglhoAKcVisTw8PHCnAAAAOSESiSgUiqamJu4goCk0NDQqKipwp2gI1FIDIKW0tbWDgoJwpwAAADkhEAhwRwBNJ/1Dagq5I2ChUAi1HwA0x/bt28+cOUOlUkUiUd3/v3r1Cnc0AACQPUePHj18+DAx5UehUIj/Q6cqi7p16/bgwQMmk4k7yLdBLTUA0iUwMNDCwgIhRKVSif+LxeKOHTvizgUAADJp1KhRJiYmCCEKhSL5v5WVFe5c4IdJ+UQ11FIDIF0MDQ179epV9xktLa0JEybgSwQAADJMVVV1yJAhdaf8mEzmuHHjsIYCTeHo6CjNi35ALTUAUmfkyJHm5ubEY7FYbGlp+cUgGwAAQOONHDmyXbt2ki9NTEx++uknrIlAUxQXF1dXV+NOUS9YlxoAqWNkZOTp6UlcndTS0goMDMSdCAAAZJiqquqgQYOIajolJaWAgADciUBTKCsr19bW4k5RL6ilBkAajRo1yszMDCEEU9QAANB8kqt/RkZGMEUto1RUVGpqanCnqBfUUgMgjQwNDT09PVVVVcePH487CwAAyDxioprJZI4dOxZ3FtBEUj5LTSe3OailBjJBKBD/c6PkU0YtlYbYn/m443wbCw0e1cU37RY97VYW7izf1rYdS8gXmXVQ6dRfB3cWAEBzPbtVkpNWS6NTinK5uLO0CDHyHNfDo/gFI/yFlHaqzST3fbKGhgaXK71/OWFdaqBwKssEJzZ98PxZX12boamnJBLBL4FNV1rALS/mvXnCDvytHYVKwR0HANAUQoH42PoPbt66GroMbX0lBJ2izJLvPnnHjh3GxsZSe52B5FlqGE8DKVdewr+8/1Pg6ro30cpbp9OaDMyVDcyVNXUZf27KnrjaHHccAEBTRARlDZ5hqqEjpTtogMaT7z6ZyWTyeDzcKeoFtdRAsTy+WtxvvBHuFPLGwELFsaf2s1sluIMAAH7Yo6vF3Yfpw3hanshrn8xgMPh8Ka3VhHWpgWLh1Ahz39Vq6sGZg3y6hqysJOldLhQAUJ/M+Co9YyXcKQDJ5LJPlvJZapILPyIjI6H2A0it0gKeuaMa7hTySddQicmiITHU0QAgS7g1Qq22TDVNBu4ggGRy2SczmUwF2j0RxtNAmokEqKpUeq8ZybqCD7VwqycAskUsphTncnCnAC1C/vpkNTU1JSXpvaICtdQAAAAAAEDaCYVCNpuNO0W9oJYaAAAAAABIOyqVKhKJcKeoF9RSAwAAAAAAaUej0YRCIe4U9YJaagAAAAAAIO0Ua0gNtdQAAAAAAIB0Ul74AbXUAAAAAABA2ikpKamoqOBOUS+opQYAAAAAANJOKBRWVFTgTlEvqKUGAAAAAADSTrEKP6CWGgAAAAAAkI5CoUhzdTHUUgMAAAAAANAsUEsNAAAAAACknWIVfsB4GgAAAAAAkI5KpdLpJM8FkwhqqQFoKVlZGX28OyUlxeMO8n1Rf13p491JIBDgDgIAUETl5ew+3p3uP4gmq8H7D6L7eHcqL2eT1SCQBmKxmM/n405RL6ilBgAAAADA7/KVc1u3r8OdAjQR1FIDAAAAAOCXnp6KOwJoOpKH1DCeBvLk2PGwxMTXO0MPE19OmORfWVlx+eLfxJcbglfW1NZs3byHzS47eHhXQsLL8nK2paXNL9PmuLl2kjRSWlayctWC+Pg4JlPJd+DQ6b/MpVIbujokEAh+j9h//8HfZWWlWlraXr36Tf9lLoPBQAilv3sbEbE/LT1VIOB3dOsye9ZiAwND4qjomFvnzp3I/fSRwWA6ODjPnrXY2MgEIbRu/XIKhdKunfm58yfXBG3p1s0zNTX5UNju9PRUDQ3Nvn18pkyeyWQyiUZycz/u2LmReGna1NkDfYa01E8WACDLrt+4dCryj7KyUvsOTgsXrJw4ecSa1Vv69O7/dYfzNu1NRMT+dxlpPB7X3Mxy6tTZndy7Eo1cu37xVOQfbHaZjY3dtCmz67bfQF9XH4FAcOBgaHT0TZFY1M3D082tc91Xo/66cu78yby8XGVlla5dus/8daGOji5CiM/nHzsedufvqKqqSmtr2xm/zHN0dEEI+Q7qOWnijNGjAonDQ3YEZ2SkhR0+iRAa7t9/XMDkDx+yHsXeEwmFfn4/jRk9YcfOjUmJr5VVVCZP+lXSc8bcvX3+/Mnsj++VlVX69vGZNnU2i8VCCK3fsAIh1KVL98jTx0pKikxNzObPW25v77Rg0fSEhFcIodu3b4SHnbIwt6rvXACkE9RSA1Av2/b2qW+TiQrj0tKSz58LxGJxTk428Wpi0utO7l1FItHyFXNTUhKXL1sXduikna39ipXzsrIyJI1EHDnQuVO3PbsjRo4Yd/bciWvXLzb8oZGnj935O2rJ4tVH/zi/aMFv9+7fOXY8DCFUWFiwaPEMCpW6KzQsdMfhisryxUtn8ng8hFDq25RNm4O6du1x+OCJrVv2cmpr165bSrTGYDCy3mekv3u7dfNee3un/IK8JctmGRma7NxxeO6cpbduXz90eBfxThqNtnff9jGjJuzfd9TNtdOO0I1FRZ9b7EcLAJBVqW9Tdu7a3L271+9hkb4DhwZv/I1YMPjrDofL5S5fMZfBZO4IOXjowJ/2Ds6r1ywmOpbExNe7dm/x6tUvIvz0+HFTJR1Rw31dAyJPH7sRdXnWrEVhh085ObmdOBkheenOnagdoRsH9B/0R8TZDetC0t+9XfnbfKJI9dDhXVF/XZk1c9HuXb8bG5suWzEnL/9Twx9Ep9PPnT/Zo7vXlUvRv/wy99z5kytWzgsYM+nqlbs+Awbv3rO1orICIRQbe3/jplXu7l1/Dz+9bOnah49iQndtIlqg0elJyfGpqcnhh09duvC3pqbWtpD1CKGNG3a2t7Hr22fAlUvRlhbW9Z0LgNSCWmoA6tW+fQcOh5ORmY4Qik94aWXV3tbWPjHpNUIo91NOSUmxe8eucS+fpb97u2RxUEe3zmZmFnNmL9HXN7x0+YykkR7dvX4ePrq9jd34cVPs7Z2iY242/KHv32dYWlh37uRhbGTi4dFz547DxJzHtesXKBRK0KpNlpbWdrb2v60Izs//9OBhDELI1MTs8KETEydMb9fOvIOdwwj/gMzMd2VlpQghMUJ5ebkrlq93cemoqakVFXWZyVRaumS1vb2TZ88+s35dKLnVQygUjhoV2LNn7/Y2dpMm/SoUCuESJADga3fu3NDW1pk9c1G7duYDBgzy9OwreemLDodGo+0KDVuxbJ2Nta25ueWUSTM5HE5ySgJC6M7fUTo6ujOmzzM1NfPo2mPkyPGSRhro6xpK9XdUzx69fQcONTE2HTZ0RCd3D8lL5y+c6tHDa1zAZFNTM1dX97lzlqa/e5ucnFBdXR3115UJgb/06d3ftn2HxQtXde7U7dOnnO/+BKytbbt186RQKH37+CCE7O2dHByciS+5XG5uTjZCKPLMMReXjr9Mm2NibOrRtccv0+ZGR9/8/LmQaIHDqZ01c5GysjKLxern7fvx4wcOh6Ompkaj0xlMJvGjq+9cAKQWyUPqyMhIa2trctsEABddXT1jI5OU5ASEUGLiKydHVwd756TkeOJLXV09Cwur1NRkBoPh6uJOHEKlUp2d3DIy0iSNODu5SR472Dt//Pih4Q/t3q3Xq9cvNgSvvP8guqKyol07c1NTM4RQamqyna2Dupo68TZ9fQNDQ2Pig9TU1PLzP638bX7AuKE/jxiwddtahFBlZQXxTlNTM00NTeJxenpqexs7SYHWgAGDliwOkny0o4ML8UBLUxshVFNbQ8ZPEQAgVz5+/OBg7yzpRjx79qn7at0Oh06n8wX8vfu2T5w8wn+kT+DE4QihiopyhFD2x/ft23eQNNKhg6OkhQb6uvrw+fxPn3Ls7Bwkz0gaFAgEmVnv7Ds4SV6ytbVHCGVkpn/4kMnj8Tr8dxSDwVi/bnvnTh5fNf8lUxMz4oGamhpCyNTUnPhSRUUVIVRVXSUSidLTU+sO64lzRFbWO+JLYyNToggEIaSurlG3x5ao71ygyGg0mqqqKu4U9YJaagAa0rFjl6TkeH//sfEJL2f8Mk+Jxbp9+zpR9eHu3hUhVFNTzefzfXy7Sw4RCoVElR5BVVVN8lhZWZnDqW34E/v391NRUb167fyWrWuEQmGP7l4L5q/Q1taprq56l5E2YGA3yTv5fH5JaTFC6O69O8EbfwscP3XunKWqqmpJyfFErd7XASorK9q2NajvoyVdPHENF8EVJwDAVyoqynX12ki+1PhvAE2o2+Hk5n5cvORXN9fOv60M1tNtIxKJRo3xI16qqanW1dGTvFOZpSx53EBfV59aTi1CiMlU+l+DyiqSl8RiMTHYJagoqyCEamtriFGskhLrR38CkvtPCEpKSnW/FIvFHA5HKBQeOx7254nf674k+S6Y//8Q4qgvnqnvXPCjaeWJUCisrq7GnaJeJA+pAwICgoODraysyG0WAFw6duyy/8AONrvs48cPDo4uTAbzc1FhcXFRYsKryZN+Jc4fTCbz97DIukfVvQGxts4YuqamRtLRN6BHD68ePbxqa2ufPos9cDA0JDR488ZdqqpqTk6uixeuqvtOorWoqMturp2mTJ5JPMnlcOprWVNLu6ZGevsjAID0YzCZdTuZr6dXJe7euyMUCoNWbSIGnYWFBZKXWCzl6uoqyZdVVZWSxw30dfVhKbGIsfjXDSqzlKlUat1+r7qmmvgUTS1tYnD/dYP/Tiv8h8fjNvDp38jDYtHp9J+Hjxnk91Pd57V+cED8zXPBD7UAWhPUUgPQEDfXTiUlxbduX7ewsNJQ12CxWNZW7e/eu51fkNexYxeEkJ2dA4/HEwqF7dqZE/8xmUp6em0lLSQn/2+rl7T0N2ZmFg1/Ymzs/fyCPGJKu0/v/oP8fnqflUFcx/z0KcfIyETyQRQKRVdXDyHE4/M0NbUkLcTcvfXNOQ+EkI21berbZC7339PDnTtR8xZMk+b9XQEA0sbEpF1a+htJD/Mo9l597+TzeUpKLMkk7t/Rf0leMjUxy8x6J+l84l4+k7zUQF9XHyaTaaBvmJmZLnnm5X8N0ul0a6v2SXX64TcpiUT5h6mJGYvFSkh8RTwvEonmL/zl9u0bRAlH3VF+5n8FG41EpVJtbOwKC/Ml34KhoTGNTtdQ1/jusZIfbH3nAiC1oJYagIZoamrZWNtevnJWUhLt6Oh66fIZS0troot379jFxtp285bV8fEv8wvyomNuTZ8RcPXaeUkLj2Lv3b13p6Ag/+q1C0lJ8T4DBjf8iRcvnd4QvDIh4VVe/qfX8XH3H0S7uLojhIYM9q+trdm2fd27jLTc3I9/noiYPHXU27cpCKEOdo5xcU9TU5MLCvJ37d6io6OHEEpLe8P5arp68KCfBQLBps1ByckJsbH3w37fa9bOouFF/QAAoK7evfoVFhYcPXY4L/9TdMytf548rO+dHewcy8vZN29dKykpvnL1/Nu0FC0t7czM9KqqKm/vgWVlpQcO7czKynj46O6dOzckRzXQ1zWgb1+f2Mf3b0RdzsrKOHf+ZN3a65Ejxz99Gnvu/MmCgvzX8XH7DuxwceloZ2uvpqbmO3Doqcg/7tyJSktP3blrc3p6qqOTK3Fveuzj++XlbD6ffyryKFH//UPGjJ7w8NHdyNPHcnKy32Wkbd6yet78qd8tWlBXU8/ISHuXkVZezq7vXACkFtRSA/AdHTt2OXvuhLNzR+JLJyfXCxcjR/gHEF/SaLRtW/cdCtu9dv0yDqfWwMAoMHDayBHjEEICoQAhNHvW4ouXTm8PWc9iKY8LmOznO6zhj1uzesvBQzvXrl9WXV2lq6vn0bXntKlzEEIGBoY7Q8PCw/fOmz+VRqOZm1ttDN5pb++EEBo3bkpefu7ipTNVVFQHD/p5QuC0kpKiHTs3Ur/696ivb7Bty77D4XsWL52poaHZu3f/X6bOaZkfGwBAPnXv3mvK5JmXLp+5cDHSxcV90cLfps8Yp8T8sjiYeOfoUYFh4XsPHtrZtUuPFcvWX7h46vSZ41QqdcH8FbNnLTpz9s/r1y/a2NgtXhw0fcY4YoK2gb6uARMnTC8vZx8O2y0SiTy69pw+fd669cuJWfB+3gO5XM658yd/j9ivqqrWs0fvGTPmE0fNmD6fQqUeDt9TW1tjYWG9ZdMeYkX/WTMXbQ9ZPyZgsLq6hp/vTz4DBr948eSHfkq9PPv+tjL49JljR48dVlVVc3R02RUa9t1b64YPH7Nl65p586euXxdS37kASC0KuXUaUEsNpFlueu3z26X9JxjjDiKf/tyQMTPEGqa8AZAhnGrRyc0fRi+zbPwhYrG4tLREUomRmPh6/sJf/og4a2EBp37pIn998v37969fvx4aGoo7yLdBLTUAAAAAGish4dWIUQP/PBGRm/sxOTnh4KGddnYO5uY/MCgHQC6RXPgRGRkJtR8ANGzlqgV171msa5Df8F//uyIJAABSyNXVfeXy9WfPn4g8fVRNTd3VxX3G9PlfLJHREoYM613fSyuWre/Rw6ulAwDQMKilBqC1rV61WSgSfvMlBp3R6nEAAODHDBgwaMCAQa38oZGnrtf3Ut1lrQHABdalBqC1qah8f2lqAAAAdUn2UwRAOkEtNQAAAAAAAM0C61IDAFpKYWHhP//8gzsFAAAA0OKglhoAQBqhUJie/i4rKysuLi41NbWqqqq8vLympiYuLg53NAAAAKAFQS01AIA0I0aM4PO5bDab2POcWARAW1sbdy4AAACgZZE8pIZaagAUGZ1Oz839SKFQ6q6opa4ONxUBAACQc1BLDQAgzbFjx+zt7b94UkVFZffu3bGxsbW1tZhyAQC+ITExcdu2bUKhCHcQAOQByUNqqKUGQJGpqqqeOHGiR48edPq/V8DEYvGqVat0dXXPnz/fv3//wMDA3bt3P378mMPh4A4LgGIpLS1FCMXFxU2ePDkiIgIhVFJS4uLiQpWnHasBwIfkf0gBAQGZmZnktgkAkC179uzx9/dXU1NDCOno6HTo0CEwMHDPnj2xsbErV67U1dU9e/ast7f3hAkT9uzZA8NrAFrI58+fk5OTEUJPnz7t1avX5cuXEUJqamoLFy6cMmUKQqhPnz4DBw5s+X0PAVAIUEsNFIgYiVU0SP47DyR0DZhioRhRKQihpUuXGhgYnDx5UlVVte577O3t7e3tAwMDEUIpKSkvX748e/bssmXLrK2t3d3d3d3dO3XqpKSkhO+bAECGCYXCuLi40tJSX1/fly9fBgUFBQQEODo6Wltb37x5k/jHaGdnV/cQkUik1Qb+xcmnun0yaAUkDy8iIyOh9gNILU09Rv4HKOdtEZVlfG6tiMb4X98dad07twAAIABJREFUGBhIDJ3r4+Dg4ODgMGHCBIRQcnIyMbxeunSpjY0NMbbu3LkzgwE7tAPQED6ff/HixYKCggULFmRkZBw/ftzHxwch5OTkdPPmTeI9enp69R2uok4vLeTyOEImC87dcuXrPhm0NFiXGigQDR2Ghg5dwBfRGVA7SLLyYp5Zh6ZvtO7o6Ojo6Dhx4kTJ8Pr06dNr1qwxMTHp9B9JfTYAikwgEFAolG3btuXk5Bw6dKi8vDwnJ6dbt24IIVtb24MHDxJvYzKZjWzQ3EGlvJjXxkS5JVOD1tbMPhk0AdRSA8Xi3FPzwfkC3Cnk0KOLBR5+uqQ0RYyt9+3bFx0dvXjxYsktj1OmTDl48OCzZ8+EQiEpHwSATMjLy8vPz0cIhYaGduvWrby8XCwW29raLlq0iJiBXrp0ac+ePZvcfucBOo8uFZIaGeBHYp8MGolCbunz6NGjN23aBOvoAWmW+qLi7YuqXv76cKGTFOXFvL9P5v0821hTr2WLNBISEuLi4l6+fBkXFzdo0CADA4POnTt37NixRT8UgNZXXV0dHx+vr69vbW29c+fOe/fuBQcHu7q6ZmZmmpqaNn76ufGKcjm3/yz0HmeopkV+46CVEX2y/xxjDV15K5y7f//+9evXQ0NDcQf5NpKH1EKhEGo/gPTLSKhKfMRmF/ENLJRrKuqd8uTxeC1x9pIbGrqM90mV7exUPPx0tdu26g8qKSnpyZMnL168SExM7NSpU5cuXTp37vz1ktgAyIqioqK7d+/a2dm5uLjMmzcPITR//nwrK6vq6uov7vFtIZ9zOC/ulH3KqDV3UK0oFbTCJ2Ih36MUjH1y61CsITUAMqSKLWAX8SjfWkHq8ePHp0+fHjNmTHMup8o9CoWiZ8xksnAWpgsEgri4uOfPn7948SI7O7tz587E8NrS0hJjKgAaIzc39+zZsyYmJqNHj7548WJmZua4ceOMjY0xRuLUCEvyeUhOxwUCgWD+/PkHDhzAHaSlSEOf3KKkfEhN8u0+AQEBwcHBVlZW5DYLQEtQ06KraX35TyA+Pn779u12dnZnrh6E1dykH51O9/Dw8PDwIC6Xv3jx4vnz5xcuXDAwMNDW1u7WrZuHh4e2tjbumAAgkUhEpVLfvHlz5MgRMzOzefPmffr0ydDQ0MvLCyHk7++POyBCCLFUaMZWcnufokAgMLZWNraW228Q4AXrUgPwLzabvW3bts+fP69du9bW1hZ3HPDDVFVVe/fu3bt3b2KjuCdPnjx+/Dg0NFRfX9/Dw6Nbt26dOnXCnREolrKyMm1t7fT09ODgYDc3t0WLFvF4vCFDhhB/Fbt27dq1a1fcGRUInU6X4ylqgB3UUgOAEEInT548evTo8uXLBwwYgDsLINnbt2+fPn365MmT+Ph4Dw+P7t27e3h4mJmZ4c4F5FNWVpalpWVBQcHUqVOdnJy2bt2am5tbUVEBtf7YicXihIQEV1dX3EFAE0l54QfUUgNFFx0dvWXLlqlTpwYEBODOAlqWQCB4+vTpP//88/TpUx6P5+Pj4+zs7OnpSaXKbekhaAVCoTAlJcXZ2ZnNZg8aNKhr1647d+6srKysrq42MDDAnQ78D4/H8/LyevLkCe4goImkfEgNtdRAcb1///748eO1tbUXL17U0tLCHQe0ODqd3rNnT+KW0/z8/FevXl29enXJkiXdunXr1atXz549YQAEGonD4bx+/ZpYJbp///69evXasWOHiopKTEwMi8VCCKmrq6urq+OOCf4fKpU6YsQI3CmA3IJaaqCgQkJCnj17tnr1ahcXF9xZAAaGhoaDBg0aNGgQscDLw4cPjx49qqGh4enp6enp6eTkhDsgkDo1NTUvXrxwc3PT0NAYPny4ra1tt27dVFVVnz9/TrwB1tyUcnQ6ffHixbhTALkFtdRA4dy4ceP3338fO3bsmDFjcGcB0iU9Pf3Ro0ePHj3Kycnx9PTs1auXp6cngyFv2yWAxuPxeM+fP7ewsDA2Np46daqmpuaGDRvU1NRw5wJNIRaLX758Cbcpyy4pL/yAWmqgQLKzszds2GBiYrJ69Wo6neRLNECesNnsR48ePXz48NGjR0OHDu3QoYO3t7eGhgbuXKCVPH/+XEdHx9raetGiRUKhMCgoqE2bNrhDgeaCWmpZJ+VDaqilBoriyJEjUVFRa9asgdu9wXdpaWkNGTJkyJAhCKG4uLhbt27t3bvX1ta2X79+3t7esNC1XHrz5g1CyN7ePjg4OC8vb/ny5QihnTt34s4FSEOlUgcOHIg7BZBbJN/nDrXUQArFxcUNHDhQU1Pz0qVLMJ4GP6pTp05BQUH37t2bOnXqu3fvRo4c+csvv5w9e7a4uBh3NNBchYWFycnJCKHjx49v2bKFx+MhhFavXn3o0CFzc3Pc6QDJ6HT62rVrcacAcgtqqYGc27hxY05OzqZNm/T09HBnAXLi1atX0dHRMTExxsbG3t7e3t7esFSIbElNTe3QocOjR4+2bNmyYMGCAQMGcLlc2C1V7olEogcPHvTp0wd3ENBEUl74AbXUQG7FxsZGRET89NNPP/30E+4sQD4lJCTExMTExMTo6en5+fkRF0NwhwLfVlRU1KZNm5ycnOHDh0+ZMmXWrFlVVVVwo6FCgVpqWSflQ2qopQbyacOGDSUlJeHh4bCsFWg5Li4uLi4uixYtSk5Ovn///vDhw52dnYcMGeLt7Y07GvgfLpc7YcIEFot1/PhxbW3tuLg44nkYTysaKpXq5eWFOwWQW1BLDeTNy5cve/fu7eLismfPHhhPg9bh6Og4Z86cu3fv+vv73759u0ePHps3b05KSsKdS6Ft27aN+N2GQqFs2rTp+PHjMIxWcHQ6fevWrbhTALlF8ix1ZGQk1FIDjPbu3VtUVHT9+nXYtwxgQewUw+FwoqKiQkNDKyoqBg8ePHjw4LZt2+KOphCePXt27ty5hQsXmpiYuLi4zJgxg9iBxdraGnc0gJ9IJLpz5w4s+gFaCMmz1DCeBrjU1tZOnDhRU1MzODgYxtMALxaL5e/vf+zYsV27dhF/M2fOnBkVFYU7l3zi8XhXr14lyjlSUlKGDBliYmKCEBo4cKCWlhbudECKCASC9evX404B5BbJQ+qAgIDMzExy2wTgu548edK/f/+lS5dOnDgRdxYA/sfMzGz27Nk3b96cPHnys2fPxo0bt2fPnqKiIty55AGHw0lISCCujiYkJBBr3k2ZMqV37964owEpBetSgxZFcuEH1FKD1hcREVFSUhIbG4s7CAD16tKlS5cuXYRC4alTpwIDA52dnQMCAmCV9CZ79erV3LlzV61a5eLiMmnSJNxxgGyAdalBi4J1qYFsW7ZsmYWFxcyZM3EHAeAHxMTEREZG8ni8gIAAX19f3HFkA4fDCQkJKS4u3rNnT2Fhob6+Pu5EQMaIRKK7d+/269cPdxDQRFK+iB7UUgNZJRaLhw8f7uPjA+NpIHO8vb2PHDmycuXKx48fE49rampwh5JSJSUlR48eJR44OTnt2rULIQTjadAEAoFg9erVuFMAuQW11EAmiUSi4cOH79mzBxYABrLL3t5+48aNFy9e5HK5Pj4+GzZseP/+Pe5QUqSwsJC4EiUUChFCxsbGP/30E5VK8mkLKA4qldqjRw/cKYDcgnWpgezhcDhdu3a9cOFCu3btcGcBoLm0tLRmzZr16NEjFxeXffv2rV+/vqysDHcozIjJ+4KCAoTQkSNHpk2bhjsRkAd0On3Hjh24UwC5RfKQOjIyEpb/BC1KJBJ5e3u/ePGCTif55loA8Bo2bNjOnTvd3NxGjhy5e/dukUiEO1FrS05Ojo6OJmoIL1686OLigjsRkCtisViydyYApINaaiBj+vXr9/jxY9wpAGgpQ4cOjY6O1tXV7dq167Fjx3DHaT1PnjwJCQkh1sLz8PCAJaUB6QQCQVBQEO4UoOloNJqOjg7uFPWCWmogS0aOHBkREYE7BQAtLjAw8MWLF5WVlb179758+TLuOC0oJiZm4cKFCKEOHTocP34crnOCFgUbgck0oVBYWlqKO0W94D4PIDNWr149Z84cS0tL3EEAaCVz5869fv16SkrKsGHDHjx4gDsOyXJychBCz58/X7JkCVFTjjsRkHMMBuP8+fO4UwC5RX4ttZWVFbltAoAQunjxorKyspeXF+4gALQqdXX1oKCgAwcOPH78eOHChVwuF3ciEuTm5s6ePZvYRXLlypXGxsa4EwFFwePxcEcAcovkITWfz4cVPwDpqqqq9u7d+9tvv+EOAgAeJiYmv/322/Dhw/v06RMVFYU7TtPl5uYihLKzs1esWNGxY0fccYBi4fF4MC8DWg7JQ+rx48dDLTUg3Z49e0JCQnCnAACzXr16/fPPP8+ePVu3bh3uLE2xefPmP//8EyHUo0cPU1NT3HEAAIBMJA+pWSwWLPoByJWUlPTu3bsuXbrgDgKAVNiwYYOfn1+PHj3evn2LO0tj5efnI4RsbW3hWhPAiMlkPnnyBHcKILdIHlIfP37cwsKC3DaBgouIiICNHgCoq0uXLjExMcHBwefOncOd5fuWLl1aXFyMEPL398edBSg6qKUGLYfkIXV1dbUCbk8AWk5WVhaVSu3ZsyfuIABIFxaLderUqffv3+/Zswd3lnrV1tYmJyf7+vo6OTnhzgIA1FKDlkXykHrKlClZWVnktgkU2e3btx0cHHCnAEBKLV++3M7ObsGCBbiDfMOhQ4cqKiocHR379u2LOwsACCFEpVLNzMxwpwByi+Qhtbq6OmwTDUiUmprq5+eHOwUA0svHx8ff33/ChAm4g/w/UVFRDAZDX18fdxAA/odOp585cwZ3CiC3SB5SR0REENvJAtB8BQUFmZmZRkZGuIMAINU8PT1nz569YcMG3EEQQohYR9XFxQVugQDSRiwWw4V00HJIHlJXVlYKhUJy2wQKKz4+HlauBaAxunbt6uvrO2XKFLwxamtriTsfTExM8CYB4Gt8Pn/cuHG4UwC5RfKQetq0ae/fvye3TaCw0tPTra2tcacAQDZ07tx54sSJixYtwpjhr7/+evz4McYAADQAaqllHY1G09DQwJ2iXlBLDaRXbm4uzHUB0HheXl5eXl6HDh1q/Y/m8Xjx8fGwTB6QZlBLLeuEQmFFRQXuFPWCWmogvUpLS3V0dHCnAECWDBs2LDs7+++//27NDxUIBJ6enq6urq35oQD8KLFYnJ2djTsFkFtQSw2kl7q6ujRf4gFAOm3dujU0NLSoqKjVPjEhIQHqPYD04/P5Y8aMwZ0CyC2opQbSKzc3l0Kh4E4BgOw5cODA6tWrW+ez8vLy7O3toeQPSD8qlWplZYU7BZBbJHeCUEsNms/d3V3yeOTIkcSD7t2779u3D18oAGSJlZWVjY1NZGRkQEBAi37Q0aNHq6ur58yZ06KfAkBzbN68+cKFC5IJGskp5uXLl1hzAXkDtdRA6tja2orFYkodOjo6v/76K+5cAMiSxYsXh4eHV1VVtdxHsNlsS0tLGE8DKTdp0iRTU1PK/9euXTvcuYC8IXlIXV1dLRKJyG0TKJqxY8cqKyvXfcbNzQ22JQfgR61cuXLXrl0t176WlpaXl1fLtQ8AKYyMjHr27ElsQkSgUCiwLy8gHclD6ilTpsDWRKCZhgwZUnf+QEdHR9o2WwZAJvj4+MTFxeXm5rZE46dPnw4PD2+JlgEgXUBAQN0lWY2NjeE+RUA6kofUDAaDSiW5TaCAAgIClJSUiDWPnJycHB0dcScCQCbNmDEjLCyM9Gb5fH5UVNT06dNJbxmAlmBsbFx3otrPz09dXR13KCBvSB7+njx50tLSktw2gQIaMmQIMaOgq6s7adIk3HEAkFV+fn7JycnFxcXkNstgME6ePElumwC0qPHjxxsZGSGETE1Nx44dizsOkEMwowyk1Lhx4+h0urOzs5OTE+4sAMiwAQMGXLlyhcQGBQJBVFQUiQ0C0AoMDQ379OkjFosHDhwIU9SgJVDqFuw33+jRozdt2mRtbU1im6A5BHxR/AN2SR6vukL2tuDJzs42MDAgKkBkiKYeg6VCNeugYmKjgjsLAKigoGDq1KkkDoKPHTtWWVk5d+5cshoECqK6QpDypIJdxK9iC7AEEAgEn3JzTdu1w1WhqqpB0zViuvXWptFhy4WmiI2NvXfvXqstuv+jSF5DGmqppUphNufS/k8OPbSMbdRYKjTccX6Ys6dM7kYuRqj4Eyf5n8qc9Npug3RxxwGKzsDAwMbG5vXr125ubqQ0qKurO3r0aFKaAoojJ70mOrLQylXDxFaNycQ2TuiI2uL6aIQQp0ZYWsAJW5E5Yr5JW1MWxiQySiAQsNls3CnqRfIsNZAeeVm1T/8q7R9ojDuI4nr2V5GGDq2Lj0z+YgDkyYkTJ0pKShYsWIA7CFBQH95Uxz8o9w4wwh1EWtz581P3wbqGFjCq/jH379+/fv16aGgo7iDfRvJvimw2WyDAc0EH1CUUiu+d/dwX+i+suvq1KcnnfXjTgnttANAYnp6ejx49IqWpCxcuPHv2jJSmgILg1Aj+uV4C4+m6vAOM7p4pFAphTlOukDyknjFjxocPH8htEzRB9ptqdR0mjQbVWpgZWqqkv6rGnQIoOnNz8zZt2uTl5TW/qfDwcLhbBvyQzMRqXSOYjv1/aHSKug4z+w2cHeQKyUNqIyMjJpNJbpugCdhF/LZmyo14I2hZukYsTrXs3RgK5I+Ojk5SUlIzG6mtrT148KCuLtwhAH5AebEA6oa/1taMVfaZjzsFIBPJQ+pdu3bV3fcO4FJbJURwQUkK0BnUskIe7hQAIBcXl4SEhGY2oqysDFPU4EfVVAoQXDH9mphSWwUTLnKF5CF1VlYWl8slt00AAADN5OzsXFFR0cxGQkJCoJAaAAC+ieQh9cqVK3NycshtEwAAQDOZmpo2/w7FBw8ewHVIAAD4JpKH1HZ2dsrKUMILAADSRU1NjcViNWdncpFIdOzYMUNDQ1JzAQCAnCB5q5f169eT2yAAAABSeHp65uTk6OnpNe1wKpXa5GMBAEDukTxLnZSUVFtbS26bAAAAmo/H4zVnHb3o6OitW7eSmggAAOQHyUPqjRs3fvr0idw2AQAANF+bNm2KioqafPiHDx80NTVJTQQAAPKj3sKPysrKJjQ3depUVVXVJhyrrq7ehI8DAADQSCYmJs2ZpQ4ICKDTSa4VBACAxqPT6dra2rhT1Kve/rFp9Ruurq5NOxaG1AAA0KJUVFSacxVRRUWF1DgAAPBjBAJBWVkZ7hT1IrnwQyAQiMWwxQgAAEgdNTW1qqqqJh8+e/bsxMREUhMBAID8IHlIXVVVJRKJyG0TAABA86mrqzetoo9QXFwME9UAAFAfkgvj6HQ6hQIbjwIAgNRRUVFhMplNPvzs2bOkxgEAALnS3Fnqa9euDR48WPKlmpoalUr9+nkAAAB4MRiM5qz4IRQKSY0DAAByheTCD0mf6+zsPHv2bHIbB6CVXbp81rt/F9wpACAHk8nk8XhNPtzT05PL5ZKaCAAA5AfJQ+rKykpiVG1ubu7r60tu40ABrVu//Nbt67hTACAPlJSUbGxsmnw4hUJpTt0IALIOzkegYY2tpRYIBMeOHXv06BGbzdbU1OzZs+fkyZMZDEbd9wiFwpCQkOLi4tDQ0Lt374aHh9+4cQMhNGLEiFGjRuXm5r548YLD4bi5uc2fPx+2DACNkZ6e6uHRE3cKAOQBlUptzpIdjx8/JjUOADIGzkegYY2dpT5//nxMTMz8+fMPHz48Z86chw8fnjp16ov3hIeHZ2dnBwcHq6mp1X2eTqdfvHjR2dn51KlTe/fuzczMDAsLI+9bAOQoLi5auWrBQL8eI0YNPHP2zyN/HJw4eQTxEptdtnnrmtFjBw306zFrzqTX8XHE89nZ7/t4d3odHxe0ZvGw4d7D/fvv3bddUvxT31GXr5wb7t//8eMHw/37Hzq8GyFUVla6eeuaEaMG+vh2Hz9h+KVLZ4h39vHulF+Qt237+iHDehPPxNy9/evMQN9BPX8eMWD/gVAOh9PwNzVi1MA/T0QQj0tKivt4d1q/YYXkVf+RPmfO/okQSn/3dtnyOcOGew8a0mv1miUFBfmS91AolDdvkmb8On7AwG4B44b+/fdfJP28AWhtNBqtOfXQUEsNWg3p56P6Ovmvz0dv094sWTpr2HBv30E9Z86aEPfyGfHO5p+PgNxr7JD6w4cP5ubmHTt2NDQ07NKly5YtW/r161f3DVevXo2Ojl67dm3btm2/PtzS0rJfv35UKtXU1NTX1/eff/5p2lYyoOXs2Lnx3bu3wRtCt23Zl5D46u69O8SdpiKRaPmKuSkpicuXrQs7dNLO1n7FynlZWRkIIRqdjhA6cDB07OiJVy/HBK3adPnKuYeP7jZ8FIPB4HBqL10+s3zZumHDRiKEtu/Y8CYlcfWqzRHhpwPGTjpwaGfs4/sIoXNn/kIIzZ2z9OSJqwih2Nj7Gzetcnfv+nv46WVL1z58FBO6a1PD35SbW+fk5HjicULiq7Zt9ZP++zInJ7u0tMTdvWthYcGixTMoVOqu0LDQHYcrKssXL50pKTmlUCj7D4YGjp+2d88ROzuHLdvWfviQ1cJ/FAC0CBqNpqWl1bRjORxOr169yE4EwLeRez5qoJP/4nzE5XKXr5jLYDJ3hBw8dOBPewfn1WsWFxV9JuV8BOReY4fUXbt2TUhI2Lp166NHjyorK01NTU1MTCSvPn/+/MiRI6tWrWrTps03ZzKsra0lj83MzHg8XklJCRn5ATlKS0ueP/9n/LipnTt5WFnZBP22qaKcTbwU9/JZ+ru3SxYHdXTrbGZmMWf2En19w0uXz0iO9erVz8HBGSHk3rGLkaFxWtqbho+iUCgcDmeEf4BH1x5GhsYIodmzFm/ffsDFpaOpqZmf7zBrq/ZxcU8RQhoamsTKX5oamgihyDPHXFw6/jJtjomxqUfXHr9MmxsdffPz58IGvq9OHbu+SU0i1kpPSHjp3XdgTU31p7xchFBi0mtNTS1rq/bXrl+gUChBqzZZWlrb2dr/tiI4P//Tg4cxRAsCgWDC+Gk9e/a2s7VftHAVnU6//yC6hf80AGgRFAqluLgYdwoAvoP081EDnfwX5yMajbYrNGzFsnU21rbm5pZTJs3kcDjJKQmNPB+VlMC/L4XW2Frqvn37qqio3LhxIzQ0VCgUenh4zJo1i9hpXSQSbd++XSAQsNns+g5XVlaWPGaxWMSmMGTkB+T49ClHLBY7OrgQX6qqqrq7d83++B4hlJqazGAwXF3ciZeoVKqzk1tGRprkWCvL/93wpKamXlVV2Zij7O2dJI+VWcqRZ47Fx8eVl7NFIlFlZYWxsekXCUUiUXp66qSJMyTPEI1nZb1r21a/vu/Lza1zdXV1VlaGtXX7+ISXM2csePs2JSnptbGRSULiq07uXSkUSmpqsp2tg7qaOnGIvr6BoaFxRkZa/37/3l/r5OT233enZmFu9enTxx//AQMg21gs1sOHD3GnAAqhJc5HDXfykvMRnU7nC/h7923PyEyvqqokdoOuqCj/ImF956Psj+91dfVa5qcCZMAPbPXi4eHh4eFRW1v74sWL8PDwPXv2rFu3jnhp9uzZaWlphw4d2r9//zcvLNbU1HzxWF1dnYz8gBzl5WyEkHKdrdGI38gRQjU11Xw+38e3u+QloVCoo6Mr+ZKppFS3KaIP+u5Rqqr/FtwLBIJlK+YIhcI5s5e0MzWn0WhBaxZ/nZDD4QiFwmPHw/488Xvd50tKG5oVaNtW39TULCk5XldXLzf3o6Oja+rb5MTE1wN9hiQmvpo4YTpCqLq66l1G2oCB3SRH8fn8us2qqqpKHiuxWFAwBxQTjUbDHQEoBNLPR43o5P89H+Xmfly85Fc3186/rQzW020jEolGjfH7OmF956OystLmfetAtjV2SP3kyRMLCwsDAwNlZeVevXplZ2ffvXuXeIlKpfbp06d79+7x8fE7duzYtm0bUfNUV3JysuTxu3fvlJSU9PTgNzkpQnRD3DqDxcrKCuKBqqoak8n8PSyy7vu//iP+QuOPSk1NzsrK2LPrd2fnfyeDy9llhgZGX7yNxWLR6fSfh48Z5PdT3ee1tHUaTtLRrXNKSoK2to6lhbWampqjo+vefdsLCwsKCws6unUhojo5uS5euKruUcrK/+vNORwOcWkFIcSprW3b1qDhTwRAatnb2zftwNra2qVLl+7fv5/sRAB8qSXORw138hJ3790RCoVBqzYpKSkRRdjfbLC+85GODgxsWhaDwfjmDXtSorG11FevXt22bVtSUlJ+fn5CQkJsbKyTk1PdNygpKS1ZsiQtLe3cuXNfH15SUnLy5Mn8/Pznz59HRUX17t1b6f//KgnwIgot3qalEF9WV1e//O82Zzs7Bx6PJxQK27UzJ/5jMpX09L7zd7rxR3F53LqTECkpifkFecTUAoF4TKVSbWzsCgvzJQ0aGhrT6HQNdY2Gk7i7d01OSUhIeOns0hEhZN/BKS8v9/6Dv9u1M9fXN0AIdejg+OlTjpGRiaRlCoVS9+Kd5I7Gmpqajzkf2pmaN+6HCoB0EYvFqampTT48Pj6e1DgAfBvp56PvdvISfD5PSYklGZ/8Hf3lEk8Nn4++WO4MkI7P53/+/Bl3ino1dki9fPlyQ0PDzZs3z5gxY9euXc7OzjNmzPjiPdbW1v7+/pGRke/evfviJR8fn+rq6oULF27dutXd3f3rYwFexkYm7W3sTp36IyUl8ePHD1u2rdH+71Kae8cuNta2m7esjo9/mV+QFx1za/qMgKvXzjfcYOOPsrZqz2QyL10+U1JS/CLu6d592zt38sjJzS4rK1VSUlJSUkpIfPUuI00gEIwZPeHho7uRp4/l5GS/y0jbvGX1vPlTq6urG07i6tqpqOjzP08eOjm6ElUcVpY2l6+cdXc+oQLBAAAgAElEQVTvSrxhyGD/2tqabdvXvctIy839+OeJiMlTR719+29vTqfTT546kpQU/ykv9+ChnXw+v0/v/k36GQOAmVgsplAoTTtWWVlZcmUSgBZF+vmo4U6+rg52juXl7Ju3rpWUFF+5ev5tWoqWlnZmZnpVVVVjzkewlJmCa2zhh7a29rJly75+fujQoUOHDpV8OXHixIkTJyKEbGxs6j5Po9FmzJgBI2lpFrRqU0ho8MLFM/R024wbN0VXR4/ocWg02rat+w6F7V67fhmHU2tgYBQYOG3kiHENt9b4o7S0tJctXRsRsf/O31Ht23dYvmxdUfHn4I0rFy359eiRc2PHTDpz9viTJ49OnrjSy7PvbyuDT585dvTYYVVVNUdHl12hYXULnb9JXU29vY3d27Q3zv/dZejo5Hr58ll3t393GjcwMNwZGhYevnfe/Kk0Gs3c3Gpj8E7ibhWhUKCsrDJtyuy9+7Z/yM5q20Y/aNUmU1Ozpv6MAZBhsHUiaDXkno8a6OS/0L17r9GjAsPC9x48tLNrlx4rlq2/cPHU6TPHqVTqgvkrvns+qrsSA1BAlLpX2Otq2tS6SCT6uqppzJgxw4YNGzt2bAMHSnNxjCx6fK2YxqA7dP+BNWg5HA5fwJfcE71o8a8aGprr1m5rsYwKoYotuHM8d+IaqBUB+FVVVQ0aNOjBgwdNOFYgEHh5ecEGiqAJok8X6hopW7t+p0ivLkU4H6X8wxbwBD2HQfn1D7h///7169dDQ0NxB/m2H1jxozEqKirU1dXhxnBZ9NuqBaVlJYsXrtLW1nny9NHr+Lgtm3bjDgUAkApUKlWy/xEALQ3OR0AWkTykptFoX9fqnTlzpp63AykStGrTwUM7V69dwuVyjIxMVixb5+HRE3eo70tKiv8taEF9r548cVXzvxsfAQBNRqVSX7x4gTsFUBQyej4CCo7kITWsNi27dHR0g1bJ3n6qdnYOx/64UN+r310PBACF4uDggDsCAN8no+cj0NLodLo01wmTPKQWCAR0OsltAtAABoMBu1UB0BgCgSAtLa0Rb/w2X1/f48ePS/P5DAAg3/h8flFREe4U9WrsInqNVFVVJRQKyW0TAABA8zVnET1iAcrvrlkJAAAt55trYEiPemeUdXV163upAadOnRo9enTTjgUAANByhEJhc+4dv3Ch3gorAABoBc2cF2hp9Q6pm9bzLly4sHl5AAAAtAgpn+ABAICGSfmQmuTuNSkpCXYPAgAAKdTMIXVISAhMVAMAMJLyeQGSk23cuPHTp0/ktgkAAKD5mln4oa+vD907AAAjKZ+lJnl1DicnJxUVFXLbBAAAQAo7O7smHztu3Di4+xwAgBGDwdDX18edol4kD6mDgoLIbRAAAAApamtrs7Ozm3w4jUaDnXEBABjV1taWlJTgTlEvqKUGAACFwOPxmExmc1ro0aMHh8MhLxEAAPyAZlavtTSopZZPVCqFIr0V/AqEQkE0hvQWfgGF0vwhtaura3p6OnmJgEKgUaW5/BUbChXBafpHSfl+giQns7OzU1ZWJrdN0ATK6rSSAj7uFABVlfNZKtL7KzVQKFwuV0lJqTktHDhwgLw4QFGw1GjV5QLcKaROFZuva8DAnULGKNYs9fr1642NjcltEzSBriGzthK6MPzKi/mGFs0axABAluYPqblcLpvNJi8RUAh6xszqCjgffammUqBr2KyrRgpIsYbUWVlZXC6X3DZBE5i2V+FxRPnva3AHUXRxt4s6D4DNRIFUaH7hh5KSko+Pj0AAwyPwA2xc1YtzOaWFMDb4n/z3NXyOyLQ9rJD2YxRrSL1y5cqcnBxy2wRNM3SGYcKD0tz0atxBFBSPI/zrSM6IeSZMFpTLAakgFosNDQ2b2cjIkSPj4uJISgQUhf884+d/FX3+CKsXIIRQTnp14oPSYb8a4Q4ie5hMpra2Nu4U9SK5ltrU1LSZFxYBWegMqv8c46gj+S9jinUNWExl6f3FTs4osaifMqrpDIrXz210jeCfA5AWpaWlPB6vmY0sWbKEpDhAgSgp04bNNPrrSH5VudDATJlCU9DbFfm1wpICroYO3X+uMYWqoD+E5igvL5fm1fFJHlLv2LGD3AZBc1BplCHTjUoLuSV5fLylbEVFRbdu3QoMDMSYgVxisfjKlSvKysoDBw784iUlFtXatY1+OyW4yx1IlYqKCg0Njea3Ex0d3bdvX2neFhhIIaYS9adZxiX53OI8Xm3Vv6Oijx8/xsTETJw4URb/OtXU1Ny4cWPUqFGNP0RVg9XFV0tHH6ZamojL5aqqquJOUS+Sh9RFRUXa2trSvMSJAtLRV8L+D/jQodPrdk1SV1fHG4Ncbr0n5+fnGxpqXb58mcvljhkzBnciABpSWVlJysZjKSkpeXl5EyZMICMUUCy6hkq6hkoIoeLiYj09vdonqXsCF+IO1WRaSm3dLawpmpqauJMoCh6PJ82FHyT/XjhnzpwPHz6Q2yaQAzNnzpSz8TSBqEz19fXNycm5efMmsWom7lAAfBtZs9TTpk2DxVJBc1y7dm3z5s0IoW7duuHO0izu7u6qqqrXrl3DHURRNP8e6xZF8pBaVVVVmm/GBK0vJSVl+/btuFO0LBaLtXTp0v79+yOEpkyZsmvXLtyJAPgGsobUqqqqI0eOJCMRUDg1NTUIoZKSkp07d+LOQg46nd6zZ89x48bhDqIQFGtI/ccff1hYWJDbJpBpGzZsmDt3Lu4UrYGod/rzzz/btGmDEMrPz8/NzcUdCoD/qaqqUlNTI6WpsrKy9evXk9IUUBxnz54lJnQnT56MOwuZdHR0Nm3ahDuFQmj+4votSvZuCACy5ezZs4p2jXj8+PEIIWVl5dmzZ1+6dAl3HAD+RaVSSZmlRghpa2traGicPHmSlNaA3BMIBHl5ednZ2fJ6z4m5uTlCaN++fbiDyDk6nS7NIwqSh9SjR4/OyMggt00gozIyMqKionCnwEZLS+vq1at2dnYIofDw8JcvX+JOBBRdZmamri5pGw8tXLhwwIABZLUG5Njly5fj4uK0tbWXLVuGO0vLmjBhwurVq3GnkGelpaUMhvTu4k7ykJpGo8HCYQAhJBKJZsyYMWjQINxBMLO3t0cIeXl5hYWFlZeX444DFJdAIKioqNDR0SGxTQqF8vbtWxIbBHJGJBJ9/PgxJSXFw8NDmicXyaKpqbl8+XLcKeRZTU2Nior0bjlJ8pA6MjLSysqK3DaBLKJSqTExMbhTSAtbW9vw8HBiNc0RI0Y8ffoUdyKgcD5//ty2bVty22zTps3JkyeJtW4A+MKtW7eysrJ0dHSCgoJwZ2k9xO0Kffr0wR1EPinWkJrP54vFYnLbBDLn48ePr1+/xp1C6hD3L4aEhKSkpCCEYHoPtKaWGFIjhDZu3KitrQ1rR4Iv3Llz59GjR9bW1mTdEStboqKiIiMjcaeQQ4o1pB4/fnxmZia5bQLZUl1dPX78eDc3N9xBpJSFhcXUqVOJfTc8PT3h3gPQOgoLC0nZ5+VrnTp1Kisra4mWgSxKS0tDCFlZWSnyIhgqKiqjR4+GnQpIp1hDaliXGjx//vzcuXO4U8iAzp073759m+hwr169yuFwcCcC8qyFZqmJyy+JiYlyf+cZaIyQkJAHDx4QQ2rcWTAjxkJeXl4wqiaRYg2pYV1q0KdPHwMDA9wpZIOKigqxJAiTyRwxYgSxjj3uUEA+lZaWttw/TG9v78DAwFevXrVQ+0D6VVZWCoVCU1PT6dOn484iRR4/fhwZGSkSiXAHkQdisZjJZLJYLNxB6kXykJr4R0Vum0BWcLlcHx8f3Clkkq+v740bNxBC9+7d27x5M8xYA9JlZWWZmJi0XPtOTk7Ozs7Q/yumc+fOxcbG0mg0eV12ujkmTJiQnZ3NZrNxB5F55eXlVKpU76ZCcrhp06a9f/+e3DaBrIiMjAwNDcWdQrb5+PjY2trGxsYihPLy8nDHAfIjKyvL0tKyRT+CTqfv3r0b7spSNJ8/f37//r2vry/uINLLwsLC398fKkCaqby8XFNTE3eKhtDJbU5dXZ1Y1gAoIDnbYxYXf39/4kFISAiLxdqyZQvuREDmcTic0tJSIyOjlv6gxYsXp6amfvjwgdhMDsi35ORkCoViYWEBizF/V0xMTEpKioODA+4gMozNZmtpaeFO0RCSZ6kjIiKgJ1VMW7du5fP5uFPIlV27dvXv35+YBEpOTsYdB8iwzMzMVrtdrEOHDubm5hcvXmydjwO4pKamhoSEdOjQQZpvF5MqDg4O165dq6qqwh1EVinckBpqqRXT9u3bLSwspHmbUBnVt29fYu+AkJCQ/fv3444DZNX79+9b+cZxIyOjrVu3tuYnglYmEAiOHz8u5bWt0mbo0KFjx46For6mUbghNdRSKyAulxsQEECswQlagoqKyvHjx4kZ6ydPnrx8+RJ3IiBjWnOWmtCtW7chQ4YQZ8HW/FzQ0goKCgYPHkzckIo7i0y6fv26jo4OzFU3gfTXUpM8pIZaagXE5/Nh1bxWYGtrixCysbEJDw+/d+8e7jhAlpSUlNjY2LTyhxJlo2FhYbdv327ljwYt5/jx4+fPn8edQraxWKyEhISsrCzcQWQMl8ttof2qyAK11KBZoqKitm/fDr9HtRo9Pb2wsDBifmj16tUvXrzAnQjIgNjYWHt7eywfvXz58sePH2P5aECuM2fOEH+gysrKuLPIvB49esA9nT8qJydHXV0dd4qGQC01aJb4+PjVq1fjTqFw9PT0EEKBgYHEdBFcWwcNyMrK0tXVxXjBdMOGDQihK1euxMfH48oAmmnZsmXt2rXDnUKuEL13YWEh7iAyo7CwUMoviUMtNWiWVatWwV2JuLRv33779u0Iodzc3MmTJ+fm5uJOBKTR69ev3dzccKdAAwcO3LdvX35+Pu4g4MeUlZUhhGbMmNG9e3fcWeTQuXPnoOtupMLCwrZt2+JO0RCopQZNVFVVtW3bNtwpAEIIOTo6Lly4MDExESGUlpaGOw6QLq9everYsSPuFIjFYh05coTBYFRVVRGbGQHp9+zZM2Lvnla+vVVxzJ07948//sCdQjZ8/vxZsYbUUEutOLZv3+7o6Ig7BfiXs7Ozn58fQujOnTvTpk2DbbqARHx8vKurK+4U/9LT01NVVT1//vzZs2dxZwHfd+3atdmzZ+NOIefWrFmDEPrw4QPuIFKNzWYrKysrKSnhDtIQilgsJrG56upqZWVlWKgSo5qamtZZnUckEv3oH7S2tjZUiTQTh8OpqKho+D18Pp+4WCQUCmX3qpGGhgaLxcKdQubl5+f/8ssvN27cwB3kS2/fvrWzs7t9+7aPjw/uLNKFz+cTtRZ48Xg8JpP5xZMqKipqamqYEkmXxnTFP6SiokJNTU0Kh0+amprSMJBNS0tbv349cc1EapH8hzdlyhRYF0YRiMViKfyXDwgMBoNCoVAolOrq6pqaGtxxAE5v3ryRzjGrnZ0dQohKpfbq1YvH4+GOA/6f6upqCoWCO4Vi0dDQ4HK5uFNIr9LSUum52lYfkkdFqqqqNBqN3DaBtBEIBOXl5bhTgO/T1NQk5pm4XC4sxaOYrl+/Ls3nof79+9+8eVMgELDZbFi+WnowGAy4otj6lJWVoaOuT2ZmpvT/nSR5SP3HH3+08ra3oPVxuVy49icriMIPOp1eUVEBBdaKhsvlPn/+3NPTE3eQhqiqqqqoqKirqz948ODQoUO44yi62tpahNDXJR+gddBoNDabDX311z58+CD9t+qRPKTmcDgikYjcNoG0UVVVld0KXcVEo9G0tbWJWp3q6mpy76AAUis6Orpfv364UzQKjUbbvHnzyJEjEUKHDh3666+/cCdSROXl5dJQNavgtLS0iOpK3EGkS3Z2tpmZGe4U30HykHrixIlQSy3fnj9/Pnny5KFDh757966Bt40ZM+b06dOtmAt8HzGkptPprVm3c+7cubFjx44aNaqB97x//97Pzy8lJaXVUimIO3fuDBgwAHeKH0DsYTRy5MgnT568ffsWdxz59OrVq/r68Lq3x23atGnlypU4AgJEp9MFAgG5o2pZ74oVcUjNYDDgrjU5JhKJTp8+ra6uvnPnThMTE9xxQFMoKSlpaWlt3rz55s2bxEXelsPn80+cOOHh4QFLmLc+DocTFxfXs2dP3EF+mJ6eXnBwMLEQ8qBBg06cOIE7kVw5c+bM1304l8sVi8VwK1Tr27x5899///318wwGg81mk1VaLetdcWVlJY/H09XVxR3kO0ge/p48edLS0pLcNoH0EIlEHA7Hzs7O2tpaWVkZdxzQdO/evaPT6WKxmMPhtNyn1NTUCIXCjh07wi0Wre/BgwfDhg3DnaLpiFuRrl69qqqqihBKTEx88eIF7lDyoLKy8os+vLy8nEqlwhIfWDRwvVdbW5usPxRZ74pzcnKkYQvY7yJ5SA03q0qb9PR0Pz+/9PR0yTNTp06NiIggHt+6dWvmzJnDhw8fM2bMxo0bi4qKiOfZbPaOHTsmTpw4fPjwhQsXJiQkEAt9DB06NDs7+8aNG35+fm/fvh0+fPjFixclLe/Zs2fevHmt/i0qurFjx169ejUiIiIwMHDEiBHr1q0rLS0lXioqKtqyZcuoUaOGDh06c+bMu3fvEs/7+fkVFhbu2rVr4sSJxNrPxBwAQujixYvDhw+XNF5UVOTn5/fs2TPiL0BERMTEiROHDRs2YcKE8PBwPp9PvC0jIyMoKGjMmDH+/v7BwcGFhYXEPthjx45FCG3ZsmXYsGEN/1UEpIuMjCR2/5FpdDr9559/RggZGhoeOXLk1KlTxO/2uHO1qgZ62uTk5KVLl44cOfLnn39esmRJUlIS8bxAIDh58uT06dN/+umnadOmRUVFEU/6+f0fe/cd1kTWNQD8pgIJVapIBxEFFBHFFRURBREVEbtgZdfeBeyAZbGAvaCCXey9rA17FxUFBaSodJAqpJGEfH/Mbt58CAFlYEI4v2effULKnRMzc3Jz58y9gyVzeEhISEhIiJqaGvYD5t69e4MHD27qk1fyqjGpGLuKQBKWislkclVVlUgkauWpOCkpSVtbm+go6odzl3r8+PFpaWn4tgmaSGJi4o4dO7y8vPbs2RMSEvLjx4+wsDDs62r16tVJSUkLFy7cvn27paVlcHDwly9fRCLRoUOHDA0N3d3dT548aWFhQfQ7AAjrc5w7d87IyOjQoUN79+5NS0vDqtj5fP7KlSuzs7NXrVq1d+9eJyen8PDwFy9eIISOHj2KEJoxY0Z0dDTWCJPJxKZElVK9d/bs2djY2Pnz50dGRs6ZM+fRo0dY/6awsHDp0qVkMnnDhg1hYWEVFRXLly+vqqqytbXdv38/QmjBggXYFkGzeffuHY1Gk6f1TbW1tSMjI7EfCdu3bw8LC4OpPDkcTkhIiJGRUURExNatW01NTYODgysqKhBC0dHRFy5cGD169J49e7y9vfft23fz5k0qlXry5EnJHF5dXd3afp80HVxS8c/odHpZWZnkx9QKU/HHjx+tra2JjqJ+UPfcen379k1BQWHAgAFt27a1srJatmzZX3/9hX0Zp6WlzZs3z87OzsjIaPr06To6OleuXGGz2ZqammQymUajqampwaQfssPQ0NDNzY1KpWprazs4OGBnEuPi4rKyshYtWmRra9uuXTtfX99OnTpduXIFIaSiooLNgaqqqoq1QCaTsTuxLnWtHWtsDiN7e/u2bdv26NEjLCwMm03ixo0bJBIpMDDQxMTE0tJyyZIl+fn5T58+pVKp4g2pqak1+79Kq3bs2DE/Pz+io8CfhoYGQmjhwoX29vbfvn1DCJ04cSI3N5fouIjx/ft3Npvdv39/IyMjY2Pj6dOnh4SE0Gg0Fot1/fr1ESNGDBgwQF9f39PT09XV9ezZs9hc9eIcjvWn4fInHDU+FdeqRgVIK0zFrbRLffr0aRi8bCk6d+5MIpECAgJu3ryZn5+voaGBrWeWkpJCo9E6d+6MPY1MJltbW2dkZKiqqkI3WjZJlscpKytjw1RpaWkKCgqS1zZYWFh8+fJFelPY92utq9k5Ojq+f/9+w4YNjx8/rqioMDQ0xC5vSklJsbS0FE9VrqOjo6enl56ejt/7A78mMzPzy5cvzs7ORAfShNzd3cU5avbs2diQbWtbK7Rdu3YGBgabN28+c+ZMWloahULp3LmzoqJiRkaGQCCwt7cXP7Nz5855eXk1KjrodDqkdHzhmIprkOxSt7ZUzOPxsrKyWkTfEg6n1svQ0DAiIuLs2bOHDh2qqKjo0KHD9OnTrays2Gw2n88fPny4+JlCoRDH6yQA7mpdl4HFYikqKkp+agwGo4F9Dmxu2rKyMsmLF/v3789gMK5duxYRESEUCnv27Dlr1iwNDQ0Wi5Weni55JRyfzxcXEYLmJ69D1LWaMGHChAkTxIXCQ4cODQwMJDqoZkKhUDZt2nTu3LmbN28ePnxYR0fHz8/P1dUVO8yXLl0qPvyx806lpaXiSxI5HA5cYo473FNxDZWVlSKRqLWl4pYyRI1/l3r8+PHiyY+ALPi5H4yVzGJMTU0DAwOFQuHHjx+PHj0aGhp65MgRJpNJp9N37twp+arKykqhUFhjiqUajUu2DAjHZDI5HI5IJBJ/TBwOh8FgSH+V5Geqrq4uvmIV07Nnz549e3I4nNevX+/fv3/79u0hISEMBsPa2nru3LmSz/z521r6rgjwwuFwkpKSVqxYQXQgzU1FReXx48dxcXEIoSdPnly5csXf39/S0pLouHAgJdOqq6v7+/v7+/t/+/bt4sWLERERRkZG2BwpAQEBNVabw6b9xnpatQ6R1Hp6CjRS41Ox+KNRVlbG7m9VqTg9Pd3BwYHoKBoE/xk/YMkfmYIdtywWC/uztLRU/Js1OTk5KSkJG+ro3Lmzn59feXl5aWmppaVlVVWVUCg0/A+NRtPQ0Ph5ylIGg1FZWSn+81fPZIEm1b59+6qqKsnLhZOSkjp06CD+s9ZDlcFg8Hg88XK4+fn52DN//Pjx7Nkz7E8lJaW+ffu6u7tjxaxWVla5ublt27YV7zAkEqlNmzY/t1zXrghwtH379hY9d14jYV+9vXv3dnd3x+Y0uHbt2u3bt1v0F1NdmTYvL+/58+fYbWNj4zlz5pDJ5G/fvpmammKzGosPSRUVFVVVVWwMVSQSUalUbKqfGi3DSm1NAZdULPnR3L9/v1Wl4mfPnnXs2JHoKBoE/3mpYYhapmhra6upqcXGxgoEgsrKysjISPFlEG/evFmzZs2TJ0/y8vLS09OvXLmiq6uro6NjZ2dnbm4eHh7+4cOH/Pz8+/fvz5s37+nTpz83bmFh8eLFi/Lycj6ff/r0aaxuDMgIBwcHIyOjHTt2pKSk5OXlHT58+PPnz1g9j4KCgoKCQmJiYnp6ujhlY7B6tdu3b2NTgWJzb5FIJCUlpYsXL27cuDEhISEvL+/9+/dPnjyxtbVFCHl4eHA4nC1btqSnp+fk5Jw8eXLmzJmSMzRhpOyKAC/fvn179erVzxNytUKurq5DhgxBCFlaWt6/f//WrVsIoZcvX7bEeULqyrTfv39fv379hQsXsrKysrOzT548SSaTraysmEymh4fHiRMnHj58iB2tK1as2Lp1q7hB8TilhYXF58+fsQmd4uLi3rx5Q9BblGc4pmLMrVu31q9f33pS8evXr7t37050FA2Cc+EHNrclkB10On3RokX79+8fNWqUjo7OpEmTvn//jk3HM2bMGD6fHx0dXVxczGQyO3bsGBoaSiKRKBTKmjVroqOj//77by6Xq6urO3bsWGxq2Br++uuvrVu3Tp48WUVFxd3dfcCAAZCRZQeVSl27du2BAwdWrlzJ4/FMTExWrVplZ2eHPTpq1Khz5869evUqKipKfDkLlscnTZoUExNz8OBBExOTmTNnzp07VyQS0Wi05cuXHzhwYN26dRwOp02bNt27d588eTJCSFdXd8OGDQcPHgwICCCTycbGxqtXr8YudZUkZVcEeImIiFi8eDHRUcgWS0tLbHpQ7MLNZcuWRUVFmZmZtYj1jTF1ZdrOnTsvXLjwwoULx48fJ5PJRkZGK1euxK5U8/f3ZzKZhw4dKikp0dDQcHR0nDRpErbkh+SY6ODBg9PS0gIDAykUir29/eTJk8PCwuCoxBe+qRghFBQUdODAgb///pvFYsl9Kk5MTDQ3N28pdf8kfE+HTZo0KSQkpIUuzyMf2Gy25Ik8XBQXF+OyEKiGhgb86GokLpf748cPYmOorKxUVlaWLA1sCqqqqti5adBAz58/P3HixK5du4gORNaxWCwmk+nr66uoqBgVFVVRUYFNMSYj+Hx+aWlpEzWOvffffjmDwZDs9rVmhKdikUjEYrGa4eNQU1PDLlgnxOHDhysqKmoUiMssnAs/uFwuLKAoZ4RCIYGHE5BBWBLHThoSHQv4n/Dw8CVLlhAdRQuA9SmPHz++Zs0arCLZycnp9OnT2FcY0dE1rcb0p4FMIZFIDAZD7ustX7161aNHD6KjaCicu9QHDx6UnHwRyAEKhQLDEuBnNBqNSqXCFAEy4urVq25ubjVmeADS6evrY5UhsbGx2Cxd165dmzBhwtu3b4kODX8ikQh+A8sZ8RJdcozH4zk6OhIdRUPhXEsNv4Dlj1AoJJPJMCk1+Jm4MKOsrExVVRWWYSNKUVHRrl27sCvwwG9QVFTEFm8fOXKkjY0N9kNxy5Yt2dnZ8+bNk48fKmw2++dZm4AcEAqFbDZbLvvWDx8+bFnLPeL8Fejv7//161d82wTE+vHjh8xeuABkhLKysnhKJtD8AgMDN23aRHQUcsLKygpbl3HevHleXl7YyO6WLVvWrVuHzVzWQtHp9JZyjRf4JRQK5bfXjpFxDx486NevH9FR/AKcu9QVFRU1JoIBLR2ZTIaxDSAdlUrFxki4XC6UgjSzEydO2NjYdOnShVQUmy4AACAASURBVOhA5A2VSnV2dsZGr6dMmWJtbY11qQ8cOLB9+/bi4mKiA/w1cGm4HMN61URHgb8W16XGufBj3759UHdLOHyLNNTV1XFsDTSeLBfhKCkplZSUkEikWhfm/SWy/DZlR35+fkxMjOSctaApaGhoeHt7Y7c9PT3v3r2blZWlqam5fv16bW3tKVOm4NhhJZFIuO/8ZWVlDAaj8UclFHdJkrUchY1oyPgk0w337t07c3PzlvV2cJ5ED8iZkpKSyspKIyMjogMBLUlRUZGWltbJkyfHjRtHdCxyLjg4ePz48ZIrsYHmlJyc/PDhw9GjR2toaMyePbtnz55+fn5EB1VTZWWlp6fnw4cPiQ4ENLnXr18XFhZ6enoSHQgODh06pK6uLv4p2yLg/Itz+vTpUEstT86cOQPXPIFfpaWlhRAqKCjYsmUL0bHIs/DwcCsrK+hPE8jKymr69OkaGhpYcQifz8dm5ZsxY8b58+eJju5fdDr9n3/+IToK0By6d+8uH/1phNCpU6f69OlDdBS/BucudVlZGdRSyxMVFRUHBweiowAt0oIFC8aMGYMQgrKEpnDnzp2ioiI4DyA7HBwcpk6dihBq27bttGnTsDvj4+P9/f2vXbuGzcxASGA8Ho9KxbnIE8iy6OjoI0eOEB1Fo8TFxZmYmGCjMy0IzoUfxcXFampqcPQCAMTu378fFRV14sQJogORH4WFhZMmTYKhxxbh3bt3379/d3Nze/z4cWRk5OjRo728vHg8XrMtoeXu7n7ixIkW1zsBjfHq1Ss1NbWWewprzZo1Xbp08fLyIjqQXwO11ECaFy9e2NnZwbrQoJGw6uq4uDg46YELT0/P6OhoPT09ogMBvyY5Obm4uNjJyenhw4dbtmyZNGnSiBEjysvLm27y3fz8/MDAwKNHjzZR+0BmsdlsKpXa+GtSCeHk5BQbG9vi+h44F37MmjULaqnlyeLFi4kOAcgDbIRMXV3d2dm5oKCA6HBatuDg4KCgIOhPt0RWVlZOTk4IIWdn5927d2OLDb9+/drZ2fnq1asIoezsbB6Ph+MW9fT0oD/dOjEYjKVLl7bEy1Lv37/v5ubW4vrT+Hepi4uLoZZablRVVdnY2LTE3RrIJgsLi+vXr2dkZBAdSAu2bds2CwuLvn37Eh0IaCwDAwM7OzuE0IABA65fv25ra4uVkLq4uNy+fRsh9P79+6ysrEZuhc/nw5dyq7VlyxYOh9Pilig6d+6cu7s70VH8DqilBgAQYMyYMUFBQfb29kQH0pKcP38+JSVl+fLlRAcCmlZZWZm6uvr58+ePHTsWEBDg5OR08+ZNDQ0NBweHX114a+XKlU5OTh4eHk0WLJB1fD6fSqXK2izadcnPz582bVoLvagd51FqTU1N6E/LDS6Xm5CQQHQUQD4dO3bszp07REfRkrx8+TI2Nhb6060BtsCWj4/PpUuXHB0dsV7RkSNHPn36hBCKioq6dOlSA5cp5fF4sLBAK0ej0QYPHlxYWEh0IA1y4cKFESNGEB3Fb4J5qUGdMjIyNm3aRHQUQD7R6fSgoCCE0I4dO54+fUp0OLIuOzv71KlTe/bsIToQ0NywUaqhQ4fu2bMHKw4xMzNLSEgoKipCCAUGBm7btg2bD7tWmzdvtra2bt6Qgcz5559/Xr16RdQ0jr8kMTERutT/gnmp5QmDwejXrx/RUQA5N2vWrNOnTxMdhUwrKyubNGnS1q1biQ4EyIT+/fuvWrVKX18fITRx4kRNTU1sxNrLy2vBggVYMWdZWRn25LS0tOrqaqJDBsTz9PR8//490VHU49atW+rq6tjaSS0RzrXUZWVlysrKUPsBAPhVR44csbGx6datG9GByJbq6mpHR8fXr18THQiQdaWlpYmJiU5OTmQy2dXVVUND49y5cw4ODnv37rWxsVFSUiI6QECwoqKiCRMmyPKKyJMmTQoICLCxsSE6kN+E8yi1uro69KflBpvNbnFXCoOWa+zYsfv27cvLyyM6ENni4uJy//59oqMALYCGhkafPn3IZDJCKDY2dseOHVwuV0VFJTo6Gltls6ysLCYmJikpiehIATG0tLTOnz//8uVLogOpXWJiIkKo5fan8e9S+/v7Qy213IiLi9u4cSPRUYDWQkFBYf/+/TQaLTs7OyUlhehwZIKHh8eFCxeUlZWJDgS0PPr6+oqKivfv34+MjLx06RJ2iOXl5cXExCCEvn79unLlSuwSYagMaT2UlZW7du2KFeLLmpiYGF9fX6KjaBScu9QVFRVQSy03NDQ0OnXqRHQUoHXR0tLS09MLDQ198+YN0bEQzN3d/dixY5qamkQHAlqq6urqnJwc8Z9KSkqLFy9eu3Yt1uF2cnIqKSnBlkz38fE5ceIEVhtQUVFBaNSgadHp9MTERFlbxy0/P//9+/cDBw4kOpBGwbmWmsViKSkpYSeeAADgt71586Zbt26lpaUt91KVxnB3dz9x4gS26iQAv6e8vHzVqlU7duyo95lfv34tLS3t2rXrixcvli5d6uvr6+/vHx8fz2azu3TpwmQymyVe0HwKCgoqKyvNzc2JDuRfmzdvNjQ0HDt2LNGBNArOfV8mkwn9abmRm5v7/PlzoqMArRR2nWJgYKDMVv41nWHDhl2/fh3606CRKBRKA69uMjEx6dq1K0KoZ8+eDx48GDVqFDan9cmTJ7EJeWJjY/fs2ZOWltb0UYPmoKury+fzP3z4QHQgCJt2/eXLly29P43/KLWvr++aNWvMzMxwbBM0s6FDh+bk5JDJ5OrqavH/hULhu3fviA4NtEbYzP8ikUhy9S93d3dZvm69MXr37n39+nU1NTWiAwEt1V9//RUXFyfO3tixU11d/fbt299uMzs7+9atW3p6ep6enjExMffv3/fz8+vbt29xcXGbNm1aysp8oIadO3eqqKhMnjwZS6oUCuXGjRvNH0ZkZCSFQvnzzz+bf9P4wnlEmc/nw4UOLZ2fnx+dTkcIYSccsIzco0cPouMCrRQ27X9wcPCDBw+we7y9vYuKipYsWUJ0aDjj8Xjjxo27c+cO9KdBY8yePVtbW1ucw7H+biOHugwMDKZNm+bp6YkQGjVq1MyZM7G99MGDB927d798+TJWrBUXFydl3Rkga+bOnevr6ysUCl1dXYuLi8vLy69cudL8YTx69Gjq1KnNv13c4dylPn78uOyU5oDfM2LECGwRATF1dXVsDiYAiLJmzZqrV69itzMzM0kk0rt37+TpEsaysjIXF5eYmBiYPxg0UpcuXaytrSVPQZNIJBzX7aLRaPb29l26dMFWTY+Li+vbty9Wun3gwIF79+4hhKKjo3fv3i1ecQbILCqV2qdPn/LycoQQl8t99OhRMwdw5MiRnj17UiiUZt5uU8C5S02j0eAEUEtHpVJ9fHwkK/Dat28PyygCwkVERCCE+vbtiyWZsrKyqKgoooPCR35+vo+Pz7NnzyB/AlxgqyqK/zQ2Nh49enTTbQ67hrh///779u1zd3dHCP3xxx9KSkpYl3r06NGTJ0+urKxECCUnJ2M3gIzo1asXtvom9tMrNTWVzWY3ZwAHDx6UjyFq/LvU06dPh3mp5cCYMWMMDAyw2wwGY8yYMURHBADCllwWp3sSiZScnHz79m2ig2qsL1++TJs2LTY2luhAgPyws7Pr3LkzdhsbotbR0WnOADp16jR16lQTExOE0IkTJxYvXowN0xw/ftzT0xO7zPHSpUt37tzhcrnNGRiQ5OjoKO5PYyorK+Pj45stgNOnT3t6esrN1Ps4d6nLyspgXmo5QKVSvb29sRMxZmZmLi4uREcEAEIISU6yixD68eNHdHQ0ceHg4NOnTwEBAdevXyc6ECBvfH19sYHqdu3aETssQqPRbG1tFRUVEULr1q17+PAh1tWm0WixsbHp6elYZVdISAi2BAlMjN1svL299fX1FRQUxGVCZWVlr169arYA5GmIGiFECQkJwbG5Pn36tG3bVj5qYlq5jh073r59WyAQzJ8/39TUlOhwAED9+/cXCAQikQibwQD7P4/HU1VVbaFrEr158yY8PPzUqVNEBwLkkJ6eXnx8/NevX4cNG+bq6kp0OP8Pdt2kpaXlgAEDsOFzY2NjCoXStm1bZWXl2bNn796928vLS0FB4cqVKyQSCRY8aiK9e/f28fExMTGpqqpis9kcDqe6uprH4/n4+DTD1i9fvkyn0z08PJphW80D50n0mh+XLcxKYf8oFrArhUTHIm8+fvz45cuXIUOGEB2IvFFQJCspUzT1afpmDKJjqZ9QIPqSyCov4svCIZadnf3jP1wut7q6WigUUiiU4cOHEx3aL6uqqnr06NGAAQOIDuSXKTEpyuqUtmaKapp0omOpX3EerzCTx/oh5LCI34GbWXFx8ePHj93c3BiMFpBqJHE4HDqdTqFQXrx4wePxnJ2di4qKkpKSDAwMTE1NBQJBvfNtM5QpKm2oBu2VGCoNmpmbWAXfuN9zeewKIY9N2JxpFRUV3759y8rK4nK53t7ezbDFf/75p2/fvrK/kBCFihjK1Db6NCPLekLFuUsdFBQ0d+5ccRluU8tIqHx9u5SpTtMzVhIKW/ZvA9B6UOnkkjyuUCCiUtGA8bpEhyNNZgr70YXv6tp0XWNGdTUcYgAhhGh0csE3Dr+q2tBSsWs/mV7b8uXNkuK8KjKFpGOkxOfBBK+tCIVKKvjG4VQIOvdRs7RXITocaR5d/M6uqCaTSVrtFPlVsJfKHDKFVFFcxeVU8zmCoX/pkyl1XkSO86+3r1+/NtulBpnJ7A9Pfgz2N2yezQGAK1WEUOKz0jsxBQNltVedk8Z5c7fUa5Yx0YEAmdPeXhUh9OBMHkOlokM3Ge2vvLtfWvad32eEHtGBAGJ0cFBDCMXG5NIVyCbWMjoU+uRykUhEcvKS0W8BICn7M+vi7hyfeXWOGuN8eWJoaGjzDFH/KOHfO13oOl6/Ac8FQEbZ9NJQYFBf3iwhOpBacFjCGwfzBvi2IzoQILv6jW6b8KQ8J41DdCC1SHtfmZXK6TUMeiqtnet4/QfnC18//SSDcyd8eFzGqay2d9UiOhDQIAaWzPbd1G4eya/rCTh3qa2srLCrepva+0dlnf5Qb4YNAdCkrHtpfHgki6shvH9Y2vEPWMMP1KPTHxrxD2VzBy6z/kOmi1JAs7Ht3ebm6eSbN29iM/rt3r27oKCA6KAQ1pOx7gV7aUtiaqOSm8Fh/ah9iVCcu9Tr1q3Lzc3Ft81aleTzNfQUmmFDADQpugKZoUotL5K5JXxL8gWabWEZP1CPNm0VSgurGvDE5lZeDN8R4F+abRU7mffALrXv1q2bkpLS9+/fEUKLFy8eM2ZMamoqQig+Pj4rK6s5o+Lzqvk8kUobWnNuFDSeloHi9+zakx7OtdQJCQnNs+4Oq0ygoAhT9QF5QKWTOZVCNS3ZSqyscoGCIs4/uYH8UWRQfhTL3Pl0oUDEZVXT6LADA4QQUmBQKsv/3UutrKysrKyw2xEREWlpaerq6gihZ8+e3b59e926dTY2Nvv27VNWVvbx8WnSs+5cdrWUC92AzKIrkDl1zH+Fc8ZZtmyZvj7UNwMAAABA1llYWGhpaSGEZs2adenSJWtra6zbXVBQgK2mPnbs2GnTpmGrzyQkJMAyNEAKnEep7ezs8G0QAAAAAKAZkEgkhJCzs7OzszN2T1RUVFpaGjYN9sGDB9+9e3fz5k1FRcVt27ZZWFg0fN2GXr16dejQITg4GFs5EsglnEepN27cmJ9f57WQAAAAAAAthbKysp2dnZKSEkJo69atDx48UFBQQAjp6uq+e/cOW5Vm+PDhwcHBCCEej5eWllZrOzwe78OHD/Pnz7948WKzvwnQTHAepX779m3zrGMJAAAAANDMsJHscePGYX8qKSnt3LkzMzMTIcTn81esWMFms69evfr9+/erV6/a2dnZ29uLX5iTk7Nnz56PHz+uXLmS0DcBmgTOXeqgoKC2bdvi2yYAAAAAgGwyNDQ0NDTEhrRPnz6N3clgMDgczr179+zt7QcPHox1xBFCpaWl165dS05OXjBnGUIyugAN+D04d6nFv8YAAAAAAFonJpM5e/Zs7DadTpd8SCAQJCUlhYWFDbVfR1B0oEngXEsdFhaWl5eHb5sAAAAAAC2UeJ4QkUgkEolUVFQMDAxgOgf5g/ModXx8PIvFwrdNAAAAAIAWqrS0lEwma2pqampq9u3b19nZuWPHjhWlgvM7sokODeAJ5y51cHBwu3bt8G0TAAAAAKCFwsqpe/ToYWBgQHQsoAnh3KXu1KkTvg0CAAAAALRcUVFRRIcAmgPOtdQrV67MzoYTGQAAAAAAoBXBuUudmprK5XLxbRMAAAAAAABZhnOXOjw83MjICN82ZdCFi6ddB/YgOorf14Liv37jkourg0AgIDoQIEOEQmHomqUenr1XrV5CdCwtWwtKBS1LcEjg4iUziY4CgN+Xn583c/Ykt0F/nDsfQ3QsLQbOXWpDQ8Ma8y+CWoWEBt28dZXoKMD/c/HSmQ2bQhrTwpcv6WPHD8Evoham2fbqDwnvHjy8O3PGwpkzFzbD5gBofsNHDMjLzyU6Cvw1Pks0PlG3aM22Y/xz8/K3bxmbN+7u7+LeDJuTDzh3qWfNmvX161d825RLnz8nER0CqKnxH0or/1ib7e3/+FGOEHLu66rfFuYXAnKooCC/vLyM6CiaBKTZxmjOHaOi4oeubtsuXezbtNFsni3KAZy71MXFxTJ7jr6srPTvDavHjPMcNNhp1pzJ7+LjEEKv4164uDp8+pQgftqnpEQXV4fXcS8QQndjb/41fcLgIX28vF2Xr1yYk1vLlZcenr1Pnzkm/nNz+NrpM3yx26WlJX9vWD1y9CB3j16+E70vXDiF3e/i6pCXn7txU+hQr37YPbH3bs2Y6efh2XvESLdduyPqrUcfOXrQ0WP/XkFcXFzk4uoQumap+FGfUe6nTh9FCH1OTQ4MmuPl7eo5tO+q1Uvy8/+3Cg+JRPr0KWH6DF+3QX+MnzDszp0b9f4DFhTkh65Z6u0z0N2j16QpI69euyB+qK74hULhocORvn7D3T16jRrjsW37Bg6Hgz00fMSAc+djgpbNcxv0R2VlJUIoKSlx3gL/QYOdRo8dHLlve1VVlbj97OzMOfOmug36Y+ToQQ0c4bh+49KkKSMHuvccNrz/+r9XlpQUY/cvW7Fg2YoF4qfduXPDxdWBzWYvWPTXzVtXb9265uLqkJqWcvbciWHD+7+OezF56igPz97jxg+9desa9pLTZ455ePYWt1BYWODi6vD8+ePDR/Zt2BRSUJDv4urw4sWThgQpT2rs1SGhQaFrlh46HOnh2fv588dSjqbLV84NHzEgKSlx5uxJQ4Y5j58w7MY/l7GHat3log/uCQkNwnahwKA52EcQumbpMC+Xge49p/qPEe/MX76ku7g6PHv2aPLUUTNnTUQIefsMPHc+JjxinZe369Bh/fZGbistLVmxatEwL5cx4zwbsmsJBIJt2zcMHdZvyDDndetXPHh418XVobi4SHoqEAgEh4/smzjZB0sFl6+cEz9N8kCI3Ld9yDBnycP//PmT7h69Kior6oqngamg1uyH+Y1UIK9qTZhR0buHDHPm8/nip508dQTLWlLym1hyyicXV4fklE/ie3z9hu+N3CZ+dEnALC9vVw/P3jNnTYx78xIh9C4+DjvZNX7CsJWrF0vff+ry884vJdqiou/LViwYNNhp5OhBp04fjT64Z9KUkfVuoqqqam/kttFjBw907zl2/JCo6N3Yt7+Ut1wjS6xYtWh1cMDpM8fGjPN09+g1fYav+FV1HU2SiVqc1VuJzMyvkjvGL33E3j4DL1w4tTdy26gxHkOGOS9bsQDLWgihDx/ezVvgP9Sr3+AhfebOn/b+/VuE0Nz50y5eOvP1a4aLq0PMycMIoYSEeOwL2sOz96LFM5KSP2Ivr5HqsXz+Lj5u2p9jPTx7T/tzbFra51u3rvlO9PYc2jdo2byystJ632lCQvy0P8e6Dfpj0pSRjx7fmz13SsSW9fUeTXVluYuXznj7DHz69KG3z8AdOzd5ePY+fuKguAWhUDh8xIADUbtw+Yxw7lIfP37c3Nwc3zZxUV1dHbR07sePH4ICQ/btPW7VodPSZfMyMtLsu3ZXV9d4/OS++JmPHsWqq2vYd+2elPxx/d8rHR2dIvcc2xC2g8vhBIcE/NJGN4Wv+fTxw6oVf0ftPzl+3OTde7c8efoAIXTm1A2E0Nw5AcePXUYIPXnyYN36Fd26OR7YfzIwIPjR49iIreult9y1a/fExHjs9vsPb3V0dBP++zMr61tJSXG3bo4FBfmLFk8nkclbI/ZFhEf+qChfHDBT3E8lkUi79kT4+frv2B5tZWUdtjE4IyOtnrezObSo+Pvf67cdjD4zwnvstu0bsB8eUuI/dz4m5uThqVNnRR84FRgQ/PTZw6iDu7GHqFTq1WsXzEwttkbsU1RUzMvPXRI4S7+twZbwyLlzAm7euro3civ2TAqFsmPnprGjJ+7aeairnUN4xLrv3wulh3r79vXwiHVuAz0PRp1eE7L5c2rysuXzRSKRlJesW7PFsr1Vfxe3SxfumplaUChUFqvy7NnjEZv3Xr54z83Nc+Pm0MxMaWdgxo6ZNGLEWB0d3UsX7jo49JQeofypsVfTaLSML2mfU5M3/L2jUydbKUcTlUplsSqPHo8KDd509fIDNzfPrdvCsI+41l1uwvipgQGrEUJHD59fvWoDn88PCJqdlf1t7ZqIQ9Fn+vbp//eG1U+fPsRiQAgdObp/zGi/gCWrsW2dOXvcqZfzpQt3//xz7pmzx5cumzd+7OTLl+65uw3Ztn3Dj4of0t/miZhD129cmjVrUeTe4zY2dpH7tmHNSn9V5L7tp88cmzBuSnTU6VEjJ+zaHX79xiXx2xcfCEM8vVks1rPnj8QvfPg4trdTPxVllbpabkgqqCv7YU/7jVQgl+pKmP1d3Fks1pu3r8TPfPQotqdjb2VlZSn5rSF4PF7Q0rk0Oj188569u492su68avXi798LbW3sVq8KQwjtizy+LGiN9P2nLj/v/FKiDd+yLjU1ee2aiI1hO99/eHvv/m0yuf6+wbbtG/65eWXG9AWHD52bNnX2xUun9+3fIf0lNbIElUJ99+51bm720cMXzp29paamHhIaWF1dLaUFyUStodGm3iDlSbt2hpI7xi99xFQq9eTpIyYmZidPXD0YdSY1NfnY8SiEEIfDWb5ygYmx2a4dh/bsOmJu1n7p8nk/Kn6Erd8+2MPLyMjk0oW7I7zHZmV9WxI4S1tLZ/fOw7t2HFJiMJYEzCwsLPg51WP5/Nq1C9u2Hjhz+h8+nx8cEvAuPi5q/8nDB8+lpHw6c/a49LdZWVm5YuVCNVX1PbuOLA0KvXTpTHZ2Zr05VkqWo9FoXC7nwsVTQYEhI0dOcO474M7d/w0cxL9/U15e5u6GT8Umzl1qGo1GIpHwbRMXcW9efk5NXrJ4pX3X7sbGpnNmL9HVbXvh4ikKheLc11WyS/348T2XfgMpFIqhgXHk3mOTJv5lZGTS0cp6pM/49PTU0tKShm909qzFmzbt7tLF3tDQeLCHl4W5ZVzcC4SQqqoaQojBYKipqiGEYk4d7tLF/k//OQbtDHs6Ov3pP/fu3X+wnbUuDvaOn5ISsNTz/v0b1/6D2GwWNuz3IeGdmpq6hbnllavnSCTSyhXrzcwsrDp0Wr50bV5ezsNHsVgLAoFgoq9/7979rDp0WrRwBZVKvXf/lvS3k/ElrbvDHx2trNvpG3gNG7lrx0Fzs/bS4x/g6rFv7/H+Lm4GBkbdHXq69HPD/gWwL3JFBcXpf82ztu5MpVKvX79IpysELFnVqZNtn94us2YsFA8LCYXC0aP9evfuZ9neavLkGUKhsN4Tf2fPnXBycp4wfoqhobGdXbe5cwI+pyYnJr6X8hJlZWUKlUqj09XU1CkUCnaI+vn6a2pq0el03wnTFBUVY+/dlNKCoqKiAl2BRCKpqanXe/zLnxp7tQih3NzspUGhXbrYq6mpSz+aBALB+LGTdXR0SSSSxyAvgUCQnv65rl1OUVFRSYmBbVFZWfnly6eZmV+DAkO6dLE3MDCaPGm6jU2Xi5dOI4QQiYQQsrNz8Bg0zMzMAtuWhUWHP/7oQyKRsALBTp1sra07Y3/yeLzsrG/S3+btO9d7O/XzGDTMoJ3hcK9RXe261/svU1lZefnK2TGj/dzdhxi0M/QaNtLdbQg28FPjQDAwMOpm30Oc7ouLixIT3w8aNExK4w1JBXVlP/E//q+mArlUV8I0M7MwMjJ58t93REFBfnLKJ1fXQdLzW0NQKJStEfuWBoa0t+hgYmI2dfJMLpeb+PE9lUplMJgIIRUVVSaTKX3/qdNPO39d0ZaUFL969cx3wrTuDj3NzduvXL7+RwNKC8rLy27fuT7Rz7+/i1s7fYOBAzxGeI+9dv2C5HD+z2pkCYSQsFo4a+YiBQUFFWWViX5/FhTkx79/I6UFyUQtm52NpkOhUCR3jIZ/xBhjI1OPQcOoVKqOjm6P7r1SUj4hhAoL81ks1sABg42NTU1MzObMXhK2fjudRldWVqbT6WQyWU1NXVFR8fKVc0pKjGVL15ibtzc3b79i2TqBQHDr9rWfUz2WUsaMmaiirKKirOLYwyk3L2fG9PmKiora2jpd7RzS0lKkv83nLx5XVFbMmxtoYWHZ0co6KDAEq/STTkqWI5FIXC53pM/4no5O+m3beQ4enpn5VTzU/ehRbKdOtkZGJo3+fBD+S734+/uvXLnSxASf4HCUlJRIo9HsunTD/iSTyZ1tu2IfbT/ngZevnPvyJd3U1PxzanJuXo5r/0HYoZuXlxMVtSsnJ4vL4wr4fKy6qOG/jJUUlWJOHY6PjysvL6uurq6o+NGunWGN51RXV3/+nDR50nTxhfqUpgAAIABJREFUPViQGRmpOjq6dbXctWt3FouVkZFmYWEZ//7NzOkLkpM/JiS8a6dv8P7DW4dujiQSKSkp0aqDtXh8S1dXr23bdmlpKQMHeGD32Np2xW4oKyubmphLH4JFCPX6o+/JU4crKyscHZ0623bt2NGm3vjV1NRv37kevmVdUVGhQCDgcNhYZwhjbd1ZfPvz5yTL9lZYXxYh5Obm6ebmKX7UxroLdkNdTQMhxOawpcQpEAjSM1JdXNzE93To0AkhlJb+2dbWTvp7rKF9eyvsBo1Ga6dvmJOT9Usvb+UMDY3FX5z1Hk1mZu2xGyoqqgghrNSh1l2uhtS0ZAUFBQtzS/E9lpYdY2P/9+OnUyfb/xeVgbE4JISQoeG/yQr7rqpkVUp5R3w+Pzc320Oij2tj06XecpH09M8CgcCh2/9OXHTp0u36jUtsNpvBYNQ4EAYPHv532KrS0hINjTaPHt/T0tLuZi9tRo4GpoK6sh/mV1OBXJKSMF36uV2+cnbRwuVkMvnR41gmk9nTsTdCSHp+qxeVSuUL+Dt2bkpL/1xZWYGdRvu591Dv/iOF5M5fV7Q5OVkikUicY5lMZrdujt8yv0hvOT0jVSgUdur4v/Y7dOjE5XKzszMb/i+A9fMUFBSw2yYm5lg89l3r/6UKMA35iDHiHIulWeyMnIGBkaGh8fqwlcOGjnRw6NneooOdXbeft/I5NcmyvZV4qIjBYBgaGmMDHzVS/b/3/JdmmUymqqqaurrGfy9kFhTmS39HmZlfqFSqiYkZ9qeurp6Wlna9/w71ZjnxP5StrZ2RkcmduzesOnSqrq5+/OT+lMkz6m2/gXDuUldUVMhmLTWbzeLz+e4evcT3CIVCrOi+c+eumppaj5/cNzU1f/QoVk+3LfYNd+/+7bXrlvv5Tps7J4DJVE5IjJcsUqyXQCAIXDpHKBTOmb3EyNCEQqFgVXE1cLlcoVB4+Mi+o8cOSN5fXFIkpXEdHV1DQ+OExHhNTa3s7EwbG7uk5MQPH94Nch/64cPbSRP/QgixWJWpaSlug/4Qv4rP50s2y2QyxbcVFBW53JpVgDUsXLDMzNTizt0bZ8+dYDKZw4aOnDplZlVVlZT4d+7afOfujYXzl1nbdFGgK5w8dURyAIzJVBbfrqj4oaOjV9emFRUVsRv/DktILeHgcDkikQjrIWEYSgyEEEdqR1z6dhFCikpKUkpawc8kP996jybx1+q/RKK6drkaZwAqWZWKikqS41VMBpPNZtUaBkKoxpRENbYrvTqIw+WIO9+YhnShsGAWLp4uDhLbSklpMdYlkoywT28XZWWVe/du+fiMe/Qo1m2gp/RT8A1JBVKyH+ZXU4FckpIw+7u4HTm6PzHxfefOXR8+iu3t5ILtNtLzW72yszMXL5nR1a778mVrtTS1q6urR48d/PPT6t1/pJDcteqKFrvcTUmiKdX/3z2qFRbVz8cCh8Mm/zcy0hCSRxCWbyshzf6KhnzEmBq5DtuZKBTKjm1RJ08duX794oGoXbq6elMnz5Qcz8Kw2SzNNlqS9zAk0myNHCuuO8L86ixwbA5bcr+qsZvV+ar6s9z/gvQcPDzm5OGZ0xckJr5ns1ku/dx+au834dyl3rp1q7Z2/b8nmh+TqUyn0w/s+3/TK2LfVWQy2dl5wJMn9yf6+T96fK9//3/ni7l+/WJXO4epU/6dW5RXxyWDNc49VVXxsBtJSYkZGWnbtx7o3PnfEaDystK2evo1Xq6oqEilUkd4j/UcPFzyfvX6xsLtu3b/+PG9hkYbM1MLZWVlGxu7HTs3FRTkFxTk23ftgb1lW1u7xQtXSL5KMn9xuVxxl5HL4Wio17NFKpXq4zPOx2dcSUnx7TvXow/uUVfXGOkzvq74hULhjX8u+/n6Dxz47/cEq+4hQDV1DcluUGMoKSqRyWTJ1lhsVq2HPUKI99/nVSsOh6OkpITdZrNZerptpXziQIoGHk011LrLjR7lK/kcZaYyh8MWiUTiz4XFZtX6WTeeooIiQkiyx1khUXtd146BBbNi+TozUwvJJ+ho13IaikajDXD1uP/wTv/+7h8S3i1etOLn59TQkFRQV/bD/GoqkEtSEqaRkYmZmcXjJ/f19Q0+fvyA/VBpYH77uTiBy/t35793/7ZQKFy5Yj3W1ykoqH307pf2n7pIiZauoFDjkKyo74oCcVSSaZb9X5oVv0Gxn++p8ap/Q2KzxOepIM3+ql/6wpWkrq4xc8aCmTMWfP2acebs8bCNwcYmZh0sO0o+h8lUrtEai1VZo5ONF0WFmr/qxTuklKOp3iwnyd1tyIGoXe/i454/f9Sntwt2xhIXONdS6+vrS/46kR1WVtbYeKqRkQn2H52uoKWlgz3q4jwwNS3lzdtXWVnfsKoPhFAVvworDMJgdbQ/D2IxGEzJX9XpGanYDayvJv65//Hjh7z8XMmXY7fJZHL79lYFBXniwNq2bUehUlVVVKW/o27dHBM/vn///k3nLvYIoU4dbXNzsx88vGNkZKKrq4cQ6tjRJicnS1/fQNwyiUTS1PzfMSC+jInNZmdmfRWfZ6lVZWXlnbv/YKcg2rTRHDtmYqdOthkZaVLir66uFgqF4n8B7LqrukYB21t0SEpO5PH+zZu3b1+ft8Bf+nUqdaFSqRbmluJ3hxD69PGDuPxDman8/z6v/05dYWqE9/6/qj42m52Z+RUrEmAwmFwuV3w2Ju3/t9DK1fX5NvBoklTXLlfjaR0sO1VVVX1OTRbf8+njBysr60a/lVrQ6XQ93baSJxMTEt6Jb9eVCszM2tNotNLSEvExoqqqpqamXtfgjefg4R8/fjh3PqZTJ1sDg/pXzqo3FUjPfr+aCuSV9ITp0s/txcsnT5891NBog5UlNDC/MbGCov92jNLSEvFMC3x+lYKConjsUPKSKQzW2q/uP7WSEi1Wjpic8lH80Js3L+tt0MysPYVCSfz4vwtUPn78oKys3K6doZS3LPm+MF++ppf/V+uCXSRj9F+arfVo+rmFVqjWt/9LX7hiuXk5T548wG6bmJhh1U1fv6TXeFoHy04pn5PEhfIVlRWZmV+bKM0aGZpUVVV9+/Zv6VFW1jfxVTdSdq16s5wkNTV1p17O9+7devgo1t19KI7B49ylXrZsWXZ2LTPNEa6bfY/2Fh3+DlsVH/8mLz/3buzNv6aPv3zlLPaotXVnXV29vZFbzcwsxJcxdbSyiYt7kZSUmJ+ft3VbWJs2WgihlJRPNWa4s7Ts+OTpg/LyMj6ffyLmkLgSzsLckk6nX7h4qri46HXcix07N3V36JmV/a20tERBQUFBQeH9h7epaSkCgWDsmImPHt+LOXk4K+tbalrK32Gr5s2fxmLVM2RrZ+fw/Xvhs+ePbG3ssFO35mbtL1463a2bI/aEoUN8OBz2xk0hqWkp2dmZR49FTZk2Ovm/iW+oVOrxE9EJCfE5udl79m7h8/ni3xK1IpFIO3ZuDI9Yl5qWkpuXczf25ufPSVjRVV3x02i09hYdbt2+lpObnZ6eunzlAkdHp4qKH5mZX3+uDhriOUIgEKz/e2Vi4vsnTx7sO7DD2Mi0IVed12rUKN8XL56cOXs8Pz/vXXzczt3hXbrYW3XohJVHJyd/TE9PFYlEL189e/36ufhVKsoqaWkpqWkp2JlQCoUSc+pwQkJ8Vta3bTs2IISwa5IsLTsihLCJ3jIzv16+fFbcgrKySnFx0YcP7xoyT5CcqbFX13i0gUeTJCm7nKQePXoZG5tGRKxLSv6Yk5t9IGpXcsqnUSMnNM27RK6ugx4/uX/l6vmMjLSYk4cluxR1pQJlZeUhQ0YcPrLv3v3buXk57+LjlgTOkrJWhampeceONqfPHBvUsFxfbyqQnv1+NRXIK+kJ08XFLTs78+q18/36DcQu+WhgftPR0cMqXAUCQUVlxY6dm8Sdno5WNuXlZf/cvFJcXHTp8tnklI/q6hrp6Z8rKyuxIZUXL558/Zrxq/tPraREq6ujZ9ne6sSJgx8/fsjM/Bq2cbVGA+YhVlNV8xg07ETMoSdPHhQU5N+6de3ylbM+I8ZRqVQpb/nnLKGiohoevvbr14yUz0n79m9v184Qu+KlrqNJMlHXO9us/JHcMWo89EtfuGKFBfnBoYFnzh7PzPyalfXt2PEoMplc4/oThJCX1ygej7spfE1W1reMjLR161cwmcp4zZJRQ8+evRkMxrbtGz4lJcbHvwnbGCwejpGya0nPcj8bPHj4nbs3qFQqvoX7OBd+ZGRkyOZeTqFQNm7YuXfftuDQQC6Xo6en7+fnL/7eJZFIzn0HnDl7/E//OeKXTJgwNTcve3HATAaDOcRzxEQ//+Li7+Fb1tUoFJs1c9GmzaFjxw9RUVEd7DHc3W0I1ktTV9cIDAiOitp1+851S8uOQYEh34sK165btmjJjEPRZ8aNnXzq9JHnzx8fP3apb5/+y5etPXnq8KHDkUymso1Nl60R+ySrG2uloqxi2d4qOeVT5/8uLbKxtbt48XS3rv9ezKSn13ZLxL79+3fMmz+NQqGYmJivW7sFO1SEQoGSEsN/6uwdOzd9/Zaho627csV66Ve8MpnMjRt2RUXtWrR4elVVlZ6e/pTJM7CvfCnxByxZvTl8zdRpo/X09KdOmdnRyuZj4vuZsydGHThVo31dXb2NYTsj929fHDBTVVWtX7+Bf06bU0cs9RvgOojH4545e/xA1C4mU7m3U7/p0+djDw0bOvJzavKChX+SKZQe3f/w958TumYpNhzu7T02bMPqefOnhYZsxp78l//cnbs2Z3xJ09bSWRsa3k7fACFk2d7Kf9rso8cO7D+ww9TUYt7cwL+mT8BacO0/6Nbta4sDZi5buqa/C27lWS2F5F5d46EGHk2SpOxykqhU6qYNu/bs3RIYNJvL5ZqZWqwNDW+6y5v8fP1LS0v2H9hRXV3d07H3RL8/N4evxR6qKxUghGbNWKiirLL/wI7i4qI2bTR7/dF32tTZUrbSt0//L1/SnPsOaEhI9aYCKdnvN1KBvJKSMBFC7fQNLNtbfU5NXrRgufglDclvdDp9aVDo7j0RQ7366ejo+U+bXfi9AEsXvXr1HTPab9/+HXv2bnHs4bQ0MPTc+RMnTx0hk8lz5wT06NFrb+RWWxu7LRGRv7r/1EpKtCtXrN8csXbh4ulamtoTJkzVbKMl/i0hxby5gQwGc9uODWVlpTraur4Tpo0fN1n6W/45S5gYmzk6Oi1bPr+o+LuFRYfQkM3YyX0pR5M4UUdHnW5tiz1ZWnYU7xiLfqoKa/gXrpidXbeggOAz544fOhxJoVCMjc3WhoYbGhrXeFo7fYPNG3fvj9rp/9c4CoVia2O3NWKf+KJDfKmpqYeGbN61O3z+An9d3bZ/+s85cnQ/9pCUXUt6H+9nDt0cFRQUBrkP/e2Ru1qR8D2B8unTJ1NTU3H5adOJ2ZDZe4Sehi4sfg6axIWLp3fviYi986oBz22sG9HZziO09EwUG/Dc5nN2a3a3gVrahrIVlax58PBu6Jqlly7clSxraSSRSDR77hTL9lYL5v/C9dBEEQpEMWEZs8JlazkCoUC0b2mG3yrZikpmcblcvoAvnu1k0eIZqqpqIcEbm3q7wSGBlZUVEeF7m3pDlWWC20eyJ62Wrd+KFaWC8zuyfRbIVlQyaMq00XZdus2fF4Rjmy9ePl21evHJE1cbMp1IDU8vFxhbKXXsUUt1Ls6j1J06dcK3QQAAaCW4XG5ubvaFi6cyM7+EBm8iOhzQWixfsaCktHjxwhUaGm2ev3j8Lj4ubP02ooMCoEl8/16YmpocsXX9CO+xv9Gflg7nLnVYWNjkyZPbtm2Lb7Otk3i58p8tDQx1cnLGfYvLVixIlLiqT5LnYO8Z/9VOyILm/8cBrQSBu9bXbxmzZk8yNjZdv3artvb/LqyBvR38LCEhfvnKBXU9evzYZbUGzIWHWbli/Z69W1YFL+HxuPr6BksDQ3r27I1j+wBIInbX2rLt78TE+H7OA6dNnYV74zgXfowZM2b9+vUWFhYNeG6jtIbCj7z83Loe0lBvIzllMl6Ki4uq+FW1PsRgMGUqgTb/P07TgcIPmSKDu5YMhiQGhR9E4fF4JaXFdT2qq6PXyCLRpm6/OUHhh0xp6btW8xV+BAUFwRA1Xn6exLqpSU6xJ+Oa/x8HtBIyuGvJYEiAcAoKCk26YzR1+6DVkuNdC+cutb29Pb4NAgAAAAAAIONwHl3fuHFjfn49C7gDAAAAAAAgT3DuUr99+7ayskFrYAIAAAAAACAf8F89UV9fPktkAAAAAAAAqBXOtdR2dnb4NggAAAAAAICMw3mUOjQ0NCcnB982AQAAAAAAkGU4d6k/ffrE4XDwbRMAAAAAAABZhnOXet26dQYGBvi2CQAAAAAAgCzDuZa6ffv2+DYIAAAAAACAjMN5lHrJkiVZWVn4tlkrFQ1aFa+6GTYEQFMjkZACQ+bWX1VWp/Kr4BAD9ajiCTV0aERHUROFSlJWowgFsAMDhBDic4WqbWRuL1VQJFOoJKKjAL+sWoiUmJRaH8L5izwrK4vH4+HbZq1Utakledxm2BAATYrPqy7N52no0IkOpCZ1HVpRLhxioB5F2TxlDZzPduJCSYVanNccX0ZA9n3P4apqyVyXmq5Erq4WVZTyiQ4E/Jr8L2xtA4VaH8K5S71nzx4TExN826yVrZPq5zflzbAhAJpUSly5bW91oqOoha2TaupbOMRAPT6/Ke/cW43oKGph21s1JQ52YIAQQqlvf3Tuo0p0FLWw7a2W8rqM6CjAL8hKYemaKDLVah9HwLlLrampSaU2x4hFG12FPwZr3juV1wzbAqCJfH5TXpLH7TVUk+hAaqGsTus3Sic2JpfoQIDsenwh36Iz07gjk+hAamHloKqlR3/5z3eiAwEEe3Amr5urhnY7RaIDqYW9i4aoWvT+UTHRgYAGKczkJD4pGTxFr64nkEQiEY7bmzRpUkhIiKmpKY5tSpHypiLhabmKBl3PRAnX9wFAE6JQScV5XAGvml9V7TG5zoNTFmQkVL66VaquQ9c1ZpCg6g8ghBCiUEgFmRweW6htQO/h3obocKR5cqmI9UNIpZN1jJSEAviSaEVIZFTwlcMq51t2U7HuKYtD1GKxpwqrqxGVRtYyUBTyYS+VOWQyKi/mcyoF5UVV3jP1qfQ6B6Nx7lKPGTNm/fr1FhYWOLYpXWW54Nsn1o9iQWWZoNk22kqUlZcVFxebm5kTHYi8UWRSGSpkbUO6UQdZHN6rgcsSZCSwy4v5laVwiAGEEGKo01TUyO3MlTT1ay8olCn537gFX7mV5QL2DyHRsTQ3gVDw6dOnzradiQ6EAMrqNJU2FKMODFVNmaui/ll2Kvt7No9VIeS0vr1U9lFoJKYqRdtAwcxWWfozce5S8/l8KpVKguEsufDgwYOrV69GREQQHQgAAIBfVlZW5uPjExsbS3QgALQKONc902gt4OcgAAAAAAAAOML58sSpU6d++fIF3zYBAAAAAACQZTh3qVksllAIlUBygkajaWlpER0FAACA30EikczN4WIYAJoJzoUfUVFRDAYD3zYBUfh8flFREdFRAAAA+B0ikSg9PZ3oKABoLXDuUquoqODbICAQiURqnlnGAQAA4I5EItHpMrcyKwDyCufCj+nTp3/9+hXfNgFRRCKRQADzpgEAQIskEomqqqqIjgKA1gLnLnVZWRl0wuQGhUKBMh4AAGihSCRSmzYyvRYPAPIE59P6e/bsUVNTw7dNQBShUMhms4mOAgAAwO8QiUQlJSVERwFAa4Fzl1pTUxPfBgGBaDSanp5ML5cNAACgLiQSycbGhugoAGgtcC78mDVrFtRSyw0+n5+fn090FAAAAH6HSCRKTEwkOgoAWgucu9TFxcVQSw0AAAAAAFoVqKUGdYIJmAAAoOUikUhMJpPoKABoLaCWGtQJJmACAICWSyQSsVgsoqMAoLWAealBnahUqrq6OtFRAAAA+B0kEqldu3ZERwFAawHzUoM6CQSCsrIyoqMAAADwO0QiUU5ODtFRANBa4Fz4ERUVBYuDAAAAAACAVgXnLrWKigq+DQIC0Wg0HR0doqMAAADwO0gkUocOHYiOAoDWAufCj6lTp3758gXfNgFR+Hx+YWEh0VEAAAD4HSKRKCUlhegoAGgtcO5Ss1gsoVCIb5sAAAAAAADIMpwLP44cOQIzGcsNWJAcAABaLhKJZG1tTXQUALQWOHepFRUV8W0QEAgWJAcAgJZLJBJ9/PiR6CgAaC1wLvzw9fXNyMjAt00AAAAAAABkGc5daj6fX11djW+bgChQ+AEAAC0XFH4A0JxwLvyIiYmhUCj4tgmIAoUfAADQckHhBwDNCedRauhPAwAAAACA1gbnLvX48ePT09PxbRMQhUajaWlpER0FAACA30EikczNzYmOAoDWAucutVAoFIlE+LYJiMLn84uKioiOAgAAwO8QiUQwyAVAs4FaagAAAAAAABoFaqlBnUgkEpWK848uAAAAzYNEIsHiawA0G6ilBnUSiUQCgYDoKAAAAPwOkUhUVVVFdBQAtBZQSw3qRKPRdHR0iI4CAADA7yCRSFZWVkRHAUBrAbXUoE58Pr+wsJDoKAAAAPwOkUiUnJxMdBQAtBZQSw0AAAAAAECjQC01qBOZTFZUVCQ6CgAAAL+DRCKpqakRHQUArQXUUoM6VVdXc7lcoqMAAADwO0QiUXl5OdFRANBaQC01qBNcnggAAC0XXJ4IQHOCWmpQJ7g8EQAAWi64PBGA5gS11KBOVCpVV1eX6CgAAAD8DhKJ1LFjR6KjAKC1gFpqUCeBQFBQUEB0FAAAAH6HSCRKSkoiOgoAWguopQZ1olAoysrKREcBAADgd5BIJLgeBoBmQ4JBZVDDiBEjqqurRSIRl8vlcrkaGhoikYjNZt+5c4fo0AAAANTD39+/sLCQRCJVV1eXlJRoa2uLRCI+n3/jxg2iQwNAnkEtNaipb9++WVlZOTk5xcXFLBYrOzs7JydHS0uL6LgAAADUb8KECaWlpTk5OXl5eTweD8vhJBKJ6LgAkHNQSw1q8vPz09fXl7xHQUFh1KhRxEUEAACgoVxcXNq3by/5XVxdXW1vb09oUADIP5y71DExMRYWFvi2CZqZpqbmgAEDJO9p167diBEjiIsIAADAL5gwYQKDwRD/qaenN3nyZEIjAkD+wbzUoBZ+fn5GRkbYbQUFhTFjxhAdEQAAgIZydXUVD2+JRKIePXqYm5sTHRQAcg5qqUEt2rRpIx6o1tfX9/HxIToiAAAAv2DixInYQLWurq6fnx/R4QAg/6CWGtRu5MiRRkZGCgoKY8eOJToWAAAAv8bFxQUbqHZ0dIQhagCaAc6T6AmFQpmt/SjO45UW8AV86PE31L17996/f79w4UKiA2kxSGSkrE7V0KUxlHGe8R0A8NsqywRFuTwuq5roQJrb58+fr1y5MnHixFY3OzUJMVUpbXRpTDUa0aGAVqRVzEud94Xz4kYJu0JoaMlkVwiIDgfILboSpTiPS0LIyIrRw70N0eEAAND16LyCTK6ukRKFCrPItRZkKqmihM/nCfXNlfp6axMdDmgtcO5Sjx8/fu3atTJ1jul7Du/uicKBk/QVFGV0+BzIn9c3vyswyE5DNYkOBIDWSygUXdiZ07GnunFHWAW2lUp4UlpZVuU2QZfoQECrIOe11OwKweW9uUOmG0J/GjSn7oO0uazqN7GlRAcCQOt1eW9ul35toD/dmtn21lDRoD88/53oQECrIOfzUr++U9rDA5b9AwTo4aGd/KpCKJChX5gAtB7fklgMFWpbU0YDngvkmY2TRmEW70cJn+hAgPyT83mpc9M5qpp0oqMArRSJjEoKqoiOAoDWqDivSoEpW99HgCg0OrkkH1IxaHJyPi91tRApq8MFv4AYGnoKP0phaAQAAnAqhaoaMJ4CEEJITZteWQ4zE4AmJ+e11JxKAZKleECrIuBVk0QwyQAABBDwRUIhJH+AEEKCKhFqdTMoAgLgPHtuTEyMrNV+AAAAAAAA0KTkvJYaAAAAAACApibntdQAAAAAAAA0NTmvpQYAAAAAAKCpQS01AAAAAAAAjQK11AAAAAAAADQK1FIDAAAAAADQKFBLDQAAAAAAQKNALTUAAAAAAACNArXUAAAAAAAANArUUgMAAAAAANAoUEvdhC5cPO06sAfRUfy+34s/OCRw8ZKZTRMRAAC0ABkZaS6uDgkJ8QTGAKkYgGaGc5c6JibGwsIC3zZbs5DQoJu3rhIdBQG+fEkfO34I0VEAAAAxLl46s2FTCNFRIITQ8BED8vJziY4CgBYAaqll2ufPSUSHQIxW+8YBAEB2cmBBQX55eRnRUQDQMkAtdU2fU5MDg+Z4ebt6Du27avWS/Pw8hNDruBcurg6fPiWIn/YpKdHF1eF13AuE0N3Ym39NnzB4SB8vb9flKxfm5Gb/3KyHZ+/TZ46J/9wcvnb6DF/sdnLKpyUBs7y8XT08e8+cNTHuzUvsfhdXh7z83I2bQod69cPuib13a8ZMPw/P3iNGuu3aHcHlcqW/l5GjBx09FoXdLi4ucnF1CF2zVPyozyj3U6eP1vWWMSQS6dOnhOkzfN0G/TF+wrA7d2405N+QRCLd+OfyuPFD3Qb9MWOm3+fUZOx+gUBw+Mi+iZN93D16+U70vnzlnPglw0cMOHc+JmjZPLdBf+w/sHPDppCCgnwXV4dz52Okb+v6jUtTpo0eNNjJy9t1dXBAYWGB+P2uXbd8qFe/YcP7h65ZKr6/sLAgdM3SYV4uA917TvUfI35HFy+d8fYZ+PTpQ2+fgXsjt0mPFgAgf2o95FkslrtHr5iTh8VP4/P5Q736HYjaJSV7S1q2YsGyFQvEf965c8PF1YHNZmOlkocOR/r6DXf36DVqjMe27Rs4HA5CaMGiv27eunrr1jUXV4fUtBTpWVoqgDi3AAAgAElEQVSKulKxlG8TyVT87Plj7Gzh+AnDVq5eLH1beKXiL1/SXVwdnj17NHnqqJmzJkIqBi0I1FL/PwUF+YsWTyeRyVsj9kWER/6oKF8cMLOqqsq+a3d1dY3HT+6Ln/noUay6uoZ91+5JyR/X/73S0dEpcs+xDWE7uBxOcEhAw7fI4/GCls6l0enhm/fs3X20k3XnVasXf/9eiBA6c+oGQmjunIDjxy4jhJ48ebBu/Ypu3RwP7D8ZGBD86HFsxNb10hvv2rV7YuK/xXzvP7zV0dFN+O/PrKxvJSXF3bo51vWWsaeRSKRdeyL8fP13bI+2srIO2xickZFW75v6lvklNvbmsqVrNm/cXcWvWrlqEZ/PRwhF7tt++syxCeOmREedHjVywq7d4ddvXMJeQqVSr167YGZqsTVi3/hxU0aMGKujo3vpwt2hQ3ykbOjDh3fhEet8RoyLjjod9vf28h9loWuXYil46bJ5ubnZoSGb162JyMvLWbZifnV1NZ/PDwianZX9be2aiEPRZ/r26f/3htVPnz5ECNFoNC6Xc+HiqaDAEC+vUdKjBQDIn1oPeSaT6djDSTL5v3nzsrKy0rX/ICnZu4HOnY+JOXl46tRZ0QdOBQYEP332MOrgboTQujVbLNtb9Xdxu3ThrpmphfQsLUVdqVjKt4lkKrbv2n31qjCE0L7I48uC1kjZEL6pGCF05Oj+MaP/j737DmvqetwAfrITCHsk7KmAgICgoLZVtK5atY5a96jWPerA2ap1VGvdq2ptxT2r1tHWjVat9etCRWTK3nslJCH5/XHb/KgjooRcSN7P08fn5kLOfZO2l9fDyb3DI2YvwqkYmhCspf6P02eOMxiMrxaucHf39PZqsWDesuzszGvXL7NYrA4fdK59Vv3zzyvhHbuwWCwnR5ftP+wbOWKcs7Orj7fvgP5DkpISiouL6nhEFou1fu2OeXOWNPP0cnV1/3zURKlU+iQmmhBiampGCDEyMjIzNSOEHDwcGRDQ6ouxUxwdnMJC238xduqlS7+r/8b/SiGtQp/GPlYqlYSQ6Oh7nTt1r6qqpCbRHz1+YGZm7unR/HUvmRpBoVCMGDb2vfc6enu1mDljIZvNvnL1/BtfVElJ8eLF37VsGRQQ0GrihBn5+XkPo+9VVFT8evrYZwOHd+v2saODU5/eA7p1/Vg998NgMPg8/vhx03x9WwqFQh6Xx2AwzMzMeTyehgM9T0ni8Xjdu/VysHds4eO3+OtVkyfNIoQ8eHg3MSk+YvaiVkGtW7YMmjXrKydHl4KC/L//vpmWljJ3zpKAgFaOjs6jRo738ws4eeoIFUAqlQ7oPyQstL29nYPmtACgZzT8Lx8e3vXZsxh1V752/bKbm4e7u6eGs3cdfdi5x44f9ncK7+ro6Nw6JCy8Y9e7d28TQoRCIYvN5nC5ZmbmLBZL81lag1eeijX/NKl9Kubz+UZGxoQQExNTY2NjDQfS4qmYMBiEkMDAkB7de7u7e+JUDE0I1lL/R2zsE28vXxOhCfVQJBLb2TkkJsYRQjp26JKZmf78eRL1O7is7MzOnbpT577s7Mz5C6YPGdq734Cuq75bTAgpLy+r4xHZbLZcId+0efXI0QP6f9pt+Mi+hJCystIXvk2pVMbHx4YEh6n3BAYEE0KSkxM0DB4U1LqyspKaV34Yfa+lf5C3l+/jxw+oSeuQ4FAGg6HhJVP8/YOoDaFQ6ObqkZaW8sYX5e7maWpiSm238PEnhKSlpSQlxSsUitovISAgOCsrg/oFKCHE17dlHd6w/77AwBAGgzHty7Fnz53MzsmytLRq4eNHLUPkcrnu7v/87a6Zp9eSxd/Z2ooSEp/xeDxPj+bqEZo390lMilc/bNHCn9p4Xdq6zAwBQJOj4QTVNux9Pp9/42YUNctw66/r1Mm/jmdvDczMzP++c3PSlFEDB33Ub0DXM2d/eeXPjjeepV/nlafiN/40aRKnYmqFDECjouW7Jw4ZMmTZsmUeHh7aHVZnKisrEhLjunZvq94jl8sLiwoIIS1bBllZWf9546qbm8f165fFIjvqvHPl6oVlyxcMHzZm6pQIY2Ph4ycPa69XfqOMjLRZsycEBbZeMH+ZtZWNUqkcOOijl79NKpXW1NRE7tmxd9+PtfdT2V7H1lbk5OTy+MlDKyvrjIw0P7/A2GdPHj160L1br0eP7o8cMU7zS6bUnpzg8flS6ZtPZMbGQvW2QCAghFRXS6uqKgkhM2aNZzAY1JeoNUJFxYVGRkYvPKuOnJ1dt2zafejInp0/bi5ft8LHx2/K5NktfPzKy8v4fMHL319RWcHnC9QBCCHGRsZUsBeSvy5tVVUll8t925wA0MhpOEE5Oji1DXv/zz+v9P1k4IOHd8vKSjt16lb3s7cGm7d8f/HSbzOmz/f1C+BxeYcO73nlrwHfeJZ+nVeeit/406RJnIqLS4oEAoe3zQnQoLRcqZv6WmpjY6G/f+CsGQtr7xQIjAghTCazQ4cPb9y4OmL42Ot/XqFOqYSQc+dOBgWGfD76n8t/Vr/mI4O1zx2EEJmsmtq4cvVCTU3NVwtXUCsccnNzXvl0Pp/PZrP79R3U86NPau83t7DU/IpaBbWOiYm2sLB0d/MUCoV+foGbNq/Ozc3Jzc1pFdRG80umSKVSPp//z7ZEYmH+hiMSQiS1ajc1Cc3nC6hT5MIFy93d/rM0yNZG9MYBNfDwaPbVguU1NTWPHz/8afe2BQu/PHr4N3Nzi6qqSpVK9cLbLjQWSiRVtfdXVlW+8ufH69IK/50oAgB9ovkEFR7e9Zul80rLSv/880qLFv52Yvu6n71fUP3vyb+mpua3338dPmxsly7/FPHKyorXZdN8ln6dV56K3/mniWY6PhVbW9nUJy1AQ8Ba6v/w8fHLzEy3t3d0dnal/mEwGFZW1tRXwzt0SUiMu3f/Tnp6KvWLP0KITC4zMzNXj3D5yh/qv0bXZmRkXFFRrn6Y9O+v2ORyGY/HV68YvnjpxUtqUEMxmcxmzbxzc7PVwezsHFhstvqXeq8THBz6JCY6Ovpey4BW1O/+srIyoq5ddHZ2FYnEb3zJhBD1JxqrqqrS0lNcXd3f+DampCRVVPzzsyEu/ikhxNXV3d29GYfDKS4uUh/I1NTMzMy8PpO+sbFPYmIeUSuOAgODPx89sbS0pKio0NPTS6FQqK/QkpKSPH7CsOfPk7yat5DJZLU/9v405pG3t+/LI78uLZut5b+FAkBjoPkE1aZ1Ox6Pd+fOrZu3rqlP/m88e1OExsL/nPz/Xd6gVCpramqoz8xQlxa59df12j871NtvPEu/zitPxe/w0+SNM2W6PxXjt4XQCGEt9X/0+ri/RFL13eolCYlxGRlpe/ftGj1m4LNnMdRXfX1bikTiH7avd3f3VC8O8/H2u3v3dmzsk5yc7PUbVlpaWhNC4uKevnCFu+bNfW7cjCotLZHL5QcO7lavt/Px9istLfn9j9OFhQWnfj32LC7G3NwiKSm+oqKCx+PxeLzoR/cTEuMUCsWgz0Zc//PKwUOR6empCYlx3678etr0MZWVlS+9iP8IDAzJz8+79dd1f79AahWHh3uzk6eOBAeH1uUls9ns/Qd+evz4YWZWxrYf1snlcvWPEw2MjIy/X7M0JSU5OTlx109bxSK7lv5BQqHw44/7Re7ZceXqhazszAcP786eM+l19zIQCk0KCwsePXqg+VpRf9+5tfDrmdeuX87MykhIjDtx4rBYZCcSiYNbtXF39/x+7bL/3b39+PHDtetXVMuqnZxc2rRp5+Litnbt8thnMZlZGT/u2vIs7umnA4a+KsBbpAWApk7z//I8Hq9duw5Hju4tKSkO79iF2qnh7F175GbNvJ89i0lKSlCpVH/fufW///1F7edwOM08vc5fOJuZlZGUlLDgqy9DQ9uXl5elpaUoFAoToUliYlxCYlxpaYnms7QGrzwVE0Lq/tOE6tm3b99ISUnWcCCcigEIIawlS7T5n+awYcMCAwMtLCy0OGZ93L9S7N3GnM2p698chEKTkJCwGzei9u778bffT1VWVX45fX5QUAj1VQaDkZ+fd+NG1ID+Q/z9A6mdzb1aJCUn7Nm78+Kl3wJaBk+aOOPp00cnTx1xcnKtrq7+3//+GjniC0KIl5fv3bu3d/646ey5kx7uzd3cPDIz03v16u/k5CKVSo4c3Xfy1GEuhzt71tdKZc2pX4+Vl5eGhb1XU6M8d+7k5Svne/ce0LyZt4OD8+kzx/fu2xV17ZK1tc3C+ctsbGw1vyIel3f79p+paSnTpkRQvyh8npp89+7fw4Z87uzsqvklP4mJfhr7JGLW15s2r47cs6O8rPTLL+dTH2TR4NLl30W2diEhYes3rjx6bL+Vlc1XC1ZYW9sQQoJbhcpk1UeP7Tt4KPLe/b9DgkOnT5tHTTYcO37A09OrVVBrahBbW/Htv2/8cuKQQCAICgx53bH8/AKqqiqPHdt/8FBk1LVLtraiuRGLzc0tGAxGWOh7z+JiDh/ec/XqBVcX9wXzlpmamjGZzHZtOzyLi9m7b+fxXw5KJFVfTp8XGtqeEJKQ8OzWX9dHDB/LZP7zX4uGtHWUElNh68SzEGE2BUDXUmOrODyWjSO/7k/R/L88h805/svBkODQ3r3+ubKnhrO3l1eL02eO9+jeWyQSe3g0z8rO+OmnrUeO7a+uln7yycBr1y4NHjSSy+X6ePvdvBm1Z+/Oe/fvDBk8uluXj2/cuPrLiUMfftjDzs7xwoVzZ8+d8PcP8vLy0fCD6XU0nIpdXNxe99PkhVOxpaXVs7inZ878kpKS1K3ba+9oq8VTcVl52cmTR7p26Wlv71iXfy91kRFfZWLOsnV+i/8YAN4BQ7tLnwcNGrRs2bJmzZppccz62PVV8ieTXXhGTXvuHJqoqCPZvm1N3f01XXwKABrCtV/yBSZcn1AzuoMA/W6fzbdz5fq1x38M0LC0vDB03759WGwKAAAAAAZFy/WXuu8R6Mzjxw8XfPXl6766f9+vZqba/3u5+gbpL5s355v27Tto8VgHD0UeOvzqq/o7O7tt3bxbi8cCAGhC5i/8Un1/3Bf0/KjvhPHTtXgsWn7WADQtWq7U48ePnzJlir+/v3aHhddp3txn546Dr/uqScNc8U3DEetyib230qtX//Dwrq/8EoeNv78BgOGaPfMrmfzVN5+i7nqoRbT8rAFoWrS/SAO3l9MlHo9HXSFVl3R5RBOhCU7WAAAvq8t19LSFlp81AE2Lliv11q1b1RdMAAAAAAAwBFqu1PhsIgAAAAAYGi3PKH/99dcXLlzQ7pgAAAAAAI2Zlis1j8d74/38AAAAAAD0iZbXacydO5fBYGh3TAAAAACAxgzXpQYAAAAAqBctL/z49ddfN2zYoN0xAQAAAAAaMy1XaqFQmJWVpd0xAQAAAAAaMy0v/OjYsWPbtm21OyYAAAAAQGOm5UrNYrGMjIy0O2Z9WNvza2pUdKcAA8UzYrG5+LQuAA2MTFgMFt0hoHHg8JhcAf5rgAan5YUfCoUiPDxcu2PWB4tDCrOq6U4BBio1tsLGgUd3CgBDZGbFyUuV0J0CGoXMxEpLMa6dAA1Oy5WazWbz+fy8vDztDvvOPAOEuWk4qwIN8jOkDp5GAiGmRgBo4OprVFooozsF0K+yTCEQsqztMbsBDU7LlZoQcvbsWVtbW60P+2582pgSpfJhVBHdQcCwSCoVt37N7TzIhu4gAAaKy2e17Wl1+QA+Lm/QlEpV1JGsTp/hVAy6wFCptLzUWCaTMZlMNlvLq7Tr48L+XK6AaWLBtXEQECxthQbDYJLSAllVmfzx9ZIh85wxRQ1Ar4yEqvP7cluEmVvZ8fnG+P/RYDBUFcWK8iL53YsFwxe4mFph1QfogvYr9eHDh9PT0yMiIrQ7bD0lRVekPquSV6uKcrC0uq5kMll1dbWJiQndQZoMI1M2h8uwc+MHhVvQnQUACPV7/+hrJUW58vIiOd1ZdE2lUhYXl1haWtIdRNe4fCZPwBS58Ft3NbjXDjTS/lyyl5fXrVu3tD5sPXkECD0ChHSnaGKioqLOnDmzdtlauoMAALwjY1N2u17WdKegR0lJSf/+Yy5fvkx3EACDoP1KHRQUFBQUpPVhAQAAAAAaJ+1/PJEQUl5eXlNT0xAjAwAAAAA0Ng1Sqbdu3XrixImGGBl0icPhiMViulMAAMA7CgwMpDsCgKFokErdoUOH58+fN8TIoEtyuTwnJ4fuFAAA8C5kMhmXy6U7BYChaJBL3bVt27Zt27YNMTLoEovFMsCPigMA6Ifk5GQbG1ySGUBHGmSWmhCSmJhYUVHRQIODbshkstLSUrpTAADAu7h161ZYWBjdKQAMRUNV6kePHm3cuLGBBgfdYDAYIpGI7hQAAPDWzp8/z2Kx2rVrR3cQAEPRUJW6Z8+eCoWigQYH3aisrCwvL6c7BQAAvJ0DBw5kZmZOnz6d7iAABqShbhvO4/EWL17cQIODbjCZTFtbW7pTAADAW9i8eTODwZgyZQrdQQAMS0PNUhNCMjMzz50713DjQ0MrLS2VSCR0pwAAgDo5efLkuHHjfHx80KcBdK8BK7WDg8OhQ4diY2Mb7hDQoCQSiUAgoDsFAAC8wenTp7t06ZKdnb1z584PP/yQ7jgAhqihFn5Q1q9fn5eX16CHgIbDYDCsrKzoTgEAAK+WnZ197NixP//8s0OHDkeOHMFlTwFo1LCV2sbGBhfFbLoyMzP9/f3pTgEAAC+6dOnS8ePHORxOSEjInj17jIyM6E4EYOgatlITQh4+fLh3795169Y19IFA60pLS83MzOhOAQAA/4iKijp//vzFixcHDhw4ZsyY1q1b050IAP7R4JU6MDDw5s2bf//9d2hoaEMfC7SrqKgIv0YEAKBXcXHxn3/++ezZs6NHj/bo0SM8PHzlypV0hwKAFzV4pSaETJ48WQdHAa3Lz8/Huh0AAFrcv3//9u3bOTk5t27dev/99zt16jRnzhy6QwHAa+miUhNC4uPjk5KSevTooZvDgVYwmUxUagAAnYmLi7t79+7ff/9dWVnJZDLDwsKGDBmydOlSunMBwJvpqFI3b978+PHjVVVV/fv3180RoZ7y8/Orq6s5HA7dQQAA9FlsbOy9e/fu37+fkpLC5/NDQkI+++yz1q1bc7lcuqMBwFvQUaUmhCxYsKCyslKpVDKZDXgxbNCW9PR0JycnulMAAOibkpKSmJiYBw8ePHr0KDo6OjQ01M3NrU+fPq1atTIxMaE7HQC8I91VakKIsbHxiRMnevfuzWbr9LjwDvLy8nx8fOhOAQDQ5Mlksvj4+Ojo6CdPnsTExFRWVoaEhHh7e48fPz4gIAA/EAH0g67/T+7Tp0/btm3v3Lmj4+PC23r69KlIJKI7BQBA01NdXZ2QkPD06dOnT5/GxsampaV16dLF3Nw8PDx8ypQpDg4OdAcEAO3TdaVmsVh37tyRyWRsNhsrQBqzuLi4Dz74gO4UAABNQEFBQXJycmxsbFxcXFxcXHZ2dnBwsKOjY3Bw8LBhwzw9PekOCAANjp7fN3G53PXr1w8ePFgsFtMSAOrCy8uL7ggAAI2OXC5PSkpKTU2NiYlJSEhISEhgsVhhYWFWVlYdOnQYN26cq6sr3RkBQNdoW8I1Y8aMQYMGHT58mK4AoMHz588LCwvxQRkAAKVSmZycnJGRERsbm5SUlJSUlJ2d7eHhERISIhKJ3nvvvWbNmllYWNAdEwBoRuenIqg+/fDhw8DAQBpjwMsePHgQFBREdwoAAF2TSCSpqanPnz9PTk5OTk5+/vx5enq6u7t7mzZtzMzMevbs6eHh4ezsTHdMAGh06P+gcUVFxezZs9esWUN3EPh/6enpYWFhdKcAAGhYOTk5mZmZSUlJKf8qKytzcXHx9PR0cXHp1auXm5ubi4sL3TEBoAlgqFQqujOQq1evtm7dWqVSYaVBIxEeHv7rr7+amprSHQQAQDsKCwvT0tLS0tJSU1PT09OpbUtLy9atWwsEAtd/4UpHAPBu6J+lpgqcSqWKjo6+fv36tGnT6I5j6B4/fuzi4oI+DQBNVHl5eWpqatp/8fl8Z2dnZ2dnFxcXPz8/aht3KAQAbWkUlZoQwmAwAgMDo6Ojr1271qFDB7rjGLQHDx50796d7hQAAG+Wk5OTkZGRmZmZnp5ObWRkZPj5+ZWVlVGluUOHDtSGsbEx3WEBQJ81ioUftVVVVRkZGX3//fcRERF0ZzFQffv23bhxIz5/AwCNR3V1dUZGhro0qzesra0dHR0dHBycnJyoDUdHR/ySDQB0r7HMUqsZGRkRQjw9PSdNmrRt2za64xicxMREgUCAPg0AdMnKysrKysrMzMzMzMzOzs7KyjIyMrp3756joyNVml1cXNq3b0+1Z9zNGwAaiUY3S61WU1PDYrGOHz/u7Ozcpk0buuMYik2bNpmZmY0cOZLuIACg5/Lz87P+RRXorKys7OxsOzs7e3t7BwcHBwcHatvR0dHa2pruvAAAmjTeSk0pKipauHDhrFmzcENX3ejWrduBAwfw0wsAtCU/Pz/7XxUVFXFxcVSHNjc3t/8XVaCpbbrzAgC8i8ZeqSklJSXm5uYLFy6cMmWKnZ0d3XH01t27dy9evDh//ny6gwBAE6NUKrOzs3NycqiZZrWcnBwLCwu7f7m6ulpZWVEdmsPh0J0aAEBrmkalply6dOns2bMbNmyQSCQCgYDuOHooIiKiR48enTp1ojsIADRSVVVVOTk5OTk5+fn56enpVGnOzs7Oz8+3exWxWIzlzgBgCJpSpVa7d+/ewYMHIyIixGIx3Vn0R2lp6cyZM3/66Se6gwAA/ajenJubSzVm9bZCoRCLxWKx2M3NjZp+FovFdnZ2uEMKABi4JlmpCSFRUVFZWVlDhgyJi4vz8vKiO44+2L59O4vF+uKLL+gOAgA6UlFRkfMvqjerm7RIJBKLxdSfVG+mtnF9OgCAV2qqlVrt6NGj+/bt27Nnj6WlJd1ZmrYhQ4bs2LED94QH0DNSqZRqyWrqh76+vkVFRdSsM9Wb1ehODQDQxDT5Sk1dxJTJZFpaWm7YsGH48OH4/OI7OH369IMHDxYvXkx3EAB4F3K5nOrKeXl5L/RmmUwmqoWab6bghoIAANqiD58aUV90ycXFZceOHUuWLMnJycEsyxsNGjTo8OHD1PbNmzcnTpxIdyIA0KS6ujovL48qzerqLBQK//rrr/Lycqor29raikQiT0/P9u3bU73ZzMyM7uAAAPpPHyq12meffUZtFBQUDBgwYPXq1e3ataM7VOMllUqDg4NtbW0XLlwolUpdXV3pTgQApKqqSl2a1b2Z2pZIJFRjtrW1tbW1dXNzCwsLE4vFX375JVa+AQDQSx8WfrySRCJJSkry8/P76aefzM3N+/Xrx2Aw6A7ViBQWFo4ePTorK4sQolKpLC0tL168SHcoAENRUlKSn59PFeXi4uKMjIzc3Nz8/Pzc3FylUlm7N1MzzdS2ubk53cEBAODV9LZSq2VkZOzdu7dTp05hYWH37t0LDg5++Xv69Omze/dug5rmKSsrGzx4cG5urnqPUqm0t7c/e/YsrbkA9Efef6lLc35+vkAgsLGxoYqyo6OjhYWFSCSysbERiURCoZDu4AAA8Nb0v1LXNmPGjKysrCNHjshkMi6XS+3s2bNnbm6us7Pz0aNHDeeWBFVVVUOHDk1PT1fvUalUYrH43LlztOYCaEokEkl+fn5+fn5BQQH1ccC8vDxq+jk/P19dmtXzzVRptrGx4fF4dGcHAABtMqxKTS2ztra2TkxMXLly5aRJk4KDg4ODgxkMhkqlat68+aFDh+gOqCNKpXLgwIEpKSnUQyaT6ePjs27dOisrK7qjATQuVEUuKChQzzdTNTovL6+mpobqzQ4ODubm5tQKDXWTpjs4AADojsFVarWHDx8mJyfv2bMnMzOT2qNSqQIDAw3n9oG9e/em1lIbGRl16tRpyZIldCcCoEdFRUVBQQG1JKP2NDPF2tra1taW+pNiY2ND9WYs0gAAAIrhVmpKeHh4eXm5+iGDwQgNDd2yZQutoXTkk08+ycjIsLW1HTp06NChQ+mOA9CApFJpQUGBuiVTjZmaeM7Pz2ez2cHBwVKplCrK6j+pDbqzAwBAE2DolZpa9VF7D5PJDAkJ2bZtG/WwKEemVNIUroHNmTNHJpONHz/ex8eH7iy1qFSmVhwun0l3DmhilEoltTyjdmlW92a5XG5tbW3zL6oxUxPPNjY2fD6f7vgAANC0GXSl7tq1a2FhIYvFEgqFPB6PyWRyuVwjIyMTE5Mtm7ZFHc+Pu1fu6isszZfRnbShqFSqxnZtQWMzds5ziciVH9TR3MUHt3aD/6dSqdSNmSrK1EPqT0dHx7y8PHVvVk8zU73ZxMSE7vgAAKDPDLpSE0K2bdtmb29vZWVlZmZmZmZmbW1tbGwsrarZtzy1w2d2Imc+k9m4GqeBqCyT3ziZF9TBzCMAa1UNS0FBQe0VGrU7dGFhoboxq9c3U9s2NjYGdRFMAABobAy9Ur/SjrlJn85y4/Cw9oBmF/ZmBnU0d/fHXLVeURdldXtW/+ni4pKSklJ7hUbtDm1tbU13dgAAgFdDpX7R378Xco04noGmdAcBIpfVXDua03eyA91B4C0olcrCwkJqVUbtOWYKNdOsnl2uPc1M/Ul3fAAAgHdhKHc2qbuMBEnLjkZ0pwBCCOFwWSUF8rIiuaklh+4s8P8UCsXLE8zqPSUlJXZ2dubm5urG7O/vb10L3fEBAAC0D5X6RUwWw8yGS3cK+Iejp1FJngyVWsekUmlhYWFxcXFubu7LM80VFRUvTDAHBASo92BNMwAAGCBU6hcV58pIDd0h4F8VpQqVCp8Q1b7y8vLaizFqN+aCggKFQmFlZRUUFCSRSKii7Orqqp5mNjc3pzs+AABA44JKDaCf1GN8wBwAACAASURBVHW5oKCgvLw8MzNT/bCgoIDL5aorspWVlY2NjY+Pj3oPbgoIAADwVlCpAZok6naAtVty7Y3CwkIrKyuqLltbWzs6Orq5ubVu3Zp6aG1tzePx6H4FAAAA+gOVGqCRKikpeV1jFovFDx8+VM8xUxvqBc3UHrrjAwAAGBBUagB61NTUaF6bIRQKazdmkUjk6+urXqdhbIzLdQMAADQWqNQADaWqqqp2ac7Pz1fXZapD155Utre39/Lyat++vbpDs9n43xMAAKBpwM9sgHdXVFRUez2G+r7Z1B4Gg1G7NNvY2Li7u+O6GQAAAPoHlRrgteRyee2KXHuamdowNzdXTypbWVk5OTkFBQWp9wgEArpfAQAAAOgCKjU0MTt27Dhz5szZs2e1MlpFRcXr1mYUFhZWVVXVXs1sY2NDrWZW72QymVqJAQAAAE0aKjU0Gbdu3dqyZUtycrJCofjkk09OnTr1xqeoVCr1ReVq38pE/ZDD4bywNqN58+bqPWZmZjp5ZQAAANC0oVJDE1BaWrphw4abN28WFhYyGP+5maL68swv1+XCwsKioiKqHKtnmnF5ZgAAANA6VGpo7G7dunX8tx9SU1MJIeo+nZub269fv8LCwpqamhcuz+zs7KzeY2VlRXd8AAAA0H+o1I3Iud9OrVm7/OL527h6Wm1nzpxJSU95YXKaz+evX7/eysoKt84GAAAA2uHDVVBXJ08dXbV6yTs//fnzpEFDPn6HJ44fP37o0KFOTk4CgUClUlE7FQqFi4sL+jQAAAA0BpgNhbqKj4+l5emurq4desycMmVKVFTUmTNnEhIS8vLyqqur6xMGAAAAQItQqbUgNvbJDzs2xMfHmpqadQrv9vnoiVwulxBy6fIfR4/uy8hM43C4vr4tJ0+a5WDvqPkphJCMjLQ165ZTXxo7ZnL3br2o/fEJz3bt2hIXH6tQyFsFtZk8aZZYbPfGbOfPnz10ZE92dqZYbD/osxE9uvem9p/77dTRY/uzsjIEAqPQNu0mTphhaWlFCOnbv8vwoWNy83KuXD0vkVT5+wfNnvmVlZX1lzPHRUffpwbcueNAM0+vV+bJzMoY+8WgL8ZO7df3M+oSdcNH9g3v2MXU1GzP3h8JIeGdQ9au+aFVUOu3fZO5XG7Xrl27du2ampr6+++/nz59+m1HAAAAAGggWPhRX9k5WbPnTLK3c1y3ZvvUKRF/nD/zw/b1hJDYZzErvv0qNLT99m37Vq3cJJVIFi+J0PwUQgiLxdq0efWggSO2bN4dFBiyZu3y/Pw8Qkhubs7MWeMZTOb6tTvWrtleVl46K2KiTCbTnO3a9cur1yzt3q3Xpo0/fdyz7+rvl0Zdu0QIuXDh3Jq1y7t26fnzriNLl3wfn/Bs/oLp1JoKNpt96MgeV1f3QwfO/LzraELCs337dxFCli9d17yZd6fwrqdOXHJ383xdHgd7x89HT9wd+UNxcREh5OfIHwR8wRdjpw76bGS/foNsbUWnTlxq6R9UnzfcxcVlwoQJv/32W30GAQAAANAizFLX17lzJ7lcXsTsr1ksFiFEUlX16PEDQoiTo8v2H/Z5uDejPms4oP+QhV/PLC4usrCwfN1TCCE1NTUDBw4PC21PCBk1asKly3/Ex8fa2NiePnOcwWB8tXCFidCEELJg3rLBQ3tdu365y4c9NGQ7dvzAe+07DvpsBCHEq7lPUVFhYUE+tb99+w5Dh4wmhDg5uUydEhExZ/KTJ9H+/oGEEBdnN2oy29ZW1KZ1u7i4p4QQoVDIYrM5XK6ZmTkhREOe/v0GX426uH3nxoEDhp0+fXz1d1uomwjyuDwGg0E9HQAAAECfoFLXV3x8bPNm3lQ5JoR07dqza9eeVAfNzs7ctWtLZma6tFqqkMsJIeXlZRYWlq97CsXPN4DaMDezIIRUSaqohSLeXr5UfyWEiERiOzuHxMQ4zZU6Pj521Mjx6ofjx02jPtiXlJwQHt5Vvd/LqwUhJDEpnqrU7u7N1F8yMTEtKy97eWQNeZhM5pzZi8ZPHBYT8+ijHn3eYY0HAAAAQNOCSl1f5eVltrbil/dfuXph2fIFw4eNmTolwthY+PjJw2+WztP8FAqfz6c2/rlsnEpFCKmsrEhIjOvava362+RyeWFRgYZgUqlULpfz+YIX9kukEpVKZWRkrN5jJDAihEgkVdTDF+5+wiCvoDmPq6u7n2/A/Qf/W7hguYaEAAAAAPoBlbq+zMwtqqoqX95/7tzJoMCQz0dPpB5WS6VvfIoGxsZCf//AWTMW1t4pEBhpeAqfz+fz+S8fSMAXMJnM2vsrqyqpQ2grz+3bNx4/edgqqPXWbWs3bdjFZGLJPgAAAOgzdJ36aubpFfvsifqabhcunJv25VilUimTy2qvG7585Q9CCPURwNc9RcNRfHz8MjPT7e0dnZ1dqX8YDIaVlbXmbJ6eXo8e3Vc/3Lx1zeata9hstqdH88dPHqr3P415pF7+oZn6stAa8lRWVq7fuHLI4NEL5i9LTU0+efLIG4cFAAAAaNJQqevr4579FArFim+/evIk+saNqB0/bnJxdmMymT7efnfv3o6NfZKTk71+w0pLS2tCSFzcU6lU+rqnaDhKr4/7SyRV361ekpAYl5GRtnffrtFjBj57FqM524D+Q/539/buyO3P4p7+cuLwqVNHfbz9CCGffjrs9u0bR4/tz8nJfvDw7uatawICWnm/qVKbCE0SE+MSEuNKS0s05Nn54yYulzdk8CgrK+sxn0/e9fPWzKwMQohQaFJYWPDo0YPSstJ3eqcBAAAAGilU6voSicTfrdycX5A3K2Lixs3fdezYZfKkWYSQoUM/DwgMnhUxccq00RYWVnMiFoUEh65Zt/zGzajXPUUDsdhu3dodRUWF06aPmTBp+J3/3Vq+bF2LFv6an9Xhg85fTp936fIf06aPOfXr0WlT53zYuTsh5MPO3WfP+urcb6eGj+z7zdJ5QYEhy5aufeMr7dt3UEFB/rTpY+LiY1+XJzr6/ukzv3w5fR51me3evfq7unqsXbtcpVJ17tTd3t5xVsREalIcAAAAQG8w1L/KB8rPi55/PM5ZYMKiOwgQQsilA1mtws1dfDStGgcAAACgF2apAQAAAADqBVf8aNp69en4ui/Nm/NN+/YddBsHAAAAwBChUjdtO3ccfN2XLMwtdZsFAAAAwEChUjdtdmJ7uiMAAAAAGDqspQYAAAAAqBdUagAAAACAekGlBgAAAACoF1RqAAAAAIB6QaUGAAAAAKgXVGoAAAAAgHpBpQYAAAAAqBdUagAAAACAekGlBgAAAACoF1TqF1k78FUMukPAv4QWbCaL7hAAAAAAGqFSv0ilUhXnSOlOAf9IfVJhbc+jOwUAAACAJqjUL3LxEZQWyOlOAYQQUlYsE7sLBEJMUwMAAECjhkr9osAOFsnRZWmxFXQHAXJpb1bbjyzpTgEAAADwBgyVSkV3hkZHpVIdWZvuGWhqac+3tucxGFhbrVNlRbLSAvnNU7mfznA0t+bSHQcAAADgDVCpX+vepeKkRxUsNiP7OZZW646FiFujUDl7C0K7W2HJBwAAADQJqNT6KSoq6syZM2vXrqU7yFtTKlVMJn4tAAAAAE0J1lJD44I+DQAAAE0OKjUAAAAAQL2gUusnDodja2tLdwoAAAAAg4BKrZ/kcnleXh7dKQAAAAAMAiq1fuJwOCKRiO4UAAAAAAYBlVo/yeXy3NxculMAAAAAGARUav3E5XLt7OzoTgEAAABgEFCp9ZNMJsvOzqY7BQAAAIBBQKXWTywWSygU0p0CAAAAwCCgUuunmpqaiooKulMAAAAAGARUagAAAACAekGl1k9sNhsX0QMAAADQDVRq/aRQKHARPQAAAADdQKUGAAAAAKgXVGr9xGazzczM6E4BAAAAYBBQqfWTQqEoLS2lOwUAAACAQUClBgAAAACoF1Rq/cRgMNhsNt0pAAAAAAwCKrV+UqlUCoWC7hQAAAAABgGVWj8xmUwul0t3CgAAAACDgEqtn5RKpUwmozsFAAAAgEFApQYAAAAAqBdUav3EYrFMTU3pTgEAAABgEFCp9VNNTU1ZWRndKQAAAAAMAio1AAAAAEC9oFLrJw6HY2trS3cKAAAAAIOASq2f5HJ5Xl4e3SkAAAAADAIqNQAAAABAvaBS6ycOhyMSiehOAQAAAGAQUKn1k1wuz83NpTsFAAAAgEFApQYAAAAAqBdUav3EYDCYTPzLBQAAANAFtC79pFKplEol3SkAAAAADAIqtX7icDhisZjuFAAAAAAGAZVaP8nl8pycHLpTAAAAABgEVGr9xGazLS0t6U4BAAAAYBBQqfWTQqEoKiqiOwUAAACAQUCl1k8sFsvCwoLuFAAAAAAGAZVaP9XU1BQXF9OdAgAAAMAgoFLrJw6HY2dnR3cKAAAAAIOASq2f5HJ5dnY23SkAAAAADAJDpVLRnQG0Zvbs2VevXmUwGLV32tvbnz59mr5QAAAAAHoOs9R6ZdiwYdbW1rX3qFSq999/n75EAAAAAPoPlVqvBAYG+vr61v7Ng6Oj46BBg2gNBQAAAKDnUKn1zfDhw62srKhtlUrVrl07JycnukMBAAAA6DNUan0TFBTUokULaqLayclpyJAhdCcCAAAA0HOo1Hpo1KhR1tbWmKIGAAAA0A2DrtQqpX5e7SQwMLBFixYikWjw4MF0ZwEAAADQf4Z4Eb3iXNndS8WZiRJCSEWJgu448C5sHHksNsO7tYlfOzO6swAAAIChM7hKnZMivXggt81HNqZWHKEZh+448I4UcmVhVnV6XAWDkI6f2tAdBwAAAAyaYVXq1GdVf50t7PkFlhfrj4dRhZIyRdfhIrqDAAAAgOEyrLXU9y8XdxvlQHcK0KbAjlZsLjMlpoLuIAAAAGC4DKhSF2ZXV5XVsDkG9JINhMCEnZEopTsFAAAAGC4D6pcl+XKHZkZ0pwDts3bgV0uVdKcAAAAAw2VAlVohV1WV19CdArRPpSRlBXK6UwAAAIDhMqBKDQAAAADQEFCpAQAAAADqBZUaAAAAAKBeUKkBAAAAAOoFlRoAAAAAoF5QqQEAAAAA6gWVGgAAAACgXlCpAQAAAADqBZUaAAAAAKBeUKkBAAAAAOoFlRoAAAAAoF5QqQEAAAAA6gWVWqeirl0K7xxSWlqi+dsWL5kza/ZEXYVqQH36dt67bxfdKQAAAAAaFio1aNkn/T7MzsmitidNmBEW9h7diQAAAAAaFpvuAKBXcnNzas/Bd+v2Ma1xAAAAAHQBlVqTb5bOI4T4+QUeO76/pKQ4MDBk/txvDh6KvHzlD5lM9mHn7lOnRDAYDELI48cPf/xpS3x8LIPB8PH2++KLqT7evoQQhUKxddvaS5d+V6qUbcPeDwpqXXv8y1fOHzu2PzXtuUBg1Cm829gxk/l8ft3jnTl74sDBn4uLi1r4+M/4cv7I0QMWfb0yvGMXQkh8wrNdu7bExccqFPJWQW0mT5olFtsRQn49fXx35PaVKzZs2vJ9enqKqYnZsGFjPurRR3OeJd/MZTAYzs6uR4/tX/TVyrZt3790+Y+jR/dlZKZxOFxf35aTJ81ysHd88PDuzFkTCCFDhvZu377D8qVr+/Tt3L/f4BHDx2p4i6g3uU2bdgcPRRYW5js5ukyfNrdFC38t/7sEAAAAaDBY+KEJi81+9PhBaWnx/r2ntm3Zc/fu7UlTRjk4OB05dG7R1ytPnjp6539/EULS01Nnz5lkY227dXPklk27BUZGsyMm5uXlEkIOHoo8e+7kpEkzd2w/4O8ftG///y8svnEjavmKhcHBoT/uPDQnYvH1Py+vXb+i7tlin8WsW/9tu3YdftxxsEf33suWLyCEUP0+Nzdn5qzxDCZz/doda9dsLysvnRUxUSaTEULYbHZlZcXe/bu+Wbz6zK9RXbv2XL9hZX5+nuY8HA4n+XlifMKzVd9uatHCP/ZZzIpvvwoNbb99275VKzdJJZLFSyIIIf5+gYu+XkkI2bF9//y5S2un1fAWsdjsx08exsY+2bn9wInjF83MzL/7/hvt/TsEAAAAaHCo1G+gUChGDP+CzWa7u3u6u3lyudzevfqzWKyQ4FAzM/OkpHhq6lcgMJo/b6mHRzMPj2YL5y9XKBTnL5wlhFy4eO699h17dO/t6ODUp/eAkOAw9cgHD0cGBLT6YuwURwensND2X4ydeunS71TLrIsLF85aWFhOnjjT2dm1a9ee77/fSf2l02eOMxiMrxaucHf39PZqsWDesuzszGvXL6tf0ZBBo2xtRQwGo0f3PgqFgnoVGvKoCMnKypg395uAgFZmZuZOji7bf9g3csQ4Z2dXH2/fAf2HJCUlFBcXsdlsIyNjQoiJiamxsXHttBreIkKIVCqZNHGmQCDg8/kfdu6RlpYilUq18W8PAAAAQBdQqd/ATmzPZv+zPMbI2NjZyVX9JaGxsLKyghASnxDbvJn3/3+bkZGTk0tSUrxcLs/MTPf29lU/xcfHj9pQKpXx8bG1G3ZgQDAhJDk5oY7B0tJSfFu0ZLFY1MP33wtXfyk29om3l6+J0IR6KBKJ7ewcEhPj1N/g7t6M2jAxMSWElFeUvzGPk5OLmanZPy9cKMzOzpy/YPqQob37Dei66rvFhJDy8jINaV/3FlEPHeyd1Cte/omkcTQAAACARgVrqd+Aw+VqeKhSqQghVVWVVpbWtfcbGRlXVVVKpBJCCJfLU+8XCIyoDalUWlNTE7lnx959P9Z+YmFRQR2DlZWVWlnbqB+a/tt3CSGVlRUJiXFdu7dV75HL5bVH5vF4pDaV6o15jI2F6p1Xrl5YtnzB8GFjpk6JMDYWPn7ykFoPrcHr3iJqm/tCnn/fWAAAAIAmAZVaC4z/na5Wq6yssLK05vP41LZ6f0VFObXB5/PZbHa/voN6fvRJ7SeaW1jW8aAcLre61uqI2tO6xsZCf//AWTMW1v5+dZt/pbfKc+7cyaDAkM9H/3Pl7Oo6LNJ43Vv0xicCAAAANH5Y+KEFXs1bxMXHyuVy6mF5RXlaWoq3ty+XyxWL7NTLGwgh9+79TW0wmcxmzbxzc7OdnV2pf+zsHFhstqmJaR0P6ujoHBf/VD2b++eNq+ov+fj4ZWam29s7qgdnMBhWVpr661vlkcllZmbm6oeXr/zxwrzyy3PMr3uL6vhiAQAAABozVGot6NPn0+pq6eo1S9PTU5OTE5evWGhsLOzW9WNCSKdO3W7cjDp77mRycuLRY/trL2ge9NmI639eOXgoMj09NSEx7tuVX0+bPqaysrKOB+34wYe5uTm7I7dnZWdeuvzHrb+uq7/U6+P+EknVd6uXJCTGZWSk7d23a/SYgc+exWgesO55fLz97t69HRv7JCcne/2GlZaW1oSQuLinUqmUquC3b99ISUmu41sEAAAA0NRh4YcWONg7fv/d1p27No8dN5jFYvn7Ba5fu8Pc3IIQMnLEuNLSku07NiiVyrDQ98aNm7bkm7lKpZIQ8sH7nRbMX3bocOTuyO3GxkI/v4D1a3e8cKEMDdq1++Dz0RNPnDx8/JeDAQHBM2csGDd+KI/LI4SIxXbr1u7YuXPTtOljWCyWq6vH8mXr3nil57rnGTr086zsjFkRE42MjD/u2W/E8LGFhflr1i1nsljhHbu0adPuh+3r/f0C163dXpe3CAAAAKCpYxjO58Di7pUnPap6v5+I7iDaoVKpiooK1cs5Hj16MH3GFz/vOuLm5kF3NF3LTpbE3CrqO9mB7iAAAABgoLDwo6mKjr4/YGD3vft2ZWSkPXkSve2Hdd7evq6u7nTnAgAAADA4WPjReB08FHnocOQrv+Ts7LZ18+75c785cmzfwUO7hUKTwIDg8eOmU3dPBAAAAABdwsKPxqu6uloml73yS0wGs+6rrvUeFn4AAAAAvTBL3XjxeLwX78kCAAAAAI0P1lIDAAAAANQLKjUAAAAAQL2gUgMAAAAA1AsqNQAAAABAvaBSAwAAAADUCyo1AAAAAEC9oFIDAAAAANQLKjUAAAAAQL0YUKVmMonAhEV3CtA+BpMIzXHTIgAAAKCNAVVqMytOznMJ3SlA+4rzqrk8A/ovGQAAABobAyoilmIul29Ar9dwSCsUYjfcuR0AAABoY0AVk81lerc2iTqaTXcQ0Ka0ZxX5GdVewaZ0BwEAAADDxVCpVHRn0Kknf5UmRVeGfWxrZILVt02bTFqT8rQi5XF538kOTBaD7jgAAABguAyuUhNCEqMroq+XFGTKbBx50qoauuM0CJVKpVKpmEyt/RZCoVCwmCwGs7E0V4ExOy9D6htm+l4fa7qzAAAAgKEzxEpNqZbUlBXKGYzG0hG16+7du9evX585c6ZWRvvmm29SU1Otra1tbW1btWrl4+NjZ2enlZHfGYfHNLPm0JsBAAAAgGK4ix94ApaNo95eU4+fIK8mBdYO2vnQXnj3kO+/v5pVGEfiyK1750UikUgkat++/eDBg7UyPgAAAECTZkAfT4R31q5dOysrK2q7qqrq+fPnf/3116ZNmwYOHEh3NAAAAAD6oVLDm4nF4mbNmtXew2AwjI2Njx49Sl8oAAAAgMYClRrqpHv37gKBQP3QwsLi0qVLtCYCAAAAaCxQqfUTi8USCoVaHLBNmzaWlpbUtqmp6VdffaXFwQEAAACaNFRq/VRTU1NRUaHFAS0sLHx9fVUqlaWl5ZUrV1q3bp2YmKjF8QEAAACaLlRqqKtvv/3W1NT0woULhBAjIyNXV9euXbvSHQoAAACAfqjU+onNZotEIq0Pe/Xq1dqHOHDgAOaqAQAAAFCp9ZNCocjNzW3oo9jY2Li6ukZGRjb0gQAAAAAaM1RqqBc2mz1o0KCePXvSHQQAAACANqjU+onD4ejsnuF8Pv/cuXO6ORYAAABAI4RKrZ/kcnl2drYujyiRSLZt26bLIwIAAAA0EqjUoB0CgaBnz564RTkAAAAYIFRq0BoXFxfcohwAAAAMECq1fmIwGGw2m5ZDP3v27PTp07QcGgAAAIAWqNT6SaVSKRQKWg7t7e1dVFT0888/03J0AAAAAN2jZyIT9NuoUaPojgAAAACgO5il1k9MJlMgENCb4eTJkxUVFfRmAAAAANABVGr9pFQqJRIJvRlat249dOhQejMAAAAA6AAqNTQUR0fHPXv26Pjy2AAAAAC6h0oNDcjc3JzD4UilUrqDAAAAADQgVGr9xGAwWCwW3SkIIYTL5fbo0YPuFAAAAAANCJVaP6lUqpqaGrpTEEKIqanpmjVrrly5QncQAAAAgIaCi+jBKyiVSi2OFhQUpPUxGxqDwWAwGHSnAAAAgKYBlRpeobS0VC6Xa3FAhUIhl8tpv65f3dnY2NAdAQAAAJoMLPwAXWCz2VKptJGsRQEAAADQLsxS6ycWi2VpaUl3iv8wNzenOwIAAABAg8AstX6qqakpKiqiO8V/YGkyAAAA6CtUatCdyspKXKMaAAAA9A8qNegOj8fT7qceAQAAABoDVGr9xGazbW1t6U7xIg6HY2JiQsuhv/3224sXL9JyaAAAANB7qNT6SaFQ5OXl0Z3iFWpqalQqle6Pm5CQoPuDAgAAgIHAFT/gzVJSUiZNmrRo0aLIyEg+n79hwwaFQnH48OHr16/n5eVZW1v37du3Z8+e1DfHxMT88MMP6enpdnZ2Y8eOPXz4sJub2+TJkwkhJSUl27dvf/r0aXl5uaur66hRowICAgghaWlpEyZMWLly5a+//vr06VMGg/HBBx+MGzeOuqd6YmJiZGRkYmKiXC4PDAwcN26cSCQihJw5c+bgwYPTp0/fuHFj586dx44dGx8fHxkZmZycXF1d7eLiMnLkSOouMx999BEhZP369Tt37jx27BghJCoq6uTJk2lpaQKBoEOHDiNHjuTz+XS/zQAAANBUYZYa3ozD4RBCDh482K9fvy+//JIQ8tNPP504cWLgwIHbtm3r27fvjh07/vjjD0JIdXX1smXLjIyM1q1bN2nSpMjIyJycHOpaH0qlctGiRfHx8VOmTNm4cWPz5s0XL178/PlzapkKIWTnzp2ffvrp4cOH586de+bMmZs3bxJC8vLy5s2bx2QyV61atXLlyvLy8gULFshkMipVdXX1r7/+OnPmzJ49e1ZXVy9atIjL5a5YsWLDhg0+Pj5Lly4tKCgghOzdu5cQMmHChJ9++okQ8tdff61evTooKGjr1q0zZsy4efPm5s2b6X6PAQAAoAlDpYY3ozpxy5Ytu3bt6urqWllZee7cuX79+n344Yf29vY9e/bs3LkzNft7586dsrKyyZMne3h4tGzZcuLEiepr+T148CAxMXH69Olt2rRxdnYeP368ra3t6dOn1Ud5//33fXx8CCGBgYFisZhaqvHbb78xGIw5c+a4uro2b9589uzZOTk5VNsmhEil0k8++aR169Z2dnYsFmvVqlUzZszw8PBwcXEZPnx4dXX106dPCSHUAm6BQGBqakoIOXr0qL+//6hRo+zt7Vu3bj169OirV6/m5+fT9O4CAABAk4eFH/qJwWAwmVr++5K3tze1kZycrFAoWrVqpf5Sy5Ytz58/L5FIMjIyjI2NXVxcqP2+vr5mZmbUdlxcHIfD8ff3r6mpYbFYTCbT19c3OTlZPYirq6t6WygUVlRUUM9q3ry5UCik9tva2orF4qSkpPDw8BdSsdlsuVy+ffv25OTkiooKasV2eXn5C69CqVQmJiYOHTpUvcff358Q8vz5c9yEHAAAAN4NKrV+UqlUSqVSu2MaGxtTG1VVVYSQefPmqe/eQvXX4uLisrIyIyOj2s9SX+KjqqpKLpf37dtXpVJRT6ypqbGwsFB/J4/He/mglZWVSUlJffr0Ue+Ry+W172KjTpWZmTl//vyAgIDZs2dbWVkplcoRI0a8PGB1dXVNTc2BAwcOHTpUe39juzMOAAAANCGo1PDWqBYbERFRe16ZEGJtg/9vhwAAIABJREFUbc3j8aqrq2vvVM8TGxsbc7nctWvXqlQqdXt+41S6kZGRr6/v1KlTa+8UCAQvf+f169eVSuWcOXOowV93wRMej8dms3v37t2tW7fa+3G/dAAAAHhnqNTw1tzc3DgcTklJiZOTE7WnpKSEwWBwuVw7O7uysrLs7Gw7Ozvq6h+lpaXU9zRv3lwmk7FYLHURz83NVS8LeR1vb+9Lly7Z2dlRH2EkhGRkZFhaWr78nTKZjMfjqcv6lStXXvgGaiqdyWR6eHjk5eWpw8vl8oKCAroumA0AAAB6AB9P1E8cDoe60lxDMDY27tGjx4EDB65du5adnR0dHb1w4cL169cTQtq0acPj8Xbs2JGenh4TE7Nr1y51/Q0MDPTw8Pj++++jo6NzcnKuXr06derUc+fOaT5Wjx49JBLJunXrkpKSMjMzDx06NHHixPj4+Je/08vLq7S09MKFC0VFRWfPno2PjzczM0tOTq6srKSq9pMnT5KSkhQKxYABA27evHn06NGMjIykpKQ1a9bMnj2bWs0CAAAA8A4wS62f5HJ5bm5uw40/duxYY2Pj3bt3FxUVWVhYhIaGjhw5khBiYWExb968H3/8ccqUKa6uruPHj9+4cSOXyyWEsFispUuXbtu2beXKlVKpVCQSDR48uG/fvpoPJBKJVq1a9fPPP0dERDCZTBcXl0WLFqk/klhbWFhY//79d+/e/eOPP4aEhMyaNevkyZPHjx9nMpmTJ0/+9NNPjx8/fufOnV27drVv33727NnHjh3bv3+/sbGxj4/PqlWrXlgCDgAAAFB3DFpuZQcNLSoq6syZM2vXrn23pxcXF8vl8nd7bllZmXoBhkwmGzRo0OjRo3v16kXd01Eul79yJXRjY2Njo/7wJQAAAIBmmKUGbaqsrBwzZkxgYOCQIUMIISdOnGAwGO3bt6e+ymaz1UuiAQAAAPQG+o1+YrPZDbeWWgNjY+Nly5ZFRkbOnj2byWS6u7uvWLFCvZxaIpE0iSlqAAAAgLeCSq2fFApFg66l1sDb23vVqlUv75dIJFq/VDYAAABAY4BKDTrCZDIxRQ0AAAB6CRfRAx155c0RAQAAAPQAZqn1Uz2vS83lcjkcjhbz/P777926dXvjvRIBAAAAmiJUav1Uz+tSU7cc15Y9e/YIhUJTU1MtjgkAAADQeKBSQ4Oj7gIDAAAAoK/wi3hoWJcvXy4oKKA7BQAAAEADQqXWT/VcS60te/bsiYmJsba2pjsIAAAAQAPCwg/9VM+11FohlUpDQkJ8fX3pjQEAAADQ0DBLDQ2loqLC29ub7hQAAAAADQ6VWj8xmUwul0tjgDlz5kRHR7NYLBozAAAAAOgGFn7oJ6VSKZPJ6Dr6w4cP+/fvHxoaSlcAAAAAAF1CpQbtCwwMpDsCAAAAgO5g4QdoU3Z29vDhw+lOAQAAAKBTqNT6iclk8vl8HR9UpVLt27dv3759Oj4uAAAAAL1QqfWTUqmUSqU6PiiDwZgzZ46ODwoAAABAO1Rq/cRkMgUCgS6POHTo0JSUFF0eEQAAAKCRwMcT9ZNSqZRIJDo73C+//LJu3brGcL9GAAAAAN1DpQYt6N+/P90RAAAAAGiDhR/6icVimZqa6uBAc+bMuX//vg4OBAAAANBoYZZaP9XU1JSVlTX0Uc6dOzdt2jRHR8eGPhAAAABAY8ZQqVR0ZwCtGT58eExMDJPJVCqV6j+tra3/+OMPrR8rPT3d2tpaxx+CBAAAAGiEsPBDr4wePZpa78FkMtV/tmrVSusHmjt3LofDQZ8GAAAAQKXWN506dXJxcam9RywWDxs2TOsHmjp1qlgs1vqwAAAAAE0RKrW+GTFihLGxsfphixYtWrRoocXxV69eTQjB+mkAAAAANVRqfdO5c2dXV1dq29LScuTIkVoc/Ouvv9bugAAAAAB6AJVaD40YMcLIyEilUgUGBvr6+mpx5KlTp+J+LgAAAAAvQKXWQ507d/bw8LC0tBwxYoS2xpwwYQIhxNbWVlsDAgAAAOgNXESP3L1YlJMiVchUkqoaurNojURSVVVZZWVtrZXRSkpKTE1NqeuH0MjchmtkwvIKNhG78ulNAgAAAFCbQVfqihLFvhWprT60MrHgCC3YREl3INCoRqHKz5RmJVV5Bhj7tTOjOw4AAADAPwy3UpcVyc/+mN1jjCObg9UvTcyNk7l2brzADuZ0BwEAAAAgBr2WOupYfodPxejTTdF7fUVpcVV5GVK6gwAAAAAQw63UpQXy4jyZqRWX7iDwjixsec+fVNGdAgAAAIAYbqUuzK52bGZch2+ERsrGkV9Vpj8fJwUAAIAmzUArtVymqpbg04hNGYNRViinOwQAAAAAMdxKDQAAAACgLajUAAAAAAD1gkoNAAAAAFAvqNQAAAAAAPWCSg0AAAAAUC+o1AAAAAAA9YJKDQAAAABQL6jUAAAAAAD1gkoNAAAAAFAvqNQAAAAAAPWCSg0AAAAAUC+o1AAAAAAA9YJKTZvS0pLwziFR1y5p/rbFS+bMmj1R60c/cfJI5y5tqO0+fTvv3bfrld82eszAjZu+e6uRNYwGAAAAoJdQqYFMmjAjLOy9+ozwSb8Ps3OytDUaAAAAQNPCpjsA0K9bt4/r8/Tc3JzS0hJtjQYAAADQ5KBS19U3S+cRQvz8Ao8d319SUhwYGDJ/7jcHD0VevvKHTCb7sHP3qVMiGAwGIeTx44c//rQlPj6WwWD4ePt98cVUH29fapDTZ345cPDnkpLiZs28x34+ufb4l6+cP3Zsf2rac4HAqFN4t7FjJvP5/LoEq6ys7Degy8gR44YMHkXtkcvl/QZ06d1rwBdjpzyLe7pr15aExDiZrNrVxX3MmMkhwaEvjNCnb+f+/QaPGD6WCr9x83epqc/FYvuxY/6T8NLlP44e3ZeRmcbhcH19W06eNMvB3vHBw7szZ00ghAwZ2rt9+w7Ll659YbRXvhXUm9mmTbuDhyILC/OdHF2mT5vbooV//f4VAQAAANADCz/qisVmP3r8oLS0eP/eU9u27Ll79/akKaMcHJyOHDq36OuVJ08dvfO/vwgh6emps+dMsrG23bo5csum3QIjo9kRE/Pycgkhjx49WL9hZYcPPty189CwoWN++L/27juuqav/A/jJgCwgDAVkuQBBUam7alXEWdtq66rVOluts61KraPWTWu1tlgX1WqtaN2Wal3VatVqHYiKogi4kCFTkkBCcm9+f9znl4dHmSHJCeHzfvlHcpOc88nleV79cvjeczeuMQx+/vyZZcvnt23b8cfoXZ9FfPn3uVOr1yyvYjCZTNaxQ5dz5/8yHLl27V+lUhnes59Go5nz+XQ7e/tV36zfsG578xatvlg4Kzv7WXlDKZXK+V/MdHKUb1z/y/x5y2Jj9+Xm5nAvJd69vXzFgo4du2xc/8tXkVHq4uIvF0UQQlqGhC78IpIQsmnjjrlzlpQerYJTIRAKbyXEJyYmRG+MObDvpFzu/PU3i6v/MwEAAACwCiipq0Gn041+/0OhUNikiX+Txv729vZvvTlYIBC0a9tRLndOSUkihPwWu08ikc79fEnTpgFNmwbMn7tMp9MdP3GYEHLi5BFXV7dJE2f4+jbs1LHL0KGjDCPv/HVb69ZtPvxgmo+3b6eOXT78YPqffx7lqs+qCAvrc/fubUOtfPbvU40bN23SxF8gEKxZvenzzxYF+Ddr1KjJ+LGT1Wp1wu0b5Y1z6d/zCkXhjOmfNW0aENSs+edzFisUhdxLvj4NN274ZczoiX5+jYKDWgwZ/F5Kyv38/DyhUCiVygghjo5OMpms9GgVnApCiFpdPGXyTIlEIhaLe4X3f/z4oVqtrv7PBAAAAIA+NH5UQwNPL6HwP2dMKpPJnZwNLznIHFQqJSEk6X5iYEDQf98mlfr6NuSq7UePHwQGBgsEAu6l4OAQ7gHLsklJiWPHTDKMFtq6LSEkNfW+u7tHVYK92uk1sVh8/sKZtwcN0+l0/1z8e9jQUYQQoVCo1Wmj1q5MTklSKhV6vZ4QUlj4vLxxHj1KFYvFjRo14Z7Wr+9ev777f76gg0NGxtPNm394+vSJWqPWabWEEIWi0MXFtbzRKjgVhBBvL19DZ4ujoxM3WhV7XQAAAACsCkrqarCzt6/gKVewFhWp3FzrlT4ulcqKilQvvyQRS7gHarWaYZhtP2/a/suPpT+Ym5dTxWBisfjVTq+dO3f67UHDrsdfLSx83rNnX0JIWtrjWbM/eiW0/by5S+u51WdZdti7r1cwTlFxkUj0P0WtRCLlHpz+68TSZfPeHzVh+rQImczhVkI81w9d0WjlnwpCiL1I9ML7uRMIAAAAUOugpDYx2f8vVxuoVEqushSLJaVfUioV3AOxWCwUCt95+90Brw8q/UHn8heAXxYW1mfxks+fFz4/d+508+YtG3h6cXUwwzAL5i8XiUTc1hwVDyIWiV8Ibwh55MjBV0LbjR/3nx2yNVVo0qjgVAAAAADYEvRSm1izwOb3khK1Wi33VKFUPH78MCioBdeOnJJ6n2VZ7qWr1/7lHvD5/ICAoKysDD+/Rty/Bg28BUKhk6NT1eft0L6zSCS6fPmfC/+cDe/Zjzuo1ZaIRGLR/68Hn/zzj4oH8fNtpNPpHj5M5Z6mpibn5eVyj0u0JXL5fxtdTp0+9sK68strzBWcCgAAAABbgpLaxAYOHKrRqFeuWvLkyaPU1ORly+fLZA59+7xBCAkP75efn7duw7epqcl/nzt94v8v1COEvDt89N/nTu/cte3Jk0f3k++tiPxixscTVCpV1ecViUSdO3ffvWd7QUF+WI/e3MHgoJDnzwuOHovNzc059Nveu/duOzu7pKQkKZXKMgfp1KmrVCqNWrsy8e7tW7fiv4v6ytAqHRwUcvXqpcTEhMzMjDXfRbq61iOE3Lt3R61Wc6X/pUvnDbV4pacCAAAAwJagpDYxby+fb75el5mZ/sHEEdNmjCN6/ZrVm5ydXQgh7dt1mjpl5tmzf3405f3de36ZNWuBYXG322s9581deur0sfEfDI/4bKpWp12zetMLG2hUqmePPikp99u26WCogzt37jZ82PuboqPGjh+SkBD/+WeLB7415PiJw5u3/FDmCHK585LFq/IL8mZ8POHrbxYPfmeEt7cvl3DkyPGtQ9vOipg8bcY4Fxe3zyIWtmvbcdW3y85fOBMYGNyhQ+cNG9dErV1ZxVMBAAAAYEt4dfOasHvXFCk3i157p0r7aYAVeppcdO9ywcDJXrSDAAAAAGCVGgAAAACgZrDjR+2wc9e2Xb9uK/MlP7/G69ZutXgiAAAAAPgPlNS1w6CBw8q7sM9wLxUAAAAAoALVWO0glUqlUintFAAAAABQBvRSAwAAAADUCEpqAAAAAIAaQUkNAAAAAFAjKKkBAAAAAGoEJTUAAAAAQI2gpAYAAAAAqBGU1AAAAAAANYKSGgAAAACgRupoSc3jETtRHf3utoHPI/ZiHu0UAAAAAKTultQOcmHBMw3tFGA8RYFWJBXQTgEAAABA6m5J7exhxzJ62inAeKrnuvo+ItopAAAAAEjdLamlDkK/IGncqRzaQcAYinztg1uKll3ktIMAAAAAEEIIT6+vu4u1fx/MYVnStlc92kGgGrLTiv/9I2fQZC89X5OVlZWVlZWbm/vs2bOkpKTIyEja6QAAAKAuqtMlNSHk0h+5jxKL+AKes4dIV8LSjgMVEQp5T5OL3BrYX0hen52bUVRUVFJSotFoVCpVYWGhUCj8999/aWcEAACAuqiul9SEkCKlLj9TqyjQ6VlrORV//vmnRCLp0qULxQwKhSI6OnrWrFmmHbagoGD37t3h4eH+/v7V/axIIqjnbf/T9nUHDhxQqVQ83v/s+OHl5RUbG2vSsAAAAABVgpLa6jx8+FCpVIaEhNAOQgoKChISErp27WrykTMzMz09Pb/++uvevXu3adOmuh/fvXv3hg0blEql4Yher7927ZqpYwIAAABUSR29PNFqqdVqJycna6inCSHOzs5t27YtKCgw+cienp6EkAEDBmzYsIEQUro4rorhw4dPmTLFzc3NcESv1ycnJxNC7t27Z/K0AAAAABVDSW1FkpOTx4wZ4+rqSjvIf0kkkt9++y0qKsocg4eEhPz444+EkLy8vDFjxnA1cRUNGzZs3LhxTk5O3FNvb++GDRsSQjZs2PDmm28SQnQ6nTkyAwAAALxMsGjRItoZgBBCtFptXFzc559/TjvIi0JDQ2UyWVFRkbOzs5mmkMvlAQEBt27datGixd27d+vVq9IeLCEhITweLzExUaPRnDlzRiAQEEL69evXo0cPR0fHgoKCkSNHikSioKAgM8UGAAAA4GCV2lrk5eX16tWLdoqyhYSEODo6ajRmvN9kSEjI0KFDCSEJCQlDhw5VKBRV+dTo0aPHjx/v4OBQ+qCXlxchxNXVdc2aNdwljP/++++WLVvM0cECAAAAgMsTrcWIESMiIyMbNWpEO0hFRo8ePX/+/GbNmpl7otTUVIlEIhAIrly5MmDAgJoPqFQqt2/fLhaLx48fHx8f7+Hh0aBBA1MkBQAAACAoqa1CWlqai4uLTCajHaRyd+7cadasGddiYW46nW7JkiVisXjevHkmHPby5ctLlixZs2ZNQEBATk5OFZtMAAAAACqAkpqy27dvOzg4cJfWWT+tVnv58mVLbphdUFDg7Ox85MgRnU43cOBAUw1bVFQklUqHDBkil8u3bNliqmEBAACgbkIvNU0xMTHHjx+vLfU0IcTOzk4ikXz44YcWm5G7JjIsLOzGjRsm3HlaKpUSQvbt2zd9+nTuyMcff3zmzBlTjQ8AAAB1ClapqXn+/HleXl7jxo1pB6m2zMxMpVJpxO0Pa6ikpMTe3v7dd9+dMmVKt27dTDv4lStXrl69Onny5Fu3buXl5XXv3t204wMAAIANQ0lNB8MwCoXCfNvS2bCnT5/u3LkzIiIiKyvLw8PD5OM/e/bsq6++aty48fTp0589e+bu7m7yKQAAAMDGoPGDjo4dO9b2enrAgAGZmZmWn9fb2zsiIoIQ8vjx4wkTJhQWFpp2fHd392+//XbSpEnctYyDBg3CHRkBAACgYlilpuDChQutW7d+YTflWqegoGD//v0TJkygmCE+Pp7P57dq1SotLc3Hx8ccUzx58kSlUgUFBS1atKh9+/Ym2dQPAAAAbAxKakvLzc2VSCTc5XFgKoMHDx42bNjw4cPNN8WdO3f27du3cOHCzMzMzMzM0NBQ880FAAAAtQsaPyxq69atu3btsqV6eunSpUlJSbRTkP3793N3b7l586aZpmjevPnChQsJIRKJZO3atd9++y23ebaZpgMAAIBaBKvUlpORkXHv3r0ePXrQDmJKmZmZc+bM+fnnn2kH+Y9Lly4tW7Zsx44d5m5Vz87Orl+/fkxMTGJi4ieffIJbxgAAANRlKKnB1mRkZCgUisDAwNzcXDc3N3NPd/ToUalU2r179wsXLljyJjgAAABgPdD4YSHvv/9+Wloa7RTmcv78eYZhaKf4jwYNGgQGBhJCJkyYsH//fnNP179/f24T68zMzHbt2lHZBQUAAADoQkltCbt37542bZqZtqSwBg8fPoyKiqKd4kWHDh1iWZYQkpWVZYHpBg8efPXqVZFIRAj54osvLly4YIFJAQAAwBqgpLaE4cOHd+zYkXYKMxo1apSzs7NWq6Ud5EVDhw4lhNy4cWPZsmWWmdHFxYUQMmjQoN27d3M39LHMvAAAAECRYNGiRbQz2LKCgoLly5f37NmTdhCze+WVVwQCAe0UZWvatGlubi7LsnK5XCgUWmBGLy+v/v378/l8pVLZp08fb29vy9+/HQAAACwGq9Tm9dlnn33wwQe0U1jC8+fPV6xYQTtFud5+++3g4ODi4mJuIzyLcXNzO3nyJJ/P53YjycnJseTsAAAAYBkoqc0rOjq6YcOGtFNYglwuT0lJiY+Ppx2kXHw+39nZuWPHjhZu+5ZIJL179yaEODo6jhw5MiEhwZKzAwAAgAVgEz1zycrKunHjRp8+fWgHsZycnBy1Wm39V2GWlJTY29vv2rVrxIgRlp89PT3dy8vr+++/Hzx4sPWfKwAAAKgK2ymp1Wp1YWEh7RT/lZub6+rqyuPxaj6UXC7n9pEwgkqlUqlUNc9gezQaTUlJiaOjY5mvuri42NnZmW/2c+fObdiwYefOnRqNxugfLgAAAFgJNH6YBcuypqqna5eCggLaEapKJBJxd4ansqP2a6+9tnPnTkJIYmJiZGSkFW6WAgAAAFWHktoseDxeHaynOTqdjnaEquK2KNHpdBQX8kNDQwMCAnbt2kUrAAAAANScJTYUq2vy8vKcnZ3rZkktl8tpR6g2kUjE3RGGliFDhnAPJk2a9MYbb7z55psUwwAAAIARsEptYiUlJQ4ODtymaXVQLV2el0gkXDs+3dp63bp19+/fJ4Tk5+dTjAEAAADVVUcrvzI9ePDg9ddfv337NiFk+fLlc+fOLfNt69evnzx5cnmD2Nvb29vbG52h4sGtX1FRkUajqdZH3n33Xa7tITY29o033ijzPWY9LefOnXv99defP38uFovp9oILhcKZM2dy/1P8/PPP0WANAABQW6CkLlv//v0HDRpU3U+p1WrDtW4rVqw4efKkGaLRUcWvU5NL/Vq1ajV16lSjP26Sc+7q6sqyLJULFktr06ZNeHj4kSNH6MYAAACAKkJJXbY2bdp07NixWh/RarUajcZwU27uL/g2o4pfRyaTGb1I36hRo/79+xv3WY5Jzjmfz9fr9dTL2d69e3O/1M2cOTMzM5NuGAAAAKiYzV6eOGvWLIlEsmzZMsORhQsXKpXKb7/9Nj8/f8uWLfHx8Uqlsl69em+++ebAgQNf+Pjy5cuVSmVkZCS3w/T3339/8+ZNqVT6+uuvl35bUlLStm3bUlNTNRqNn5/f2LFjX3nlFUII97Y1a9ZER0fv3buXEHLmzJmDBw8+fvxYIpF07959zJgxYrG44sHN4fHjxx999FFkZORvv/12584dHo/XrVu3iRMncr8JZGdnb968+fr162q12tvbe+jQoT179izz65Sphuc8NjY2Ojr68OHDFZ+W8oaq+jnX6XTR0dF//fUXy7IdOnRo3br1C0mEQmFhYWFRURG3yx5dkydPXr169TfffEM7CAAAAJTLZkvqbt26bdmyRaVSyWQy7o4n8fHxEyZMIIR8//33T548mTNnjouLy+3bt9euXevu7v7qq6+WN9SqVavS09MXLVrk6up6+PDhCxcuODk5cfcKWbhwYVBQ0PLly4VC4dGjR5csWfLjjz/Wq1dv+/bto0eP/uijj3r06EEIuXjx4sqVK4cNGzZnzpynT5+uXbu2sLAwIiKigsHNRCgUcrdJnzZtWnBwcHx8/Lx581q0aNGtWzetVrtgwQKhUPjFF1+4urr+9ddfq1atkkqlnTp1euHrlOe111776aefzHrOKxiq6ud87969x44dmzZtWkhIyPXr13/99deXA4wYMUKj0eh0Ou6MURQQEMDV09u3b+/fv3/9+vXp5gEAAICX2Wzjx2uvvcYwzJUrV7inFy9eZFm2W7duhJCJEycuW7asZcuWPj4+ffv2bdKkSVxcXHnj5OTk3LhxY+jQoaGhoX5+fpMnTzasXAoEgq+++urTTz9t2rSpXC5/7733NBrNnTt3CCHcPfkkEglXCO7Zs6dly5Zjx4718vJq3779uHHj/vrrr+zs7AoGN/fJCQ4O5jZF9vT05Polrl69+uTJk5kzZ7Zs2dLb23vUqFHNmzePjY19+euUp2PHjuY+5xUMVcVzTgg5derUq6++2qdPHy8vrwEDBnB/WHiZg4NDTExMVFRUDc60KfXv3//999/HNYsAAABWyGZXqV1dXVu2bPnPP/9wa5YXLlwIDQ11cXEhhIjF4j179ty8ebOwsJBlWaVS6eXlVd44T548IYQEBgZyT3k8XmBgYGpqKrfiq9VqN27cmJKSolQquTcoFIoXRmBZNjk5eeTIkYYjLVu25HZ14G55XebgZtWoUSPDYwcHBy58cnKySCRq0qSJ4SV/f/+zZ89WfdgGDRqY+5xXcagKzrmzs3N6enrppu1mzZodP368zCRjxoy5c+dOQkJCSEhI1c+DmdSvX//YsWNqtfrRo0f+/v604wAAAMB/2WxJza3Fbt68WaPRMAxz/fr1adOmcX20CxYsYFl20qRJPj4+AoFg6dKlFQxSXFzMbY1nOMLtYUwIefr06dy5c1u3bh0REeHm5say7OjRo18egQsQExPzwh3y8vLyuPXUMgc3K5FI9PJBlUolFotL7yotlUqLioqqPizDMOY+51UcqoJzrlarq3XOmzdvrlKp1Go114dNnVgsdnZ2Hjhw4L59+7hfyQAAAIA6Wy6pu3TpsmHDBu5iO0II17l77969hw8frly50rDuWFBQ4OHhUd4gXCFVurI03Lz677//Zlk2IiKCx+OJRKJnz56VOYJIJBIKhW+99Vbfvn1LH3d2duY6Lsoc3PJkMllxcbFerzdU1cXFxVVvRHn+/LlUKjX3Oa/iUBWcc+7XidLnudJzLpPJZs6cOXDgwO7du1fxbJhVvXr11q1bd+XKlVdeecUyv4MBAABAxWy2l5qrn1q3bn358uVLly61b9+eu2aupKTE0HdLCElMTMzKytLr9eUN4u3tTQgxdB3odLqbN29yj0tKSkQiEcMw3C33Tp8+/cJnuWH5fH7Tpk2fPXvm+/88PT2FQqGjo2MFg1teQEBASUlJcnKy4UhiYmKzZs0MTys4SwzDiEQiOzs7C5zzioeq9Jzb29t7eHg8ePDA8JHr169XenK+/fZbrVZbWFhY6Tstw8fHp3Pnzvn5+b///jvtLAAAAGDTJTXX+xEXF3ft2jXDVhWNGze2t7ePjY3Ny8uLi4vbsGFDmzZt0tLSyrsFtIcRuprtAAAgAElEQVSHR1BQ0J49e+Li4lJSUqKiogx/bW/WrNnz58/PnDlTXFx8+PDhpKQkuVyempqqUqlEIpFIJEpISEhJSdHpdEOGDLlw4cKePXvS0tJSUlJWrVo1e/bsoqKiCga3vHbt2vn5+UVFRd27dy8jI2Pbtm1JSUnc1sgvfJ2XPysQCAx9EWY95xUMVcVzTgjp3r37xYsXjx079uDBgwMHDqSkpFTl/PTq1cuw6biV8PLyunbtWlpaGu0gAAAAdZ1g0aJFtDOYhk6ne/lW2B4eHjExMUKhcPr06Vw9JBaLPT09jx07tmfPnvT09I8//tjPz+/48eOXLl3q0qXLH3/80adPH3d393PnzpWUlPTq1YsQ0rp16zt37uzbt+/cuXOhoaGNGjV6/Pjxm2++6ePjo1arDx06FBsba2dn98knnzAMc+TIEYVC0aFDB5Zljx07dvbs2ddff93f39/Ly+uPP/7YtWvX+fPnXV1dIyIi6tWrV8Hgpb+FWCw2eis3rVZbeo8IhUIRGxsbHh7eoEED7sjRo0ddXV07derE5/M7duyYlJS0c+fOQ4cOFRcXT506tX379tzbSn+dF27mwrU+G8rNap3zN954Y9++fUFBQS1btrx37961a9fee++9Ck5LxUNV8Zw3b948Nzf30KFDx48fF4vFAwcOPHfu3DvvvFO6iUIikbxcQF+/fn3FihUDBgww7mdhDj169Hj+/LlcLqcdBAAAoE7jVfD399pFrVZb/u/yarVaIBCYe2lZLpeXeUFhVahUKrP2Z2s0GpZlba+j18XFpcwf699//y0Siap7Z01zO3r0qEKhGDZsGO0gAAAAdRRK6hrJy8tzcXEpvUuGOVhzSW2ryiuprdbp06e1Wu0Ll2MCAACAZdjyjh8WIJfLzV1PW5Xbt2+X7hQqvT0IIWTLli1mvfWjlUhLS/vpp58WLlxIO8j/4G4dDwAAAFRglboWsJ5Vao1GY7imUKFQGHbe4Li7u/P5NnLBa8Wr1Bs3bnRzcxs6dKhlQ1Vu9erVHTt27Nq1K+0gAAAAdQtKauMplcqaXDhYddZTUnNeWJy2SbWu8cNg3bp1gwcP9vT0pB0EAACgDrGRNUUqNBqNBeppa8PdA5x2CvrS0tIobiJegalTp6KeBgAAsDCbKql5FmRopLbYdMbh8/mmTVJQUODk5GTaMa1QpSfWx8dn8eLFDx8+NPpHYz4JCQlff/017RQAAAB1iO00foC5HTlyxKq2ZKYuLS0tNTW1W7dutIOUYevWrW5ubm+99RbtIAAAAHUCSmoj/fTTT/Xr13/hniw2bP369e7u7kOGDKEdBAAAAMDq2FTjhyVdu3atfv36tFNYAnd1Y5s2bVBPv+zixYtbtmyhnaJs2dnZR44coZ0CAACgTsAqtZEYhnn5htW258SJE4mJiR9//DHtINarV69ee/fudXFxoR2kDIsXL37llVfQ/gEAAGBuKKmhXGq1evHixZGRkbSDWDWdTqfX6612x72EhISQkBDaKQAAAGwcSmpjZGVlzZw5MyYmhnYQc7l//75CoWjZsqXVVorWQ6/XFxYWyuVy2kHKxjCMXq+vg7s9AgAAWBJ6qY2RmZlp9L1XrF9iYuIXX3zRvHlz1NNVwePx5s+ff/HiRdpByiYQCLp27arVamkHAQAAsGVYpTZGcXFxUVGRm5sb7SAmlpaW5uPjc+fOnebNm9POUpv8888/cXFx06ZNox2kbL///ntJScngwYNpBwEAALBZKKnhP3777bcDBw78/PPPtIMAAAAA1DJo/DDGvn371q1bRzuFyaSnp3MNDKinjZaYmJibm0s7Rblu3LhhnTd6BAAAsA0oqY1RUFDA59vIqVu+fPnZs2cJIdhqrSaSkpKs+bcskUg0f/582ikAAABsFvYBMMaYMWN4PB7tFDVVUFBACAkODn7nnXdoZ6n1evXq9ejRI9opyhUUFDRq1Kjc3FzbuwAAAADAGqCXui7KycmZNWtWZGSkl5cX7SwAAAAAtZ6NdC9Y2M8//3z06FHaKYzBMAwh5Pjx4xEREainTSsuLu7u3bu0U5RLqVSuWLGCdgoAAADbhJLaGFlZWYWFhbRTVNvOnTsnT55MCBk5ciTuqGdyBQUFW7ZsoZ2iXA4ODklJSbdu3aIdBAAAwAahl9oYs2fPrl291IWFhTKZLCMjIzo6mnYWm9W5c2drbqcmhHz11VfcnykAAADAtNBLbQytVsvj8WrFTZ6VSuW8efM++eSTJk2a0M4CAAAAYJtQUldDeHg4t0tGae7u7tbZV80wjEAgOH78uJOT06uvvko7Tp1w5MiRZs2a+fv70w5SrvHjx69du1Ymk9EOAgAAYFPQS10NnTt35v0vPp9vDds5DxkyJDw8vPSR/fv3Dxs2jBDSt29f1NMW8/Tp01OnTtFOUREXF5crV67QTgEAAGBrUFJXw3vvvefu7l76iK+vL1e5UrRixYonT54Yls8zMzO5S+X2799PN1gd1Lt374YNG9JOUZHFixe3adOGdgoAAABbg5K6GoKDg1u1amVoleHxeL1796Z774xLly6dPn2aYRgej9e1a9dJkyY9ffqUEDJhwgSKqeqsxo0b9+vXj3aKijg4ODg5OdFOAQAAYGtQUlfPmDFjDDV0gwYNqC9RR0ZGGtan1Wr1o0eP2rZtSzdSHXfgwAHaESqiVqv79+9POwUAAICtQUldPcHBwaGhodzj8PBwukvUixYt4takDXJzc6mlAUIIIZs3b87KyqKdolxisdje3j4tLY12EAAAAJuCkrraxo8f7+rq2qBBg1GjRlGMcfbs2TNnzrxwUK/X9+3bl1IiIISQoUOHajQa2ikqsn//ftw4EwAAwLQsvYleaoIyN71EU8Sqi2vxLScuXrwok8latWpFMcPp06dZluVaugkh3GM+n8/j8Xr27Fnpx6UOArFMUM9b5NdMapG8AAAAADbLciU1y+p/j85wcLazE/GdPUSMlrXMvFAmoR0/N12t07JEr+/1ngftOLYjISHB3t4+MDCQdpByHThwIDExcf78+bSDAAAA2A4L3f9PryeH1qcHtpM3DHawzIxQqUYtHAght87lnfr1Wfi77lX4BFQuLi4uPz/fmktqX1/f06dP004BAABgUyy0Sv3X3mfyeqKANnILzAXVdfVEtkt9YWgPF9pBbMHdu3czMjLCwsJoBwEAAADLscTliXpWf/tiIeppqxXYTn7zfCHtFDYiKCjI+uvpkpIS2hEAAABsiiVK6pynJV5NJBaYCIzj5GrP4xFNMbrbTeDx48fbt2+nnaISvXv3ViqVtFMAAADYDkuU1Jpillh0WxGoNobRo6Q2ieLi4mPHjtFOUQlPT0/DHYIAAACg5ix0eSJAHeHt7T1y5EjaKSqxe/du2hEAAABsCm71AmBKDg4OAwYMoJ2iEizLWnhDegAAANuGkhrAlNRqdVRUFO0UlVi4cKH1d6cAAADUIiipAUxJp9Pt37+fdopKODk5FRUV0U4BAABgO9BLDWBKYrE4IiKCdopKfPbZZ7QjAAAA2BSsUgOYklAofOONN2inqATDMDqdjnYKAAAA24GSGsCUGIb54YcfaKeoxI4dO9avX087BQAAgO1ASQ1gSgzDxMTE0E5RCYlEwrLYhhwAAMBk0EsNYEpCofCrr76inaISw4YNox0BAADApmCVGsCU+Hx+9+7daaeoBHqpAQAATAslNYAp6XS6hQsX0k5RiWPHji1ZsoR2CgAAANuBkhrAlFiWPXnyJO0UlRAKhUIhmr4AAABMpq78Z/X584JB7/T6cuFXPbr3quBtXy76TKlUrF61wdx5FiycdeHC2YkfTh/x7pjSx/Pz84YO788wzMnjl7ii52l62q5d265eu5SbmyMUCps0CXh70PBe4f1Kj/Py+N1e67l40Upzfwt4mVAoXLp0Ke0Ulejbt2/fvn1ppwAAALAddaWkNq1Fi+d06tS1X983azKIWCw+cfLICyX16dPHBQIBwzDc07y83E9nTqxf32PyR596enoplYrjJw4vX7FAp9MaZvf28vnkk7kvDO7q4laTbGA0Pp/fq1dFv7ZZA5ZlWZbFQjUAAICp4L+pxkhKSuzUqWsNBwlp0frqtX+T7t8NDAgyHDz55x/NmjW/dSuee3r271PZ2c9+jN4ld5JzR9q26aBRq2/evG4oqcUSSbu2HWsYBkxFp9MtWbLEyjuVT506derUKevfmQQAAKC2sNKSevGSzwkhISGhe/ftKCjIDw1tN3fO4p27tp06faykpKRXeL/p0yJ4PB4h5Nat+B+3/JCUlMjj8YKDQj78cHpwUAtukNjf98fs/KmgID8gIOiD8VNLj3/q9PG9e3c8evxAIpH2DOv7wYSpYrG4itnCwtsRQr5euXjd+tW//3aGEHLkj0N79u5IT0+TSKQdO3Se/NGnrq6VLxK7utVr2jTg+InDhpL68eOH95ISx439yFBS63RaQohOq/2fk4OODivG9VJbeUktEAi4//sAAACASVjp5YkCofDmrevPn+fv2H5o/Q8/X716acq0sd7evrt3HVn4ReTBQ3suX7lICHny5NHsz6bUr+e+bu22H6K2SqTS2RGTnz3LIoTcvHl9zXeR3bv12hy9a9TICRs2rjEMfv78mWXL57dt2/HH6F2fRXz597lTq9csr3q2Pb/+QQiZPi1ixy+/EUJOnDiyavWyPr0H/LR595JF3yTdvzt33sd6vb7ScRiG6dG99+nTxw3bmZ38848mTfz9/BoZ3tOhfWc+nz9n7vR//vlbrVaXOY5er9e8pCoBwBxqRS91z549IyMjaacAAACwHVZaUnN/QB/9/odCobBJE/8mjf3t7e3fenOwQCBo17ajXO6ckpJECPktdp9EIp37+ZKmTQOaNg2YP3eZTqc7fuIwIeTEySOurm6TJs7w9W3YqWOXoUNHGUbe+eu21q3bfPjBNB9v304du3z4wfQ//zzKFeJV4eQkJ4RIpVKuGWPvvpguXbqPfG+cr2/D0NC206dFJN2/m5BwoypDhYf3KyjIv3LlIlcZnzp1rGfY/1w01rBh4+VLv1UqFfO/mPnmwB7TP56w/ZfN2dnPSr8nNTW53+tdXvh3Lymxil8HTKtW9FLr9XrcPREAAMCErLTxgxDSwNPLcPmUVCaTOzkbXnKQOahUSkJI0v3EwICg/75NKvX1bchV248ePwgMDBYIBNxLwcEh3AOWZZOSEseOmWQYLbR1W0JIaup9d3eP6obU6XQpqffDwvoYjjRr1pwQkpyS1LJlaFW+Y4sWrU6cPPLqq6/duhWfkZkeFtYn6X+r4U6duu7sEHv79s2r1y7FXb+y7edNO2K2zJu71LB1ibe377zPX2wzaOjXuLrfBUyCYZgtW7ZMnDiRdpCKnDt37urVqzNnzqQdBAAAwEZYb0ltZ29fwVOusaGoSOXmWq/0calUVlSkevkliVjCPVCr1QzDbPt50/Zffiz9wdy8HCNCFquL9Xq9VCr7bwCJlBBSXFxUxRHCe/bbuOk7pVL556mjwcEhXg28k15aYObz+S1bhrZsGTpu7EcZmelffhmxevWyLp2729nZcTuHNG/e0ojwYA4Mw2zdutXKS2qtVpuZmUk7BQAAgO2w3pK6KmT/v1xtoFIpuUpaLJaUfkmpVHAPxGKxUCh85+13B7w+qPQHnV1cjQggEUv4fD5XxP8nQJGKC1bFEcJ69F63fvW586fP/n1qzPsfvvCqSqXSaNSlL3Zs4Ok1dMjIFV8tzMxM9/VtaERmMCuBQDBu3DjaKSoRHh4eHh5OOwUAAIDtsN5e6qpoFtj8XlKi9v83xFAoFY8fPwwKakEI8fVpmJJ639AwevXav9wDPp8fEBCUlZXh59eI+9eggbdAKHRydKrW1NwyuVAo9G8aeCsh3nD8zu2bhvaPqnB2dmnbtuOuX39WKAq7v3Qbmukfj1+6bN4Lba+PHj/g8XhyZ5dqBQbLEAgEVr5EDQAAACZXu0vqgQOHajTqlauWPHnyKDU1edny+TKZQ98+b3BX/uXn563b8G1qavLf506fOHHY8Kl3h4/++9zpnbu2PXny6H7yvRWRX8z4eIJKpapwqv8SiUQikejGzbj7yfd0Ot3QoaMuXTq/Z++OzMyM6/FX165b1bp1m6Aql9SEkF49+z158uiV0HZubvVeeOmD8VNvJcTPjphy6vTxW7fiL/17Ye26VTt3bRv41hDD7wDFRUX/Xv7nhX9Xrl6qegAwIYZhtm3bRjtFJU6dOvXZZ5/RTgEAAGA7anfjh7eXzzdfr4vevPaDiSMEAkHLkNA1qzc5O7sQQtq36zR1ysxfd2///ff9AQFBs2YtmDhpJLe03O21nvPmLt3167at2zbKZA4hIa3XrN4kk8mqMOF/jHh37K+7f7548dyOXw71Cu+n0aj37N3x4+YfZDKHrl16TJr0cbW+RZcuPcRicc+eZdwgunPnbmtWb9q7Lyb6x6i8vFw7O7uGDZt8PGPOm2+8Y3hPesbTz+fOeOGDfD7/1MnL1YoBJsEwzKZNm8aOHUs7SEVYluXza/ev0wAAAFaFZ4ENjNOSii8fz+s92tvcE4HR9n//8J1pPk6utftXLGtQK3b8AAAAANPCShWAKaGXGgAAoA7CqmQZdu7atuvXstth/fwar1u7tdIRbt2Kn7fgk/Je3fHLb9xtYsD2MAzzyy+/WHnjx/Hjx8+ePbtixQraQQAAAGwESuoyvPnm4NJ3bynNTmhXlRECA4OjN+0s71VHB8capAOrVit6qfV6PY/Ho50CAADAdqCkLoOjg2MNq16RSNTA08t0iaDWqBX7Uvfr169fv360UwAAANgO9FIDmBJ6qQEAAOoglNQApqTT6VauXEk7RSUOHjy4bNky2ikAAABsB0pqAFNiWfbgwYO0U1SCYRiBQEA7BQAAgO1ALzWAKQkEgilTptBOUYkhQ4bQjgAAAGBTsEoNYEoCgeD999+nnaISer2eZVnaKQAAAGwHSmoAU2IY5rvvvqOdohLR0dGbN2+mnQIAAMB2oKQGMCWGYXbv3k07RSU0Go1IJKKdAgAAwHaglxrAlIRC4axZs2inqMSMGTNoRwAAALApWKUGMCU+n4+L/wAAAOoaS5TUIhlfq9VbYCIwGqPVSxzw+5UJMAwTHR1NO0Ul5s+ff+zYMdopAAAAbIclqqh6XvZ5GRoLTATGeZ5bInHg29mjpDYBhmG2bt1KO0UliouLJRIJ7RQAAAC2g6fXW2L9+NyhHKG9IKSLiwXmguq68FuWb4C4xaty2kFsAcuyZ8+eDQsLox0EAAAALMdCJTUh5I+fMuo3lAa1Q91mXa6cyJHKeJ1ed6MdBAAAAKC2slxJTQg5sSOTZYjQXuDqaa9DdzVVdvb87DS1nmUdnIVd3qpHO47t0Ol0H3/88bp162gHqciAAQO2bNni6elJOwgAAICNsOgmen1GeaanFueka4oKdVpNLS6p4+PjHRwc/P39aQcxHk/P9/YX1fcRufuIaWexKSzLxsXF0U5RCZVKJZfj70UAAAAmY9FVapuxcuXKhg0bDh8+nHYQsDp6vf7mzZutW7emHQQAAAAsB5s8AJgSj8ez/nqaYRjaEQAAAGwKSmoAU9LpdJ9++intFBW5c+fO2LFjaacAAACwKSipAUyJZdlLly7RTlGR/Px8XJgIAABgWha9PBHA5gmFwgULFtBOUZEuXbp06dKFdgoAAACbglVqYzg4ONjb29NOAdaIz+cPGDCAdoqKaLVanU5HOwUAAIBNQUltDKVSWVJSQjsFWCOGYTZv3kw7RUWWLl16/Phx2ikAAABsCkpqY0ilUqxSQ5kYhtmyZQvtFBXJy8tr2LAh7RQAAAA2Bb3UxigqKsIqNZRJKBTOmjWLdoqK/PDDD7QjAAAA2BqsUgOYEp/PHzJkCO0U5dLr9Xl5ebRTAAAA2BqU1MYQiURCIRb4oQw6nS4yMpJ2inLdvXt3xowZtFMAAADYGpTUxtBoNNgzAcrEsmxsbCztFOXKzMy0/ps7AgAA1DpYagUwJaFQ+OWXX9JOUa6wsLCwsDDaKQAAAGwNVqkBTInP5/fr1492inLl5OSo1WraKQAAAGwNSmpjODs7SyQS2inAGul0umXLltFOUa733ntPpVLRTgEAAGBrUFIbo6CgoLi4mHYKsEYsyx45coR2irLl5+cHBAS4ubnRDgIAAGBrUFIDmJJQKJwzZw7tFGVzcXFZt24d7RQAAAA2CCU1gCnx+fxBgwbRTlG2zMzM7Oxs2ikAAABsEEpqYzg6OopEItopwBoxDGO1tyecN29eeno67RQAAAA2CCW1MRQKhUajoZ0CrBHDMDExMbRTlIFhGJlMhk2pAQAAzAElNYApCQSCcePG0U5RBoFAsHbtWtopAAAAbBNKagBTEggEEydOpJ2iDPfv33/48CHtFAAAALYJJbUxsC81lIdhmM2bN9NOUYYFCxbodDraKQAAAGwTSmpjYF9qKA/DMFu2bKGd4kWFhYU9evTw9/enHQQAAMA2CWkHALAQlmVzc3MtMFFMTIwF9qqzt7eXy+VVfLOTk9PkyZPNnAgAAKDuQkkNdYher7fALA4ODhaYqFpTxMbGtmnTxsfHx5yJAAAA6i40fhgDvdRQgaKiItoR/kd+fn5UVBTqaQAAAPNBSW0M9FJDBaztfxv5+fnffvst7RQAAAC2DI0fACZmbX/BaNKkCe0IAAAANg6r1AAmJpVKY2Nj33jjDdpBCCHk6dOnS5YsoZ0CAADAxqGkBjCN33//neuvKC4ubtWq1dSpU2knItz2I82aNaOdAgAAwMah8QPANJKTk7kHRUVFjRo1atSoEe1EhBAyYcIENzc32ikAAABsHEpqqNP+/PPPffv2ZWZmenh4DB48uE+fPtzxY8eOHTx4MCMjQyKRtG3b9sMPP3RxcSGEREZGEkLatm27d+/e3NxcHx+fKVOmBAUFzZkz59atW9yA33zzzYULF6Kjow8fPkwIGTFixLvvvpudnX327Nni4uKQkJAZM2a4uroSQt5+++1Ro0YNHjyYm/T7779PSUmJioriLoHdvHnzrVu3CgsLGzVqNHbs2NatW1f32+l0OkdHR1OfMwAAAHgRGj+g7jp//vx3333Xq1evb775pl+/ft999925c+cIIadOnYqKiurZs+f69evnz5+fkpLy5ZdfcvtACwSC27dv37t3LyoqaufOnU5OTmvWrCGELFy40N/fv3v37rt27QoKCio9i1Ao3Ldvn5+f39atWzds2JCcnLxr166Kg7Esu3DhwsTExE8//fT7778PDAz88ssvHzx4UN0vOHz48PT09OqfGAAAAKgelNRQdx08ePDVV18dMmRIQEDA22+/PWTIEO72igcPHuzUqdPw4cN9fHxatWr10UcfJScn37lzh/uUWq3+8MMPJRKJWCwOCwt78uSJWq2WyWQCgcDOzk4ul2u12hcm8vX17dOnj1AorF+/frt27e7fv19xsOvXrycnJ8+YMSM0NNTPz2/SpEnu7u6xsbHV+nbx8fHdunWzkv4TAAAA24bGD2PgVi+2ITk5eeTIkYan48eP55olHjx40K1bN8PxgIAAQkhqamqLFi0IIV5eXmKxmHvJwcGBEKJUKg1HCCEqleqFiRo3bmx47ODgoFAoKg527949Ozu7Vq1acU/5fH6LFi1SU1Or9e1CQ0NDQ0Or9REAAAAwDkpqYxQUFMjlctopoEbUarVWqy1dChuO6/V6qVRqOML9+mS4gYu9vf0LH3nh3uAv/7r18kcqVlRUpNVqBw0aZDjCMAzXzF1FGRkZd+7cCQ8Pr9a8AAAAYByU1FBHicVisVj88s3DxWIxn88vfZx7LJPJqjhy6XK8Yjwer/RTjUbDPZDJZPb29mvXri39Kp9fjTatzz//PCIiourvBwAAgJpASQ11V5MmTRISEgxPN27cyOPxJk2a1KRJE0PnNCEkMTHR0P5RMW65Wq1WVzGAVCpVKpWGpw8ePLCzsyOEBAYGlpSUMAxj6ITOysqq+h9GcnNzIyIiQkJCqvh+AAAAqCFcnmgMJyenlxsGoNYZNGhQXFzcL7/8kpSU9Ntvvx0+fDgwMJDb2+7y5csHDhzIysq6cePGpk2bWrZsyb1UAQcHh5SUlJSUlMzMzCoG8Pf3v3Tp0vPnz7Va7e7duw091qGhoU2bNl21atXNmzczMzP/+uuv6dOnHzlypIrDurm5oZ4GAACwJKxSG6OwsLBaja1gnbp27Tp16tQDBw7s27fP3d198uTJYWFhhJCwsDCNRnPw4MFt27bJZLJOnTpNmDCh0tHeeuut1atXz549e9asWVUMMHHixDVr1owdO9bR0bFv3769evW6du0at1XfkiVLtmzZsmLFCrVa7eHhMWLEiLfffrsqY8bGxiYnJ8+cObOKGQAAAKDmeC9cWQVVsXLlyoYNGw4fPpx2EKgGlmVzcnJopzAZe3t7Z2fnl4+PGTNm69at1Wq8BgAAgBrCf3cBTMxwlSEVP//8M+ppAAAAC8N/eo0hEAhQtUB5Sl9xaEn5+fkHDx6kMjUAAEAdh7rQGAzDsCxLOwVYKZFIRGXeadOmBQcHU5kaAACgjsPliQAmxt1S0cJycnJWrlzp7e1t+akBAAAAq9QAJlb1falNRa/X29nZoZ4GAACgBSW1kV647x2AgUqlsvCMkyZNSk5OtvCkAAAAYIDGDyNh88Fah8/nu7u7m3sWhmH2798/efJkc09kcOXKlcGDB7dt29ZiMwIAAMALUFIDmJJAILBkPU0Iad++vSWnAwAAgJeh8QPAlFiWPXTokMWmW7ZsWXp6usWmAwAAgDKhpDaGTCazt7ennQKskU6n+/rrry0zV3R0dGBgoJeXl2WmAwAAgPKg8cMYKpWqpKSEdgqwRnw+v3fv3paZa+LEiZaZCAAAACqGVWoAUxIKhUuWLHwslP8AAAuZSURBVLHARDExMRaYBQAAAKoCJTWAKbEse+HCBXPPMm7cuJYtW5p7FgAAAKgilNTGcHJyEovFtFOANdLpdLNnzzbrFAUFBVFRUa1atTLrLAAAAFB1KKmNUVhYaPk75EGtwOfzu3TpYr7xc3Nzs7KyHB0dzTcFAAAAVBdKagBTEgqFq1atMtPgmZmZo0ePbtasmZnGBwAAAOOgpDaGi4uLVCqlnQKsEcuyf/31l5kGT0tLs+Sm1wAAAFBFKKmNkZ+fX1RURDsFWCOdTjdv3jxzjJyWlhYcHGxnZ2eOwQEAAKAmUFIDmBKfzx8yZIjJh121atW5c+dkMpnJRwYAAICaw61ejOHo6CgSiWinAGskFApnzZpl2jHT09PfeuutwMBA0w4LAAAApoJVamMoFAqNRkM7BVgjlmX37dtnwgFLSkqkUinqaQAAAGuGktoYzs7OEomEdgqwRjqdbvXq1aYaLSMj45133nF2djbVgAAAAGAOKKmNUVBQUFxcTDsFWCM+n9+pUydTjXbixInDhw+bajQAAAAwE55er6edodZo06YNj8fT6/U8Ho87otfr3dzcTp48STsaAAAAAFCDVepqaN++PY/H4/P5vFJ69+5NOxdYEb1ef/fu3ZqPM2HChISEBFMkAgAAALNDSV0N48aNc3JyKn3E19fXHDumQe2l1WrHjRtXw0GOHj06d+7ckJAQE4UCAAAA80JJXQ2dOnUKDAw0tMro9foOHTo0adKEdi6wInw+v4alMMuy/fr18/f3N10oAAAAMC+U1NUzduxYuVzOPfb19R0xYgTtRGBdhELhjz/+aPTH165du337dkOzPgAAANQKKKmrp1OnTs2aNeMed+jQoXHjxrQTgXVhWfbChQvGfTYpKSksLGzs2LGmDgUAAADmhZK62saMGePo6Ojj44MlaniZTqebPXu2ER/My8uTyWTonwYAAKiNbPyG5Bo1U5ijK1LoigoZrVavZ02wY6CEBLUPHOLi4lL4xOXGk4KaDygQ8oR2PKmjUOokcPO05/HxR/9aTCAQjB49urqfOnr06IULF5YtW2aeUAAAAGBetrkvtaJAmxKvSrquKlaxDKMX2gsEdgKBncAkJbXJ8YUCnUbLlDC6Ep1Ww9T3ETdr6xDQxsHeHn9DqBNUKpVCofD09KQdBAAAAIxkayW1VsOe2Z+bk16i59s5uUsd3GrfbcMLn6kU2UWsVtukpazLG66040D1sCwbGxs7aNCgKr4/Ozs7LS3tlVdeMXMuAAAAMCObKqn/PZ5/7WSeR4Crm59TFd5u7Z6l5Oc8fN5tsHvIq460s0BVlZSUdO/e/eLFi1V588WLF2NiYn744Qfz5wIAAAAzsp2SOnZThpaI3PzktIOYEsuw2an57l78sCH1aGeBKmEYZu3atZ988kml79TpdGq12sHBwSK5AAAAwIxspKTevuyR3NtZ7mmb1UnOwwKpRPf6WA/aQcBkHj9+fPnyZdx6EwAAwDbYwgVwO7564tLQ1VbraUJIvUbOqmK72OhM2kGgcizLHjp0qOL3xMXFfffdd6inAQAAbEatX6WOjc4g9jInDxntIGaX87DA3VPf7W10gFi1Snupnz175u7ubtlQAAAAYF61e5X68vF8hieqC/U0t1adlc7ei1PQDgIVEQgEw4cPL+/Vq1ev3rt3z7KJAAAAwOxqcUmtVjFxp/NdfGzqesSKufg4n9mTTTsFVEQgEFRwbeKZM2dee+01yyYCAAAAs6vFJfXZgznu/i60U1iU0F4gb+Bw5UQ+7SBQLoZhtm3b9vLxu3fvEkKMu1c5AAAAWLnaWlI/zynJz2JcfWxh/+lq8QhwTbququ0d8DaMYZhNmza9cPDKlSs3btyglAgAAADMrraW1Mk3lDw7O9opyqVSFcz+ouONhFMmH5nH4+l5/AcJKpOPDCYhEAjGjRv3wsGLFy9W0GANAAAAtV1tLanvxxc51JPSTkGHzFV6Px4ltZUSCAQTJ040PP33338JITNmzKAaCgAAAMyrVpbURQpdiVovcxHTDkKHk7v0WZqGdgooW+le6hs3bsTFxdFOBAAAAGYnpB3AGAXPtGZtJU5Lv/vHyfVp6XcZnTagafu3+n/q6tKAEPLP5f3HT0WPH7X6tz++fZb9UCqVh3cf17HtW9ynLl4+cOrvbUpVvk+DoH69PzJfPIGdoOi5rljJSBwE5psFjMP1Uo8dO5YQcv/+/cmTJ9NOBAAAAGZXK1epVYU6ochcvwzkF2Ru/GkKn8efPH79R+PXFRUVbto2TasrIYQI+EK1Wvnn2Z9Gvxu5dP6ptqGvH/j964LnzwghqQ+v7//961YtwmdO2RHeY9zvR6PMFI9jLxGqCnVmnQKMw/VSHzt2jBCC+yMCAADUEbWypC4qZAR25lqgvXjlAOHxRg5d2sDD39e7+Yghi/Lyn966fZp7lWF1Ya+NdpZ78Hi8Dm3eZBhdeuZ9Qsi1+KOODm4D+kxzr98wOLBz967vmSkeRygSFBUyZp0CjCMQCLp37479PQAAAOqUWllSM6yeLzBX8sdPEvy8m0skjtxTF2dPVxfvpxlJhjd4eQRwD6QSJ0KIWq0ghGRlP/TxDhII/lPo+/m0MFM8jtBeoNOxZp0CjJadnT1nzhzaKQAAAMByamUvtdRBoNOY6/q8YrUqPfPenEVdDUcYRluoyDE8tbMTlX4/t0W0RqNycnQzHLS3k5gpHkejKpE51sqfXV3QtWvXKrwLAAAAbEetLMtkciFTYq5OYrFY1tgvdMjAz0sftLevZMM+e3uJWq00PC1WK8wUj6NVMzJ5rfzZAQAAANieWtn44SAX2kvM1Uvd0DckJ++Jm6uPe/1G3D9CeE6O9Sr+VH03v/SsZJb9TzPG/ZTLZorHkTnbSZ1q5c8OAAAAwPbUyrLMxcNela/RFGnNMXindm9rNEW/HljyNP1eds7jk39tWfXDiCdPb1f8qVda91Uq82KPfpeRlXzz9l9Xr/9hjmwcRXaRSMzn82vlzw4AAADA9tTWsqxxiEzxrMgcI7u6NPho/HqFMnfd5onfbxx77/6lcSNXNfRtWfGnmvl3fKv/Jzdvn/puw9izF2KGDpxraLM2OUVOUWCbOnrnSAAAAAArxDNT2WduT1OKzv9e6NGsPu0gFGTcznzjA3dHZzvaQQAAAACA1OJVau+mUsLqVPlq2kEsLS9N4eohRD0NAAAAYD1q8a4R3d52OxGTI2vrVearzwuzv1n7bpkviUUOao2yzJc86jeePnGzCUMuWB5e3ksso+MLyjj/Pl5BH41bV96nslPy+i9oaLqAAAAAAFBTtbXxg3N8R5aWyBzcytgEmmVZjUZV5qd0Oq1QWPYqL4/HF4tlJkxYXFzubnoMoxOUVVJXkCH/aaFnA/bVAW5lvgoAAAAAVNTukpoQEj03tUknH6G9ufbUsx6qfHVhet6I2b60gwAAAADA/6itvdQGo+b5pV56SjuF2TE69nF8JuppAAAAACtU61epCSHFKt2OFU+avurDF9T63xDKpFaWPL2VNXZhQ4GQRzsLAAAAALzIFkpqQkhhrjbmq8eN2jWQOIloZzExRbYq/3H+qHl+fD7qaQAAAABrZCMlNefIT5mF+Xq3xi72ElvYY674uSbnYZ5XI7vwdz1oZwEAAACActlUSU0IuX9dce5QrpOng8hB5FivVt5iUK/XK54VqQuLdcUl3d5x8wmold8CAAAAoO6wtZKak3i58PYlxbPHaldfBx5fYCcSCEUCgZ217grC4+k0Op2G0Wp0jEabn17k20wW0tmxaSsH2skAAAAAoHK2WVJzdFr24R1VbrpWUaBTPtexjF5XQjtTWaSOApbVy+RCRxeBu4+oUXNTbowNAAAAAOZmyyU1AAAAAIAF2OaucwAAAAAAFoOSGgAAAACgRlBSAwAAAADUCEpqAAAAAIAaQUkNAAAAAFAjKKkBAAAAAGrk/wDrAJVwzV1B1QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "###################################\n",
    "#           LIBRARIES             #\n",
    "###################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import uuid\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import textdistance\n",
    "import httpx\n",
    "from py4j.java_gateway import JavaGateway\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET  # For parsing the Ecore file\n",
    "\n",
    "from codecarbon import EmissionsTracker  # Import CodeCarbon\n",
    "\n",
    "# LangChain and related libraries\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.llms import Ollama\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.tools.base import Tool\n",
    "from typing import Callable\n",
    "\n",
    "from pytextdist.edit_distance import levenshtein_distance, levenshtein_similarity\n",
    "from pytextdist.vector_similarity import cosine_similarity\n",
    "\n",
    "###################################\n",
    "#         CONFIGURATION           #\n",
    "###################################\n",
    "\n",
    "# Configuration file paths (llm_config_anthropic, llm_config_google, llm_config_groq, llm_config_mistral, llm_config_ollama, llm_config_openai)\n",
    "CONFIG_FILE = \"config/llm_config_mistral.json\"\n",
    "MODELS_FILE = \"config/llm_models.json\"\n",
    "CONFIG_RAG_FILE = \"config/llm_config_openai_rag.json\"\n",
    "CONFIG_RAG_TAVILY_FILE = \"config/secrets-master-llm.json\"\n",
    "VECTOR_DB_TYPE = \"FAISS\" # FAISS, CHROMA\n",
    "CSV_FILE_PATH = \"config/BASE_URL.csv\"\n",
    "LLM_TYPE = 'Others' # 'Others', 'Ollama' (\n",
    "RAG_CHAT = 'LangChain' # 'OpenAI', 'LangChain' (Same Model as the model Generation)\n",
    "\n",
    "# Define an array with all the topics/tools for retrieval\n",
    "vectorstore_topics = [\n",
    "    # \"CAEX/AutomationML\",\n",
    "    \"BPMN Designer\",\n",
    "    \"HEPSYCODE\",\n",
    "    # \"Additional Tool 1\",\n",
    "    # \"Additional Tool 2\",\n",
    "    # Add more topics as needed\n",
    "]\n",
    "\n",
    "###################################\n",
    "#         UTILITY FUNCTIONS       #\n",
    "###################################\n",
    "\n",
    "# Function to load configuration from a JSON file\n",
    "def load_config(config_file):\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file {config_file} not found.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Function to load file content\n",
    "def load_file_content(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to save content to a file\n",
    "def save_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Function to save metadata to a file (in JSON format)\n",
    "def save_metadata(file_path, metadata):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "###################################\n",
    "#         LLM CONFIGURATION       #\n",
    "###################################\n",
    "\n",
    "# Load LLM configuration\n",
    "config = load_config(CONFIG_FILE)\n",
    "models_config = load_config(MODELS_FILE)\n",
    "\n",
    "# Extract LLM parameters from configuration\n",
    "LLM = config.get(\"llm\")\n",
    "if not LLM:\n",
    "    raise ValueError(\"LLM name must be specified in the configuration file.\")\n",
    "\n",
    "PRICE_PER_INPUT_TOKEN = config.get(\"price_per_input_token\")\n",
    "print(f\"PRICE_PER_INPUT_TOKEN: {PRICE_PER_INPUT_TOKEN} $\")\n",
    "PRICE_PER_OUTPUT_TOKEN = config.get(\"price_per_output_token\")\n",
    "print(f\"PRICE_PER_OUTPUT_TOKEN: {PRICE_PER_OUTPUT_TOKEN} $\")\n",
    "temperature = config.get(\"temperature\")\n",
    "max_retries = config.get(\"max_retries\")\n",
    "api_key = config.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "base_url = config.get(\"base_url\")\n",
    "\n",
    "# Determine LLM type and initialize LLM instance\n",
    "llm_config = models_config.get(LLM, None)\n",
    "if llm_config and LLM_TYPE != 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"max_retries\"] = max_retries\n",
    "    llm_params[\"api_key\"] = api_key\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    # Dynamically initialize the LLM class\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM  # Use LLM name as the model name\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    print(f\"Model Temperature: {temperature}\")\n",
    "elif LLM_TYPE == 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    print(f\"Model Temperature: {temperature}\")\n",
    "else:\n",
    "    raise ValueError(f\"Model configuration for '{LLM}' not found in {MODELS_FILE}.\")\n",
    "\n",
    "###################################\n",
    "#     FEW-SHOT CONFIGURATION      #\n",
    "###################################\n",
    "\n",
    "# Define file paths for static resources and output directories\n",
    "example_model_path = \"../../01_MSE/HEPSYCODE/HEPSYCODE-Models/D1/HEPSY/2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\"\n",
    "\n",
    "# Path to the metamodel (Ecore file)\n",
    "metamodel_path = \"../../01_MSE/HEPSYCODE/workspace/org.univaq.hepsy/model/hepsy.ecore\"\n",
    "\n",
    "# Path to the model folders (Hepsy file)\n",
    "base_model_path = \"../../01_MSE/HEPSYCODE/HEPSYCODE-Model-Description/D1/HEPSY/\"\n",
    "\n",
    "# Path to the Output Directory\n",
    "base_output_dir = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}\"\n",
    "base_output_json_dir = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "\n",
    "# Profiling Folder\n",
    "PROFILING_FOLDER = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(PROFILING_FOLDER):\n",
    "    os.makedirs(PROFILING_FOLDER)\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"profiling.csv\")\n",
    "\n",
    "# CodeCarbon Folder\n",
    "CODECARBON_FOLDER  = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(CODECARBON_FOLDER ):\n",
    "    os.makedirs(CODECARBON_FOLDER )\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"codecarbon_summary.csv\")\n",
    "\n",
    "# Folder to save evaluation results per file\n",
    "EVALUATION_FOLDER = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(EVALUATION_FOLDER):\n",
    "    os.makedirs(EVALUATION_FOLDER)\n",
    "\n",
    "# Global variable to force context regeneration regardless of REFINED_CONTEXT_PATH presence\n",
    "FORCE_CONTEXT_GEN = False  # Set to True to force context generation even if REFINED_CONTEXT_PATH exists\n",
    "\n",
    "# File path to save the refined context (persistent cache)\n",
    "REFINED_CONTEXT_PATH = f\"D2-HEPSYCODE/LLM-{model_name.lower()}-{temperature}/HEPSYCODE_refined_context.json\"\n",
    "#REFINED_CONTEXT_PATH = \"config/HEPSYCODE_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/CAEX_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/BPMN_Designer_refined_context.json\"\n",
    "\n",
    "###################################\n",
    "#         GLOBAL PROFILING        #\n",
    "###################################\n",
    "\n",
    "# Global list to collect CodeCarbon metrics for each node call (per file)\n",
    "cc_metrics_for_file = []  # This will be reset for each file\n",
    "\n",
    "# Global list for overall CodeCarbon summary per file\n",
    "cc_summary_records = []\n",
    "\n",
    "# Global list to save profiling data\n",
    "profiling_records = []\n",
    "\n",
    "###################################\n",
    "#      TIMING NODE PROFILING      #\n",
    "###################################\n",
    "\n",
    "def timing_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator to profile a node function.\n",
    "    Appends a record with the node name and its execution time (in seconds) to profiling_records.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        profiling_records.append({\"node\": func.__name__, \"execution_time\": elapsed})\n",
    "        print(f\"[Profiling] {func.__name__} took {elapsed:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#    CODECARBON NODE DECORATOR    #\n",
    "###################################\n",
    "\n",
    "# os.environ[\"CODECARBON_API_KEY\"] = \"CODECARBON_API_KEY\"\n",
    "# os.environ[\"CODECARBON_API_URL\"] = \"https://api.codecarbon.io\"\n",
    "# os.environ[\"CODECARBON_EXPERIMENT_ID\"] = \"UUID\"\n",
    "\n",
    "def cc_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator that wraps a node function with CodeCarbon tracking.\n",
    "    It starts a tracker before calling the node and stops it right after.\n",
    "    The resulting metrics are appended to the global cc_metrics_for_file list.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        # Create a CodeCarbon tracker for this node\n",
    "        tracker = EmissionsTracker(\n",
    "            project_name=f\"cc_{func.__name__}\",\n",
    "            measure_power_secs=1,\n",
    "            output_dir=CODECARBON_FOLDER,  # You can adjust output_dir as needed (\".\")\n",
    "            allow_multiple_runs=True\n",
    "            # api_call_interval=4,\n",
    "            # experiment_id=experiment_id,\n",
    "            # save_to_api=True\n",
    "        )\n",
    "        tracker.start()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        emissions = tracker.stop()\n",
    "        # Try to extract detailed metrics if available (from the internal attribute)\n",
    "        if hasattr(tracker, \"_final_emissions_data\"):\n",
    "            metrics = tracker._final_emissions_data\n",
    "        else:\n",
    "            metrics = {\"total_emissions\": emissions}\n",
    "        # Append the node's CodeCarbon metrics to the global list\n",
    "        cc_metrics_for_file.append({\n",
    "            \"node\": func.__name__,\n",
    "            **metrics  # Flatten the metrics dictionary\n",
    "        })\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#       PROFILE & CC DECORATORS   #\n",
    "###################################\n",
    "\n",
    "# (Assuming you already have a @profile_node decorator for timing, as in your code.)\n",
    "# Here we combine both decorators so that each node is profiled for time and CodeCarbon metrics.\n",
    "# The order of decorators means that cc_profile_node will wrap the function first.\n",
    "def profile_node(func):\n",
    "    return timing_profile_node(cc_profile_node(func))\n",
    "\n",
    "###################################\n",
    "#       LOAD URLS FROM CSV        #\n",
    "###################################\n",
    "\n",
    "def load_urls_from_csv(csv_file_path):\n",
    "    urls = []\n",
    "    try:\n",
    "        with open(csv_file_path, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if row:  # Ensure the row is not empty\n",
    "                    urls.append(row[0].strip())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file '{csv_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "    return urls\n",
    "\n",
    "# Load base URLs for the vector database from CSV\n",
    "BASE_URLS = load_urls_from_csv(CSV_FILE_PATH)\n",
    "if not BASE_URLS:\n",
    "    raise ValueError(\"No URLs were loaded from the CSV file.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(BASE_URLS)} URLs from '{CSV_FILE_PATH}'.\")\n",
    "\n",
    "###################################\n",
    "# RAG AGENT SETUP (Chroma/FAISS)  #\n",
    "###################################\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "if VECTOR_DB_TYPE == \"CHROMA\":\n",
    "    # Directory for persisting the Chroma vector store.\n",
    "    CHROMA_PERSIST_DIR = \"chroma_db\"\n",
    "    \n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    # Initialize OpenAIEmbeddings\n",
    "    embd = OpenAIEmbeddings(openai_api_key=api_key_rag)\n",
    "    \n",
    "    # Build or load the Chroma vector store\n",
    "    if os.path.exists(CHROMA_PERSIST_DIR) and os.listdir(CHROMA_PERSIST_DIR):\n",
    "        print(\"Loading existing Chroma vector store from disk...\")\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=CHROMA_PERSIST_DIR,\n",
    "            embedding_function=embd,\n",
    "            collection_name=\"rag-chroma\"\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "    else:\n",
    "        print(\"Creating new Chroma vector store...\")\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=500, chunk_overlap=0\n",
    "        )\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=doc_splits,\n",
    "            collection_name=\"rag-chroma\",\n",
    "            embedding=embd,\n",
    "            persist_directory=CHROMA_PERSIST_DIR\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "elif VECTOR_DB_TYPE == \"FAISS\":\n",
    "\n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"  \n",
    "    HUGGINGFACE_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    \n",
    "    faiss_folder = \"faiss\"\n",
    "    if not os.path.exists(faiss_folder):\n",
    "        os.makedirs(faiss_folder)\n",
    "        print(f\"Folder '{faiss_folder}' created.\")\n",
    "    else:\n",
    "        print(f\"The folder '{faiss_folder}' already exists.\")\n",
    "    \n",
    "    DATABASE_PATH = os.path.join(faiss_folder, \"faiss_index.index\")\n",
    "    METADATA_PATH = os.path.join(faiss_folder, \"metadata.json\")\n",
    "    \n",
    "    embedding = HuggingFaceEmbeddings(model_name=HUGGINGFACE_MODEL_NAME)\n",
    "    \n",
    "    if os.path.exists(DATABASE_PATH):\n",
    "        print(\"Loading existing FAISS index from disk...\")\n",
    "        vectorstore = FAISS.load_local(DATABASE_PATH, embedding, allow_dangerous_deserialization=True)\n",
    "        if os.path.exists(METADATA_PATH):\n",
    "            with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                metadata = json.load(f)\n",
    "    else:\n",
    "        print(\"Creating new FAISS vector store...\")\n",
    "        from langchain_community.document_loaders import WebBaseLoader\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = FAISS.from_documents(doc_splits, embedding)\n",
    "        vectorstore.save_local(DATABASE_PATH)\n",
    "        metadata = [doc.metadata for doc in doc_splits]\n",
    "        with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        \n",
    "    retriever = vectorstore.as_retriever()    \n",
    "\n",
    "###################################\n",
    "#         ROUTER NODE             #\n",
    "###################################\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model for routing the user query\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Route the user query to either a vectorstore or web search.\"\n",
    "    )\n",
    "\n",
    "# Initialize RAG LLM and router\n",
    "LLM_RAG = config_rag.get(\"llm\")\n",
    "LLM_RAG_TEMP = config_rag.get(\"temperature\")\n",
    "\n",
    "if RAG_CHAT == 'OpenAI':\n",
    "    llm_rag = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "elif RAG_CHAT == 'Ollama':\n",
    "    llm_rag = OllamaFunctions(model=LLM) \n",
    "elif RAG_CHAT == 'LangChain':\n",
    "    llm_rag = llm_LangChain\n",
    "\n",
    "structured_llm_router = llm_rag.with_structured_output(RouteQuery)\n",
    "\n",
    "# Join the topics into a single string, separated by commas\n",
    "topics_str = \", \".join(vectorstore_topics)\n",
    "\n",
    "# Create router prompt\n",
    "router_system_prompt = (\n",
    "    \"You are an expert at routing user queries to either a vectorstore or web search. \"\n",
    "    \"The vectorstore contains documents related to {topics_str}.\"\n",
    "    \"Use the vectorstore for questions on these topics; otherwise, use web search.\"\n",
    "    \"Based on the query, respond with a JSON object that contains a key 'datasource'\"\n",
    "    \"whose value is either 'vectorstore' or 'web_search'. Do not include any additional keys or text.\"\n",
    ")\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", router_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "###################################\n",
    "#      RETRIEVAL GRADER NODE      #\n",
    "###################################\n",
    "\n",
    "# Data model for grading document relevance\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates whether the document is relevant ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm_rag.with_structured_output(GradeDocuments)\n",
    "\n",
    "grader_system_prompt = (\n",
    "    \"You are a grader assessing the relevance of a retrieved document to a user query. \"\n",
    "    \"If the document contains keywords or semantic content related to the user query, grade it as relevant. \"\n",
    "    \"Output a binary score 'yes' or 'no'.\"\n",
    ")\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grader_system_prompt),\n",
    "        (\"human\", \"Retrieved document:\\n\\n{document}\\n\\nUser query:\\n{question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "###################################\n",
    "#        GENERATION CHAIN         #\n",
    "###################################\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# Set up in-memory cache to avoid repeating expensive LLM calls.\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "\"\"\"\n",
    "context_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an expert in information retrieval and content synthesis. Your task is to refine and enhance context \"\n",
    "                \"from multiple sources by generating a cohesive, well-structured, and detailed context that combines information \"\n",
    "                \"from various retrieved documents.\\n\\n\"\n",
    "                \"Responsibilities:\\n\"\n",
    "                \"1. Synthesize information from multiple sources into a unified explanation.\\n\"\n",
    "                \"2. Expand on the query with relevant details from the retrieved content.\\n\"\n",
    "                \"3. Format the refined context with clear structure and professional language.\\n\"\n",
    "                \"4. Incorporate metadata for traceability.\\n\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            (\n",
    "                \"Question: {question}\\n\\n\"\n",
    "                \"The following are the retrieved documents and metadata:\\n\\n{context}\\n\\n\"\n",
    "                \"Using this information, generate a refined and comprehensive context.\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Load static content files\n",
    "metamodel_text = load_file_content(metamodel_path)\n",
    "\n",
    "context_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are a domain model expert with deep knowledge of metamodeling and semantic model interpretation.\"\n",
    "                \"Your task is to analyze a given Ecore metamodel and extract a structured and comprehensive domain context.\"\n",
    "                \"This context will be used as background knowledge to guide synthetic model generation.\\n\\n\"\n",
    "                \"Instructions:\\n\"\n",
    "                \"1. Identify and describe the key domain concepts (classes, attributes, references, enumerations).\\n\"\n",
    "                \"2. Explain the relationships and constraints implied by the metamodel structure.\\n\"\n",
    "                \"3. Enrich the context with relevant external domain knowledge.\\n\"\n",
    "                \"4. Structure the output clearly with sections like 'Domain Overview', 'Key Concepts', 'Relationships', 'Behavioral Semantics', and 'External Domain Background'.\\n\"\n",
    "                \"5. When possible, infer the real-world domain (e.g., hardware modeling, system behavior, message passing) and include related terminology.\\n\"\n",
    "                \"6. Use professional and academic language, suitable for expert systems.\\n\"\n",
    "                \"7. Incorporate any relevant metadata such as names, types, multiplicities, and containment relationships.\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            (\n",
    "                \"Here is the Ecore metamodel to analyze:\\n\\n\"\n",
    "                \"{metamodel_text}\\n\\n\"\n",
    "                \"Question: {question}\\n\\n\"\n",
    "                \"The following are the retrieved documents and metadata:\\n\\n{context}\\n\\n\"\n",
    "                \"Using this, generate a refined and detailed context about the domain it represents.\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if RAG_CHAT == 'OpenAI':\n",
    "    llm_for_context = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "elif RAG_CHAT == 'LangChain':\n",
    "    llm_for_context = llm_LangChain\n",
    "    \n",
    "rag_chain = context_prompt_template | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#     HALLUCINATION GRADER        #\n",
    "###################################\n",
    "\n",
    "# Data model for grading hallucination\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer is grounded in facts ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_hallucination = llm_rag.with_structured_output(GradeHallucinations)\n",
    "\n",
    "hallucination_system_prompt = (\n",
    "    \"You are a grader assessing whether the LLM generation is grounded in the retrieved facts. \"\n",
    "    \"Output a binary score 'yes' if the answer is supported by the facts, otherwise 'no'.\"\n",
    ")\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", hallucination_system_prompt),\n",
    "        (\"human\", \"Facts:\\n\\n{documents}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "hallucination_grader = hallucination_prompt | structured_llm_hallucination\n",
    "\n",
    "###################################\n",
    "#         ANSWER GRADER           #\n",
    "###################################\n",
    "\n",
    "\"\"\"\n",
    "# Data model for grading answer relevance\n",
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer addresses the question ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_answer = llm_rag.with_structured_output(GradeAnswer)\n",
    "\n",
    "answer_system_prompt = (\n",
    "    \"You are a grader assessing whether an LLM-generated answer addresses the user query. \"\n",
    "    \"Output a binary score 'yes' if it does, otherwise 'no'.\"\n",
    ")\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_system_prompt),\n",
    "        (\"human\", \"User Query:\\n{question}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "answer_grader = answer_prompt | structured_llm_answer\n",
    "\"\"\"\n",
    "\n",
    "###################################\n",
    "#       QUESTION REWRITER         #\n",
    "###################################\n",
    "\n",
    "rewrite_system_prompt = (\n",
    "    \"You are a question rewriter. Given an input question, produce an improved version optimized for vectorstore retrieval. \"\n",
    "    \"Focus on the underlying semantic intent.\"\n",
    ")\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rewrite_system_prompt),\n",
    "        (\"human\", \"Original question:\\n{question}\\n\\nRewrite the question:\"),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = rewrite_prompt | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#           WEB SEARCH            #\n",
    "###################################\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "config_tavily = load_config(CONFIG_RAG_TAVILY_FILE)\n",
    "os.environ[\"TAVILY_API_KEY\"] = config_tavily.get(\"tavily_api_key\")\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "###################################\n",
    "#       GRAPH STATE DEFINITION    #\n",
    "###################################\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict, total=False): \n",
    "    # Retrieval and model generation branch keys\n",
    "    question: str                         # The user's search question or refined query\n",
    "    generation: str                       # The generated answer or refined query output\n",
    "    documents: List[Any]                  # List of retrieved documents\n",
    "    file_name: str                        # For model generation node\n",
    "    context_llm: str                      # The refined context generated by the LLM\n",
    "    model_status: str                     # Status of the processing model\n",
    "    model_out: str                        # The output model\n",
    "    metadata: Dict[str, Any]              # Additional metadata related to the process\n",
    "    branch: str                           # Indicates the branch: \"retrieve\" or \"web_search\"\n",
    "    evaluation_metrics: Dict[str, float]  # Metrics evaluating the generated results\n",
    "    bert_score: Dict[str, float]          # BERTScore metrics for evaluating document support\n",
    "    web_bert_score: Dict[str, float]      # BERTScore metrics for evaluating web search branch results\n",
    "    skip_router: bool                     # If True, skip the routing and proceed directly to cache_context_node\n",
    "    model_val: bool                       # Flag indicating whether the model should be refined or not\n",
    "    validation_attempts: int              # Number of validation/correction attempts\n",
    "    next_step: str                        # Next transition key for conditional routing\n",
    "    val_cycles: int                     # Number of generation-validation cycles\n",
    "\n",
    "###################################\n",
    "# FUNCTION: GENERATE QUERY FROM METAMODEL #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_from_metamodel(metamodel_path):\n",
    "    \"\"\"\n",
    "    Reads the metamodel (Ecore file), extracts basic information (package name, nsURI, and classifiers),\n",
    "    and constructs a query based solely on the extracted information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(metamodel_path)\n",
    "        root = tree.getroot()\n",
    "        # The root is typically an EPackage with attributes\n",
    "        package_name = root.attrib.get(\"name\", \"UnknownPackage\")\n",
    "        ns_uri = root.attrib.get(\"nsURI\", \"Unknown nsURI\")\n",
    "        # Extract all classifiers (e.g., EClass, EEnum, etc.)\n",
    "        classifiers = []\n",
    "        for classifier in root.findall(\"{http://www.eclipse.org/emf/2002/Ecore}eClassifiers\"):\n",
    "            classifiers.append(classifier.attrib.get(\"name\", \"UnnamedClassifier\"))\n",
    "        classifiers_str = \", \".join(classifiers) if classifiers else \"None\"\n",
    "        # Build a generic query based solely on the metamodel information\n",
    "        query = (\n",
    "            f\"Metamodel Analysis Query:\\n\"\n",
    "            f\"Package Name: {package_name}\\n\"\n",
    "            f\"Namespace URI: {ns_uri}\\n\"\n",
    "            f\"Classifiers: {classifiers_str}\\n\"\n",
    "            \"Based solely on the metamodel information provided above, generate a context for a tool based on this metamodel. \"\n",
    "            \"The context should include the tool's name, which must be directly derived from the package name.\"\n",
    "        )\n",
    "        return query\n",
    "    except Exception as e:\n",
    "        print(\"Error generating query from metamodel:\", e)\n",
    "        return \"Metamodel analysis query could not be generated.\"\n",
    "\n",
    "# The query for generating the context is now created based on the metamodel\n",
    "# question = generate_query_from_metamodel(metamodel_path)\n",
    "# print(question)\n",
    "\n",
    "###################################\n",
    "#        EVALUATION NODES         #\n",
    "###################################\n",
    "\n",
    "# (1) LLM-based Evaluation for RAG output (vectorstore branch)\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RAGEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the facts.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the question.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the context used.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved context.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of the context.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the context.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_rag_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the RAG output (vectorstore branch) based on metrics such as:\n",
    "    Faithfulness, Answer Relevance, Context Precision, Context Accuracy,\n",
    "    Context Recall, and Context F1.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE RAG OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of RAG outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, and Context F1. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer:\\n{generation}\\n\\nContext:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(RAGEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during evaluation of RAG output:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (2) BERTScore Evaluation for RAG output (vectorstore branch)\n",
    "@profile_node\n",
    "def evaluate_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty. Skipping BERTScore evaluation.\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    bert_precision = P[0].item()\n",
    "    bert_recall = R[0].item()\n",
    "    bert_f1 = F1[0].item()\n",
    "    state[\"bert_score\"] = {\"precision\": bert_precision, \"recall\": bert_recall, \"f1\": bert_f1}\n",
    "    print(\"BERTScore metrics:\", state[\"bert_score\"])\n",
    "    return state\n",
    "\n",
    "# (3) LLM-based Evaluation for Web Search output\n",
    "# Here, we introduce an additional metric \"accuracy\" along with the previous ones.\n",
    "class WebEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the web sources.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the query.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the web search results.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved web content.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of relevant web information.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the web search results.\")\n",
    "    accuracy: float = Field(..., description=\"Score (0-1) indicating the overall accuracy of the generated context based on web sources.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_web_search_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the output of the web search branch.\n",
    "    It uses the same metrics as the RAG evaluation plus an extra metric 'accuracy'.\n",
    "    The reference is the concatenated web search source content.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE WEB SEARCH OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of web search outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, Context F1, and Accuracy. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1, accuracy.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer/Context:\\n{generation}\\n\\nWeb Search Sources:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(WebEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Web search evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during web search evaluation:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (4) BERTScore Evaluation for Web Search output\n",
    "@profile_node\n",
    "def evaluate_web_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE WEB BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty for web search. Skipping BERTScore evaluation.\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    web_bert_precision = P[0].item()\n",
    "    web_bert_recall = R[0].item()\n",
    "    web_bert_f1 = F1[0].item()\n",
    "    state[\"web_bert_score\"] = {\"precision\": web_bert_precision, \"recall\": web_bert_recall, \"f1\": web_bert_f1}\n",
    "    print(\"Web BERTScore metrics:\", state[\"web_bert_score\"])\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#        DECIDE TO GENERATE       #\n",
    "###################################\n",
    "\n",
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    print(\"--- DECIDE TO GENERATE ---\")\n",
    "    filtered_documents = state.get(\"documents\", [])\n",
    "    if not filtered_documents:\n",
    "        branch = state.get(\"branch\", \"retrieve\")  # Fallback default to \"retrieve\"\n",
    "        if branch == \"retrieve\":\n",
    "            print(\"--- No relevant documents found in vectorstore; transforming query to improve retrieval ---\")\n",
    "            return \"transform_query\"\n",
    "        else:  # branch == \"web_search\"\n",
    "            print(\"--- No documents found via web search; proceeding with generation using empty context ---\")\n",
    "            return \"generate\"\n",
    "    else:\n",
    "        print(\"--- Relevant documents found, generating answer ---\")\n",
    "        return \"generate\"\n",
    "\n",
    "###################################\n",
    "#        CACHE NODE (LangGraph)   #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def cache_context_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that checks if a refined context is already available.\n",
    "    If present in the state or in the file cache, it uses that value.\n",
    "    Otherwise, it generates the refined context using the rag_chain,\n",
    "    caches it (in state and on disk), and returns the state.\n",
    "    \"\"\"\n",
    "    if \"context_llm\" in state and state[\"context_llm\"]:\n",
    "        print(\"Using refined context already present in state.\")\n",
    "        return state\n",
    "\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        try:\n",
    "            with open(REFINED_CONTEXT_PATH, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            state[\"context_llm\"] = data.get(\"context\", \"\")\n",
    "            print(\"Loaded refined context from file cache (LangGraph node).\")\n",
    "            return state\n",
    "        except Exception as e:\n",
    "            print(\"Error loading refined context from file in cache node:\", e)\n",
    "\n",
    "    print(\"Generating refined context in LangGraph cache node...\")\n",
    "    refined_context = rag_chain.invoke({\"question\": state[\"question\"], \"context\": \"\", \"metamodel_text\": metamodel_text})\n",
    "    state[\"context_llm\"] = refined_context\n",
    "    try:\n",
    "        with open(REFINED_CONTEXT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"context\": refined_context}, f, indent=4, ensure_ascii=False)\n",
    "        print(\"Refined context cached to file from LangGraph node.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error caching refined context to file in cache node:\", e)\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#          GRAPH NODES            #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that generates the query from the metamodel.\n",
    "    If the refined context file exists, skip query generation and mark state to bypass router.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        print(\"Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\")\n",
    "        state[\"skip_router\"] = True  # Flag to skip routing\n",
    "    else:\n",
    "        state[\"skip_router\"] = False  # Flag to skip routing\n",
    "        state[\"question\"] = generate_query_from_metamodel(metamodel_path)\n",
    "        print(\"Generated query from metamodel:\", state[\"question\"])\n",
    "    return state\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# Node: Retrieve documents using the vectorstore\n",
    "@profile_node\n",
    "def retrieve(state: GraphState) -> GraphState:\n",
    "    print(\"--- RETRIEVE ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = retriever.invoke(question_val)\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "# Node: Perform web search (remains separate)\n",
    "@profile_node\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    print(\"--- WEB SEARCH ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    docs = web_search_tool.invoke({\"query\": question_val})\n",
    "\n",
    "    # Combine web search results into a single Document\n",
    "    \"\"\"\n",
    "    web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state\n",
    "    \"\"\"\n",
    "    # Check the type of docs and extract content accordingly.\n",
    "    if isinstance(docs, str):\n",
    "        # If docs is a string, use it directly.\n",
    "        web_results_content = docs\n",
    "    elif isinstance(docs, list):\n",
    "        # If docs is a list, check the type of its elements.\n",
    "        if docs and isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "            web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "        else:\n",
    "            # Assume it's a list of strings.\n",
    "            web_results_content = \"\\n\".join(docs)\n",
    "    else:\n",
    "        # Fallback: convert docs to string.\n",
    "        web_results_content = str(docs)\n",
    "    \n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state    \n",
    "\n",
    "# Merged Node: Generate answer using the RAG chain (used for both branches)\n",
    "def generate(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question_val, \"metamodel_text\": metamodel_text})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Generate answer using web search results\n",
    "@profile_node\n",
    "def generate_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question, \"metamodel_text\": metamodel_text})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Grade documents for relevance\n",
    "@profile_node\n",
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    print(\"--- GRADE DOCUMENTS ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        \"\"\"\n",
    "        score = retrieval_grader.invoke({\"question\": question_val, \"document\": d.page_content})\n",
    "        if score.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Document is relevant ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- Document is not relevant ---\")\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        attempts = 0\n",
    "        max_attempts = 3\n",
    "        score = None\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                print(\"Calling retrieval_grader with input:\", {\"question\": question_val, \"document\": d.page_content})\n",
    "                output = retrieval_grader.invoke({\"question\": question_val, \"document\": d.page_content})\n",
    "                print(\"Raw score output:\", output)\n",
    "                if isinstance(output, dict):\n",
    "                    score = output.get(\"binary_score\")\n",
    "                else:\n",
    "                    print(\"Unexpected output format:\", output)\n",
    "                    score = output.get(\"binary_score\")\n",
    "                break  # Exit loop if the call is successful\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    wait_time = 10  # seconds to wait; adjust if needed\n",
    "                    print(f\"Rate limit exceeded, waiting for {wait_time} seconds before retrying...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    attempts += 1\n",
    "                else:\n",
    "                    raise  # Re-raise the error if it's not a 429\n",
    "            except httpx.ReadTimeout as e:\n",
    "                wait_time = 10  # seconds to wait; adjust if needed\n",
    "                print(f\"Read timeout occurred, waiting for {wait_time} seconds before retrying...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempts += 1\n",
    "        if score is None:\n",
    "            print(\"The retrieval_grader did not return a valid result for this document, skipping it.\")\n",
    "            continue\n",
    "        if score.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Document is relevant ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- Document is not relevant ---\")\n",
    "        \"\"\"\n",
    "        attempts = 0\n",
    "        max_attempts = 3\n",
    "        score = None\n",
    "\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                input_data = {\"question\": question_val, \"document\": d.page_content}\n",
    "                # print(f\"\\n[Grade Attempt] Input:\\n{json.dumps(input_data, indent=2)}\")\n",
    "\n",
    "                raw_output = retrieval_grader.invoke(input_data)\n",
    "                # print(f\"[Grade Output] Raw result:\\n{raw_output}\")\n",
    "\n",
    "                # Check if we received a proper object or dict\n",
    "                if hasattr(raw_output, 'binary_score'):\n",
    "                    binary = raw_output.binary_score.lower()\n",
    "                elif isinstance(raw_output, dict) and \"binary_score\" in raw_output:\n",
    "                    binary = raw_output[\"binary_score\"].lower()\n",
    "                else:\n",
    "                    print(\"Unexpected output format, skipping document.\")\n",
    "                    break  # Skip this doc\n",
    "\n",
    "                if binary == \"yes\":\n",
    "                    print(\"Document is relevant.\")\n",
    "                    filtered_docs.append(d)\n",
    "                else:\n",
    "                    print(\"Document is not relevant.\")\n",
    "\n",
    "                break  # Done with this document\n",
    "\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                if e.response.status_code in [429, 502, 503]:\n",
    "                    wait_time = 10\n",
    "                    print(f\"HTTP {e.response.status_code} error, retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    attempts += 1\n",
    "                else:\n",
    "                    print(f\"Unexpected HTTP error {e.response.status_code}: {e}\")\n",
    "                    break  # Exit loop for other HTTP errors\n",
    "            except httpx.ReadTimeout as e:\n",
    "                wait_time = 10\n",
    "                print(f\"Read timeout, waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                attempts += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error grading document: {e}\")\n",
    "                break  # Don't loop forever on unknown errors\n",
    "\n",
    "    state[\"documents\"] = filtered_docs\n",
    "    return state\n",
    "    \n",
    "\n",
    "# Merged Node: Transform the query (for both branches)\n",
    "@profile_node\n",
    "def transform_query(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question_val})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Node: Transform the query for web search\n",
    "@profile_node\n",
    "def transform_query_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Conditional routing after transformation: based on branch in state\n",
    "\"\"\"\n",
    "def route_after_transform(state: GraphState) -> str:\n",
    "    if state.get(\"branch\") == \"retrieve\":\n",
    "        return \"retrieve\"\n",
    "    elif state.get(\"branch\") == \"web_search\":\n",
    "        return \"web_search\"\n",
    "    return \"retrieve\"\n",
    "\"\"\"\n",
    "\n",
    "# Node: Grade the generation against the documents and question\n",
    "@profile_node\n",
    "def grade_generation_v_documents_and_question(state: GraphState) -> str:\n",
    "    print(\"--- GRADE GENERATION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # Evaluate if the generation is supported by the retrieved documents.\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    if score.binary_score.lower() == \"yes\":\n",
    "        print(\"--- Generation is grounded in documents ---\")\n",
    "        # score_answer = answer_grader.invoke({\"question\": question_val, \"generation\": generation})\n",
    "        # if score_answer.binary_score.lower() == \"yes\":\n",
    "        #     print(\"--- Generation addresses the question ---\")\n",
    "        return \"useful\"\n",
    "        # else:\n",
    "        #     print(\"--- Generation does not address the question ---\")\n",
    "        #     return \"not useful\"\n",
    "    else:\n",
    "        print(\"--- Generation is not supported by documents, retrying ---\")\n",
    "        return \"not useful\"\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# Node: model Generation – generate model and JSON metadata from a single file.\n",
    "# TODO: change this function to model generation and feedback with Eclipse EMF\n",
    "@profile_node\n",
    "def model_generation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node for generating the model and JSON metadata\n",
    "    from a single file using the refined context.\n",
    "    \n",
    "    Expected state:\n",
    "      - \"file_name\": the file to process.\n",
    "      - \"context_llm\": the refined context.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = state[\"file_name\"]\n",
    "    context_llm = state[\"context_llm\"]\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    \n",
    "    output_model_path = os.path.join(base_output_dir, file_name)\n",
    "    metadata_path = os.path.join(base_output_json_dir, file_name)\n",
    "\n",
    "    attempts = state.get(\"validation_attempts\", 0)\n",
    "    cycles_loop = state.get(\"val_cycles\", 0)\n",
    "    \n",
    "    # Skip processing if the output files already exist\n",
    "    if os.path.exists(output_model_path) and os.path.exists(metadata_path) and attempts == 0 and cycles_loop == 0:\n",
    "        print(f\"Skipping {file_name} as output files already exist.\")\n",
    "\n",
    "        val_cycles_value = state.get(\"val_cycles\", 0) + 3\n",
    "        state[\"val_cycles\"] = val_cycles_value\n",
    "        \n",
    "        val_attemps_value = state.get(\"validation_attempts\", 0) + 3\n",
    "        state[\"validation_attempts\"] = val_attemps_value\n",
    "        \n",
    "        state[\"model_status\"] = \"skipped\"\n",
    "        return state\n",
    "    # else if \n",
    "\n",
    "    # Load the model file description\n",
    "    input_file_path = os.path.join(base_model_path, file_name)\n",
    "    model_description = load_file_content(input_file_path)\n",
    "    \n",
    "    # Load static content files\n",
    "    metamodel_content = load_file_content(metamodel_path)\n",
    "    example_model_content = load_file_content(example_model_path)\n",
    "    \n",
    "    # Define system prompt for model generation\n",
    "    system_prompt = (\n",
    "        \"You are an expert in Model-Driven Engineering and EMF (Eclipse Modeling Framework). \"\n",
    "        \"Your task is to generate a valid model instance that conforms to a given Ecore metamodel. \"\n",
    "        \"You will receive:\\n\"\n",
    "        \"- A context extracted using Retrieval-Augmented Generation (RAG) to provide relevant background information.\\n\\n\"\n",
    "        \"- A metamodel definition (in Ecore format).\\n\"\n",
    "        \"- An example model that demonstrates the structure and syntax of a valid instance.\\n\"\n",
    "        \"- A text-based description of the desired model (in natural language).\\n\"\n",
    "        \"You must return a syntactically correct and complete model file that adheres to the metamodel structure,\"\n",
    "        \"accurately represents the input description, and follows the style of the example provided.\"\n",
    "        #\"The output should be in plain text, without any explanations, comments, or extra formatting.\"\n",
    "        \"**Do not** add comments, backticks (```), or markdown formatting like ```xml. \"\n",
    "        \"The output must be pure XML text, starting directly with the XML declaration `<?xml version=\\\"1.0\\\" ...>` and ending with the last closing tag. \"\n",
    "        \"Do not prepend or append anything outside the model content.\"\n",
    "        \"Only return the model file content.\"\n",
    "    )\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", (\n",
    "                f\"Context:\\n{context_llm}\\n\\n\"\n",
    "                \"This is the metamodel:\\n\\n{metamodel_content}\\n\\n\"\n",
    "                \"(Input example) This is an example model based on the given metamodel:\\n\\n{example_model_content}\\n\\n\"\n",
    "                \"(Input) Generate the model file for the following text description:\\n\\n{model_description}\\n\\n\"\n",
    "                \"Do not add comments or extra quotation marks at the beginning and end of the model file.\"\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Invoke the LLM chain for model generation\n",
    "    start_time_llm = time.time()\n",
    "    response_chain = chat_prompt | llm_LangChain\n",
    "    # print(f\"Final Prompt:{response_chain}\")\n",
    "    result = response_chain.invoke({\n",
    "        \"context\": context_llm,\n",
    "        \"metamodel_content\": metamodel_content,\n",
    "        \"example_model_content\": example_model_content,\n",
    "        \"model_description\": model_description,\n",
    "    })\n",
    "    print(f\"Final Results:{result}\")\n",
    "    end_time_llm = time.time()\n",
    "    execution_time = end_time_llm - start_time_llm\n",
    "    \n",
    "    # Extract the model from the result\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        model_output = result.content.strip()\n",
    "    else:\n",
    "        # model_output = result.strip()\n",
    "        # Extract the model from the result\n",
    "        if hasattr(result, \"content\"):\n",
    "            model_output = result.content.strip()\n",
    "        else:\n",
    "            model_output = str(result).strip()\n",
    "    \n",
    "    # Build metadata for the response\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        metadata = {\n",
    "            \"response_length\": len(model_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"usage\": result.usage_metadata,\n",
    "            \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN +\n",
    "                         result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    else:\n",
    "        metadata = {\n",
    "            \"response_length\": len(model_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "\n",
    "    # Check if metadata file already exists\n",
    "    \"\"\"\n",
    "    if os.path.exists(metadata_path):\n",
    "        try:\n",
    "            with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_metadata = json.load(f)\n",
    "            print(f\"[INFO] Loaded existing metadata from {metadata_path}\")\n",
    "    \n",
    "            # Increment numeric fields if they exist\n",
    "            for key in [\"execution_time\", \"response_length\", \"price_usd\"]:\n",
    "                if key in metadata and key in existing_metadata:\n",
    "                    if isinstance(metadata[key], (int, float)) and isinstance(existing_metadata[key], (int, float)):\n",
    "                        metadata[key] += existing_metadata[key]\n",
    "    \n",
    "            # Optionally merge nested 'usage' dictionaries if present\n",
    "            if \"usage\" in metadata and \"usage\" in existing_metadata:\n",
    "                for token_key in [\"input_tokens\", \"output_tokens\", \"total_tokens\"]:\n",
    "                    if token_key in metadata[\"usage\"] and token_key in existing_metadata[\"usage\"]:\n",
    "                        metadata[\"usage\"][token_key] += existing_metadata[\"usage\"][token_key]\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not read or parse existing metadata: {e}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save the model and metadata to output files\n",
    "    save_to_file(output_model_path, model_output)\n",
    "    save_metadata(metadata_path, metadata)\n",
    "    \n",
    "    print(f\"Processed: {file_name}\")\n",
    "    print(f\"Model saved to: {output_model_path}\")\n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "    val_cycles_value = state.get(\"val_cycles\", 0) + 1\n",
    "    state[\"val_cycles\"] = val_cycles_value\n",
    "    \n",
    "    state[\"model_status\"] = \"processed\"\n",
    "    state[\"model_out\"] = model_output\n",
    "    state[\"metadata\"] = metadata\n",
    "    state[\"validation_attempts\"] = 0\n",
    "    return state\n",
    "\n",
    "# Node: model Generation – generate model and JSON metadata from a single file.\n",
    "# TODO: change this function to model generation and feedback with Eclipse EMF\n",
    "@profile_node\n",
    "def model_validation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    file_name = state[\"file_name\"]\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the generated model file description\n",
    "    output_model_path_val = os.path.join(base_output_dir, file_name)\n",
    "    output_model_path_val_abs = os.path.abspath(output_model_path_val)\n",
    "\n",
    "    # Connect to the running Java EMF Validator\n",
    "    gateway = JavaGateway()\n",
    "    validator = gateway.entry_point\n",
    "\n",
    "    # Paths to the BPMN Model and Ecore Metamodel\n",
    "    file_extension = \"hepsy\"  # \"hepsy\", \"caex\", etc.\n",
    "\n",
    "    # Model Validation\n",
    "    metamodel_path_val_abs = os.path.abspath(metamodel_path)\n",
    "\n",
    "    print(\"[DEBUG] Validating with:\")\n",
    "    print(\" - Model:\", output_model_path_val_abs)\n",
    "    print(\" - Metamodel:\", metamodel_path_val_abs)\n",
    "    \n",
    "    result = validator.validateModel(output_model_path_val_abs, metamodel_path_val_abs, file_extension)\n",
    "    print(result)\n",
    "    \n",
    "    state[\"model_val\"] = True\n",
    "    return state\n",
    "    \"\"\"\n",
    "    val_cycles = state.get(\"val_cycles\", 0)\n",
    "    validation_attempts = state.get(\"validation_attempts\", 0)\n",
    "\n",
    "    file_name = state[\"file_name\"]\n",
    "    # name_val = \"refined\"\n",
    "\n",
    "    # Split the filename into name and extension\n",
    "    file_base, file_ext = os.path.splitext(file_name)\n",
    "    print(f\"file_base: {file_base}, file_ext: {file_ext}\")\n",
    "\n",
    "    # Append the index to the base name\n",
    "    file_name_metadata = f\"{file_base}_{val_cycles}_{validation_attempts}{file_ext}\"\n",
    "    print(f\"file_name_metadata: {file_name_metadata}\")\n",
    "\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    output_model_path_val = os.path.join(base_output_dir, file_name)\n",
    "    output_model_path_val_abs = os.path.abspath(output_model_path_val)\n",
    "    metamodel_path_val_abs = os.path.abspath(metamodel_path)\n",
    "\n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    metadata_path_val = os.path.join(base_output_json_dir, file_name_metadata)\n",
    "\n",
    "    # Check if metadata file already exists\n",
    "    \"\"\"\n",
    "    if os.path.exists(metadata_path_val):\n",
    "        \n",
    "        # Flag model as corrected (will be revalidated on next iteration)\n",
    "        val_cycles_value = state.get(\"val_cycles\", 0) + 3\n",
    "        state[\"val_cycles\"] = val_cycles_value\n",
    "        \n",
    "        val_attemps_value = state.get(\"validation_attempts\", 0) + 3\n",
    "        state[\"validation_attempts\"] = val_attemps_value\n",
    "        \n",
    "        state[\"model_val\"] = False  # For now mark as not valid (you can revalidate if desired)\n",
    "        return state  \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        try:\n",
    "            with open(metadata_path_val, \"r\", encoding=\"utf-8\") as f:\n",
    "                existing_metadata = json.load(f)\n",
    "            print(f\"[INFO] Loaded existing metadata from {metadata_path_val}\")\n",
    "    \n",
    "            # Increment numeric fields if they exist\n",
    "            for key in [\"execution_time\", \"response_length\", \"price_usd\"]:\n",
    "                if key in metadata and key in existing_metadata:\n",
    "                    if isinstance(metadata[key], (int, float)) and isinstance(existing_metadata[key], (int, float)):\n",
    "                        metadata[key] += existing_metadata[key]\n",
    "    \n",
    "            # Optionally merge nested 'usage' dictionaries if present\n",
    "            if \"usage\" in metadata and \"usage\" in existing_metadata:\n",
    "                for token_key in [\"input_tokens\", \"output_tokens\", \"total_tokens\"]:\n",
    "                    if token_key in metadata[\"usage\"] and token_key in existing_metadata[\"usage\"]:\n",
    "                        metadata[\"usage\"][token_key] += existing_metadata[\"usage\"][token_key]\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Could not read or parse existing metadata: {e}\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the Java EMF Validator\n",
    "    gateway = JavaGateway()\n",
    "    validator = gateway.entry_point\n",
    "    file_extension = \"hepsy\"\n",
    "\n",
    "    print(\"[DEBUG] Validating with:\")\n",
    "    print(\" - Model:\", output_model_path_val_abs)\n",
    "    print(\" - Metamodel:\", metamodel_path_val_abs)\n",
    "\n",
    "    validation_result = validator.validateModel(output_model_path_val_abs, metamodel_path_val_abs, file_extension)\n",
    "    print(\"[VALIDATION RESULT]\", validation_result)\n",
    "\n",
    "    # CASE 1: VALID MODEL\n",
    "    if \"Validation successful\" in validation_result:\n",
    "        print(\"Model is valid.\")\n",
    "        state[\"model_val\"] = True\n",
    "        state[\"next_step\"] = \"validated\"\n",
    "        return state\n",
    "    else:\n",
    "        attempts = state.get(\"validation_attempts\", 0) + 1\n",
    "        state[\"validation_attempts\"] = attempts\n",
    "\n",
    "        if attempts >= 3:\n",
    "            if val_cycles >= 2:\n",
    "                print(f\"[ERROR] Model is still invalid after {val_cycles} generation-validation cycles. Stopping.\")\n",
    "                state[\"next_step\"] = \"not_validated\"\n",
    "                return state\n",
    "            else:\n",
    "                print(f\"[INFO] Model invalid. Will regenerate. Cycle: {val_cycles}, Attempts: {validation_attempts}\")\n",
    "                state[\"next_step\"] = \"regenerate\"\n",
    "        else:\n",
    "            state[\"next_step\"] = \"continue\"\n",
    "        state[\"model_val\"] = False\n",
    "\n",
    "    # CASE 2: INVALID MODEL — Need to correct with LLM\n",
    "    print(\"Model is invalid. Sending to LLM for correction.\")\n",
    "\n",
    "    model_content = load_file_content(output_model_path_val_abs)\n",
    "    context_llm = state.get(\"context_llm\", \"\")\n",
    "    metamodel_content = load_file_content(metamodel_path)\n",
    "    example_model_content = load_file_content(example_model_path)\n",
    "\n",
    "    correction_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are a Model-Driven Engineering (MDE) and Eclipse Modeling Framework (EMF) expert. \"\n",
    "            \"A model file failed validation against an Ecore metamodel. Your job is to fix the model.\\n\\n\"\n",
    "            \"You will be given:\\n\"\n",
    "            \"- The validation error message.\\n\"\n",
    "            \"- The metamodel definition (Ecore).\\n\"\n",
    "            \"- An example valid model.\\n\"\n",
    "            \"- The model that failed.\\n\\n\"\n",
    "            \"Correct the model so that it becomes valid. Return only the corrected model, with no comments or explanations.\"\n",
    "            \"Do not add extra text or quotation marks at the beginning and end of the model file.\"\n",
    "            \"Let's think step by step\"\n",
    "        )),\n",
    "        (\"user\", (\n",
    "            f\"Validation error:\\n{validation_result}\\n\\n\"\n",
    "            f\"Metamodel:\\n{metamodel_content}\\n\\n\"\n",
    "            f\"Example model:\\n{example_model_content}\\n\\n\"\n",
    "            f\"Invalid model:\\n{model_content}\\n\\n\"\n",
    "            f\"Provide the corrected model:\"\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    correction_chain = correction_prompt | llm_LangChain\n",
    "    # print(correction_chain)\n",
    "\n",
    "    # Invoke the LLM chain for model refinement\n",
    "    start_time_llm = time.time()\n",
    "    result = correction_chain.invoke({\n",
    "        \"validation_result\": validation_result,\n",
    "        \"metamodel_content\": metamodel_content,\n",
    "        \"example_model_content\": example_model_content,\n",
    "        \"model_content\": model_content,\n",
    "    })\n",
    "    end_time_llm = time.time()\n",
    "    execution_time = end_time_llm - start_time_llm\n",
    "\n",
    "    corrected_model_partial = result.content.strip() \n",
    "\n",
    "    # corrected_model = corrected_model_partial.strip()\n",
    "    #if not corrected_model.startswith(\"<?xml\"):\n",
    "    #    corrected_model = \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\" + corrected_model\n",
    "\n",
    "    # Pulisce il modello rimuovendo righe con ```\n",
    "    lines = corrected_model_partial.strip().splitlines()\n",
    "    cleaned_lines = [line for line in lines if not line.strip().startswith(\"```\")]\n",
    "    corrected_model = \"\\n\".join(cleaned_lines).strip()\n",
    "\n",
    "    # Build metadata for the response\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        metadata = {\n",
    "            \"response_length\": len(corrected_model),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"usage\": result.usage_metadata,\n",
    "            \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN +\n",
    "                         result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    else:\n",
    "        metadata = {\n",
    "            \"response_length\": len(corrected_model),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "        \n",
    "    # Save the corrected model (overwrite original file)\n",
    "    save_to_file(output_model_path_val_abs, corrected_model)\n",
    "    save_metadata(metadata_path_val, metadata)\n",
    "\n",
    "    print(f\"Processed: {file_name}\")\n",
    "    print(f\"Corrected model saved to: {output_model_path_val_abs}\")\n",
    "    print(f\"Metadata saved to: {metadata_path_val}\")\n",
    "\n",
    "    # Track number of validation attempts\n",
    "    \"\"\"\n",
    "    attempts = state.get(\"validation_attempts\", 0) + 1\n",
    "    state[\"validation_attempts\"] = attempts\n",
    "    \n",
    "    # If attempts exceed max, restart from model_generation\n",
    "    MAX_ATTEMPTS = 3\n",
    "    if attempts >= MAX_ATTEMPTS:\n",
    "        print(f\"[INFO] Max validation attempts ({MAX_ATTEMPTS}) reached. Re-generating model.\")\n",
    "        return \"regenerate\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flag model as corrected (will be revalidated on next iteration)\n",
    "    state[\"model_val\"] = False  # For now mark as not valid (you can revalidate if desired)\n",
    "    return state    \n",
    "\n",
    "def model_to_MSE_node(state: GraphState) -> GraphState:\n",
    "    val_cycles = state.get(\"val_cycles\", 0)\n",
    "    if val_cycles >= 2:\n",
    "        print(f\"[ERROR] Model is still invalid after {val_cycles} generation-validation cycles. Stopping.\")\n",
    "    else:\n",
    "        print(\"Model generated correctly!!!\")\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#       GRAPH WORKFLOW SETUP      #\n",
    "###################################\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Initialize the state graph using our GraphState type\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "\n",
    "# Add the new node to the workflow\n",
    "workflow.add_node(\"generate_query\", generate_query_node)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)             # Merged generate node\n",
    "workflow.add_node(\"generate_web\", generate_web)\n",
    "workflow.add_node(\"transform_query\", transform_query) # Merged transform node\n",
    "workflow.add_node(\"transform_query_web\", transform_query_web)\n",
    "\n",
    "# Add evaluation nodes for vectorstore branch\n",
    "workflow.add_node(\"evaluate_rag_output\", evaluate_rag_output)\n",
    "workflow.add_node(\"evaluate_bert_score\", evaluate_bert_score)\n",
    "\n",
    "# Add evaluation nodes for web search branch\n",
    "workflow.add_node(\"evaluate_web_search_output\", evaluate_web_search_output)\n",
    "workflow.add_node(\"evaluate_web_bert_score\", evaluate_web_bert_score)\n",
    "\n",
    "workflow.add_node(\"cache_context\", cache_context_node)  # Caching node\n",
    "workflow.add_node(\"model_generation\", model_generation_node)\n",
    "workflow.add_node(\"model_validation\", model_validation_node)\n",
    "workflow.add_node(\"model_to_MSE\", model_to_MSE_node)\n",
    "\n",
    "\n",
    "def custom_parse_router_output(raw_output: str) -> RouteQuery:\n",
    "    try:\n",
    "        data = json.loads(raw_output)\n",
    "        # If the output contains \"datasource\", use it directly.\n",
    "        if \"datasource\" in data:\n",
    "            return RouteQuery(**data)\n",
    "        # Alternatively, if the output contains a \"tool\" key and it equals \"HEPSYCODE\",\n",
    "        # you might decide to map it to one of your expected values.\n",
    "        elif data.get(\"tool\") == \"HEPSYCODE\":\n",
    "            # Here you can choose what \"HEPSYCODE\" should map to.\n",
    "            # For example, if HEPSYCODE is related to vectorstore, then:\n",
    "            return RouteQuery(datasource=\"vectorstore\")\n",
    "        else:\n",
    "            raise ValueError(\"Output does not contain a valid routing decision.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse router output: {e}\")\n",
    "\n",
    "# Starting node: route question decides between web_search and vectorstore (retrieve)\n",
    "def route_question(state: GraphState) -> str:\n",
    "    # If the flag is present, skip the routing and return a special key (\"skip\")\n",
    "    if state.get(\"skip_router\", False):\n",
    "        print(\"Skipping routing; moving directly to cache_context.\")\n",
    "        return \"skip\"\n",
    "        \n",
    "    print(\"--- ROUTE QUESTION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question_val, \"topics_str\": topics_str})\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = custom_parse_router_output(source)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing router output:\", e)\n",
    "        # Fallback to a default value\n",
    "        parsed = RouteQuery(datasource=\"web_search\")\n",
    "    \"\"\"\n",
    "        \n",
    "    # Normalize the datasource value.\n",
    "    datasource = source.datasource.lower().strip()\n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"--- Routing to vectorstore ---\")\n",
    "        state[\"branch\"] = \"retrieve\"\n",
    "        return \"vectorstore\"\n",
    "    elif datasource == \"web_search\":\n",
    "        print(\"--- Routing to web search ---\")\n",
    "        state[\"branch\"] = \"web_search\"\n",
    "        return \"web_search\"\n",
    "    state[\"branch\"] = \"retrieve\"\n",
    "    return \"vectorstore\"\n",
    "\n",
    "# Add an edge from the START node to the new \"generate_query\" node\n",
    "workflow.add_edge(START, \"generate_query\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"skip\": \"cache_context\", # If the flag is active, go directly to cache_context_node\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"vectorstore\": \"retrieve\",  # Key now matches the returned normalized value\n",
    "    },\n",
    ")\n",
    "\n",
    "# For the web search branch, send directly to generate.\n",
    "workflow.add_edge(\"web_search\", \"generate_web\")\n",
    "\n",
    "# For the retrieve branch, first go to grade_documents.\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# After grading, decide whether to generate or transform.\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    lambda state: decide_to_generate(state),\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"transform_query_web\", \"web_search\")\n",
    "\n",
    "# After generate/generate_web, grade the generation.\n",
    "# If the generation is \"useful\", route to the caching node.\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate\",\n",
    "        \"useful\": \"evaluate_rag_output\",\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_rag_output\", \"evaluate_bert_score\")\n",
    "workflow.add_edge(\"evaluate_bert_score\", \"cache_context\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_web\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate_web\",\n",
    "        \"useful\": \"evaluate_web_search_output\",\n",
    "        \"not useful\": \"transform_query_web\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_web_search_output\", \"evaluate_web_bert_score\")\n",
    "workflow.add_edge(\"evaluate_web_bert_score\", \"cache_context\")\n",
    "\n",
    "# After caching, flow to model generation.\n",
    "workflow.add_edge(\"cache_context\", \"model_generation\")\n",
    "# workflow.add_edge(\"model_generation\", END)  # End the workflow after model validation\n",
    "workflow.add_edge(\"model_generation\", \"model_validation\")  # End the workflow after model validation\n",
    "\n",
    "# If model_validation sets model_val = False, redirect to model_generation\n",
    "\"\"\"\n",
    "workflow.add_conditional_edges(\n",
    "    \"model_validation\",\n",
    "    lambda state: \"validated\" if state.get(\"model_val\") else \"continue\",\n",
    "    {\n",
    "        \"validated\": \"model_to_MSE\",  \n",
    "        \"continue\": \"model_validation\"  \n",
    "    },\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"model_validation\",\n",
    "    lambda state: state.get(\"next_step\", \"continue\"),  # Usa direttamente il campo\n",
    "    {\n",
    "        \"validated\": \"model_to_MSE\",\n",
    "        \"continue\": \"model_validation\",\n",
    "        \"regenerate\": \"model_generation\",\n",
    "        \"not_validated\": \"model_to_MSE\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# workflow.add_edge(\"model_validation\", END)  # End the workflow after model generation\n",
    "workflow.add_edge(\"model_to_MSE\", END)\n",
    "\n",
    "# Compile the workflow graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Optionally visualize the graph (requires additional dependencies)\n",
    "try:\n",
    "    from IPython.display import display, Markdown, Image\n",
    "    # Retrieve the graph and set its configuration\n",
    "    graph = app.get_graph()\n",
    "    graph.mermaid_config = {\"graph_direction\": \"TD\"}\n",
    "\n",
    "    # Generate the PNG image bytes from the graph\n",
    "    png_bytes = graph.draw_mermaid_png()\n",
    "\n",
    "    # Save the image to disk as 'graph.png'\n",
    "    with open(\"graph.png\", \"wb\") as f:\n",
    "        f.write(png_bytes)\n",
    "    print(\"The graph has been saved as 'graph.png'.\")\n",
    "    \n",
    "    display(Markdown(\"### LangGraph Visualization ###\"))\n",
    "    display(Image(graph.draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Graph rendering failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f643811-682a-4136-aa1a-e638d0aa2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Generating Model for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0854 seconds\n",
      "Skipping routing; moving directly to cache_context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitto\\anaconda3\\lib\\site-packages\\codecarbon\\output_methods\\file.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.1743 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"stim_system_payload\">\\n          <entry name=\"stim_01\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"ccdpp\">\\n      <nChannels name=\"ccdpp_cntrl_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"16\" rendezVous=\"true\">\\n        <message name=\"ccdpp_cntrl_payload\">\\n          <entry name=\"img_01\" type=\"sc_uint\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"cntrl\">\\n      <nChannels name=\"cntrl_codec_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"16\" rendezVous=\"true\">\\n        <message name=\"cntrl_codec_payload\">\\n          <entry name=\"img_01_08\" type=\"sc_uint\"/>\\n        </message>\\n      </nChannels>\\n      <nChannels name=\"codec_cntrl_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"16\" rendezVous=\"true\">\\n        <message name=\"codec_cntrl_payload\">\\n          <entry name=\"img_01_ack\" type=\"sc_uint\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"codec\"/>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n    <ports name=\"internal_display_port\">\\n      <pChannels name=\"internal_process_channel\" pFrom=\"//@nodes.2/@ports.1\" pTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\"/>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 644, 'prompt_tokens': 5691, 'total_tokens': 6335, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-c216e847-97db-4932-a5d4-8983bb9411d8-0' usage_metadata={'input_tokens': 5691, 'output_tokens': 644, 'total_tokens': 6335, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "[Profiling] wrapper took 11.5372 seconds\n",
      "file_base: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@58a8a484 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@338f299 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.44%2000%2520-%2520DigitalCam%2520Nominal-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 9.1626 seconds\n",
      "file_base: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation successful: No errors found.\n",
      "Model is valid.\n",
      "[Profiling] wrapper took 5.1246 seconds\n",
      "Model generated correctly!!!\n",
      "Profiling data for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.1679 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.1920 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"stim_system_message\">\\n          <entry name=\"raw_image_data\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <ports name=\"digitalcam_in\">\\n      <pChannels name=\"stim_ccdpp_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@processes.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"raw_to_preprocess\">\\n          <entry name=\"pre_processed_data\" type=\"sc_lv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec0\">\\n        <entry name=\"data_chunk0\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec1\">\\n        <entry name=\"data_chunk1\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec2\">\\n        <entry name=\"data_chunk2\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec3\">\\n        <entry name=\"data_chunk3\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.5\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec4\">\\n        <entry name=\"data_chunk4\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.6\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec5\">\\n        <entry name=\"data_chunk5\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.7\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec6\">\\n        <entry name=\"data_chunk6\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.8\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec7\">\\n        <entry name=\"data_chunk7\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"merged_image_message\">\\n        <entry name=\"merged_data\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"display_data_message\">\\n          <entry name=\"final_image\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1244, 'prompt_tokens': 5444, 'total_tokens': 6688, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-458215d3-b800-48b3-93f5-703989426ec6-0' usage_metadata={'input_tokens': 5444, 'output_tokens': 1244, 'total_tokens': 6688, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 19.2126 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@6ac8e83e (eClass: org.eclipse.emf.ecore.impl.EClassImpl@182338fa (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 70, 133)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 13.4838 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@49e14ff7 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@ee1062c (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 15.1570 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@12c799d1 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@2d015868 (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, -1, -1)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 14.7935 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_system_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"stim_system_message\">\\n          <entry name=\"raw_image_data\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"DigitalCam\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <ports name=\"digitalcam_in\">\\n      <pChannels name=\"stim_ccdpp_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@processes.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"raw_to_preprocess\">\\n          <entry name=\"pre_processed_data\" type=\"sc_lv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n    <processes name=\"ccdpp\"/>\\n    <processes name=\"codec0\"/>\\n    <processes name=\"codec1\"/>\\n    <processes name=\"codec2\"/>\\n    <processes name=\"codec3\"/>\\n    <processes name=\"codec4\"/>\\n    <processes name=\"codec5\"/>\\n    <processes name=\"codec6\"/>\\n    <processes name=\"codec7\"/>\\n    <nChannels name=\"ccdpp_codec0_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec0\">\\n        <entry name=\"data_chunk0\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec1_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec1\">\\n        <entry name=\"data_chunk1\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec2_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec2\">\\n        <entry name=\"data_chunk2\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec3_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec3\">\\n        <entry name=\"data_chunk3\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec4_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.5\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec4\">\\n        <entry name=\"data_chunk4\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec5_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.6\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec5\">\\n        <entry name=\"data_chunk5\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec6_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.7\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec6\">\\n        <entry name=\"data_chunk6\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"ccdpp_codec7_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.8\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"preprocess_to_codec7\">\\n        <entry name=\"data_chunk7\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"codec_merge_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n      <message name=\"merged_image_message\">\\n        <entry name=\"merged_data\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"display_data_message\">\\n          <entry name=\"final_image\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1244, 'prompt_tokens': 5444, 'total_tokens': 6688, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-458215d3-b800-48b3-93f5-703989426ec6-0' usage_metadata={'input_tokens': 5444, 'output_tokens': 1244, 'total_tokens': 6688, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0500 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@19ca558 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@b89ea20 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 70, 133)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 20.7328 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@2b87b5f9 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@3fe67326 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 70, 133)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 14.9742 seconds\n",
      "file_base: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@4e6d602d (eClass: org.eclipse.emf.ecore.impl.EClassImpl@2bfcc41 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2016.59%2000%2520-%2520DigitalCam%2520Parallel-representations.aird.hepsy, 70, 101)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.0829 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.9611 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9785 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rt_out_port\">\\n      <pChannels name=\"stim_rt_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"stim_rt_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RTApp\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"acquisition\">\\n      <processExtension xsi:nil=\"true\"/>\\n    </processes>\\n    <processes name=\"filtering\" processExtension=\"//@nodes.1/@processes.0\">\\n      <nChannels name=\"stim_acquisition_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@processes.0\">\\n        <message name=\"acquisition_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"decision\" processExtension=\"//@nodes.1/@processes.1\">\\n      <nChannels name=\"acq_filter_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"filtering_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.1/@processes.2\">\\n      <nChannels name=\"filter_decision_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"decision_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <nChannels name=\"decision_control_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\">\\n      <message name=\"control_payload\"/>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"control_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 654, 'prompt_tokens': 5509, 'total_tokens': 6163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7bd1325-0cf1-4418-869a-d019c74e0ef6-0' usage_metadata={'input_tokens': 5509, 'output_tokens': 654, 'total_tokens': 6163, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "[Profiling] wrapper took 17.3463 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@4ef610bf (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4e5f20f2 (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 15, 76)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 9.1804 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@4d38ce3e (eClass: org.eclipse.emf.ecore.impl.EClassImpl@5890de1a (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 16, 140)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 10.6797 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@6ee107 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@49444498 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 18, 140)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 10.4232 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rt_out_port\">\\n      <pChannels name=\"stim_rt_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"stim_rt_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RTApp\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"acquisition\">\\n      <processExtension xsi:nil=\"true\"/>\\n    </processes>\\n    <processes name=\"filtering\" processExtension=\"//@nodes.1/@processes.0\">\\n      <nChannels name=\"stim_acquisition_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@processes.0\">\\n        <message name=\"acquisition_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"decision\" processExtension=\"//@nodes.1/@processes.1\">\\n      <nChannels name=\"acq_filter_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"filtering_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.1/@processes.2\">\\n      <nChannels name=\"filter_decision_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"decision_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <nChannels name=\"decision_control_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\">\\n      <message name=\"control_payload\"/>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"control_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 654, 'prompt_tokens': 5509, 'total_tokens': 6163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7bd1325-0cf1-4418-869a-d019c74e0ef6-0' usage_metadata={'input_tokens': 5509, 'output_tokens': 654, 'total_tokens': 6163, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0942 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@7458fc71 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4f4072d8 (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 15, 76)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 10.0800 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@7aa4073c (eClass: org.eclipse.emf.ecore.impl.EClassImpl@164ed12c (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 15, 76)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 8.8726 seconds\n",
      "file_base: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@7f7ce89 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@35afc43f (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-13%2017.34%2001%2520-%2520FIRFIRGCD-representations.aird.hepsy, 16, 140)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 4.9866 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.9174 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9889 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rt_out_port\">\\n      <pChannels name=\"stim_rt_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"stim_rt_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RTApp\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"acquisition\">\\n      <processExtension xsi:nil=\"true\"/>\\n    </processes>\\n    <processes name=\"filtering\" processExtension=\"//@nodes.1/@processes.0\">\\n      <nChannels name=\"stim_acquisition_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@processes.0\">\\n        <message name=\"acquisition_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"decision\" processExtension=\"//@nodes.1/@processes.1\">\\n      <nChannels name=\"acq_filter_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"filtering_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.1/@processes.2\">\\n      <nChannels name=\"filter_decision_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"decision_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <nChannels name=\"decision_control_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\">\\n      <message name=\"control_payload\"/>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"control_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 654, 'prompt_tokens': 5509, 'total_tokens': 6163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7bd1325-0cf1-4418-869a-d019c74e0ef6-0' usage_metadata={'input_tokens': 5509, 'output_tokens': 654, 'total_tokens': 6163, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0138 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@54c70593 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@2cfebd38 (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 15, 76)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 9.7085 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@67e063e7 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4fb1ebc8 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 14, 140)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 10.0040 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@216f6487 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@7744eb9 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 37, 138)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 9.7935 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rt_out_port\">\\n      <pChannels name=\"stim_rt_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"stim_rt_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RTApp\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"acquisition\">\\n      <processExtension xsi:nil=\"true\"/>\\n    </processes>\\n    <processes name=\"filtering\" processExtension=\"//@nodes.1/@processes.0\">\\n      <nChannels name=\"stim_acquisition_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@processes.0\">\\n        <message name=\"acquisition_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"decision\" processExtension=\"//@nodes.1/@processes.1\">\\n      <nChannels name=\"acq_filter_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"filtering_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.1/@processes.2\">\\n      <nChannels name=\"filter_decision_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"decision_payload\"/>\\n      </nChannels>\\n    </processes>\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.0\"/>\\n    <nChannels name=\"decision_control_channel\" queueSize=\"8\" rendezVous=\"true\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\">\\n      <message name=\"control_payload\"/>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.0\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"control_payload\"/>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 654, 'prompt_tokens': 5509, 'total_tokens': 6163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7bd1325-0cf1-4418-869a-d019c74e0ef6-0' usage_metadata={'input_tokens': 5509, 'output_tokens': 654, 'total_tokens': 6163, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0289 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@6cfe0462 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@5b9ae2bc (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 15, 76)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 8.8252 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@33d598ec (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4c81a170 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 14, 140)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 10.0150 seconds\n",
      "file_base: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.40 02%20-%20RT%20App-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@5fd7aba (eClass: org.eclipse.emf.ecore.impl.EClassImpl@204e0bdd (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.40%2002%2520-%2520RT%2520App-representations.aird.hepsy, 15, 140)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.0050 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 14.40 02%20-%20RT%20App-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.9517 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.0377 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_rtPaper_out_port\">\\n      <pChannels name=\"stim_rtPaper_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"stim_rtPaper_payload\">\\n          <entry name=\"inputData\" type=\"sc_logic\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RT_App_Paper\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.3\"/>\\n    <ports name=\"capture_port\" portExtension=\"//@nodes.1/@processes.0\"/>\\n    <ports name=\"output_port\"/>\\n    <processes name=\"capture\" priority=\"1\" criticality=\"3\" processExtension=\"//@nodes.1/@ports.0\">\\n      <nChannels name=\"stim_capture_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"capture_payload\">\\n          <entry name=\"rawData\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"preprocess\" priority=\"1\" criticality=\"3\">\\n      <nChannels name=\"capture_preprocess_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"preprocess_payload\">\\n          <entry name=\"conditionedData\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"analyze\" priority=\"1\" criticality=\"3\">\\n      <nChannels name=\"preprocess_analyze_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"analyze_payload\">\\n          <entry name=\"features\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"control\" priority=\"1\" criticality=\"3\">\\n      <nChannels name=\"analyze_control_channel\" nFrom=\"//@nodes.1/@processes.3\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"control_payload\">\\n          <entry name=\"commands\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_rtPaper_channel\" pFrom=\"//@nodes.2/@ports.0\" pTo=\"//@nodes.2/@ports.1\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"disp_rtPaper_payload\">\\n          <entry name=\"displayData\" type=\"sc_logic\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 772, 'prompt_tokens': 5402, 'total_tokens': 6174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-14ca9c30-1a2e-4edd-81d0-809560e3f5b3-0' usage_metadata={'input_tokens': 5402, 'output_tokens': 772, 'total_tokens': 6174, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "[Profiling] wrapper took 15.0317 seconds\n",
      "file_base: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2014.50%2003%2520-%2520RT%2520App%2520Paper-representations.aird.hepsy, 47, 132)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 11.3103 seconds\n",
      "file_base: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation successful: No errors found.\n",
      "Model is valid.\n",
      "[Profiling] wrapper took 5.0016 seconds\n",
      "Model generated correctly!!!\n",
      "Profiling data for 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 14.50 03%20-%20RT%20App%20Paper-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0362 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.0927 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rtPaper2_out_port\">\\n      <pChannels name=\"stim_rtPaper2_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"stim_message\">\\n          <entry name=\"data\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RT_App_Paper_2\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.1\"/>\\n    <processes name=\"capture\">\\n      <processExtension name=\"stim_capture_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"capture_message\">\\n          <entry name=\"captureData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"filter\">\\n      <processExtension name=\"capture_filter_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"filter_message\">\\n          <entry name=\"filteredData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"preprocess\">\\n      <processExtension name=\"filter_preprocess_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"preprocess_message\">\\n          <entry name=\"preprocessedData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"analyze\">\\n      <processExtension name=\"preprocess_analyze_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"analyze_message\">\\n          <entry name=\"analyzedData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.0/@ports.0\">\\n      <processExtension name=\"analyze_control_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"control_message\">\\n          <entry name=\"controlData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_rtPaper2_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"5\" rendezVous=\"true\">\\n        <message name=\"display_message\">\\n          <entry name=\"displayData\" type=\"sc_logic\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 671, 'prompt_tokens': 5461, 'total_tokens': 6132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-7e20f7c3-d9b6-4fc9-bb17-27925db7bfe6-0' usage_metadata={'input_tokens': 5461, 'output_tokens': 671, 'total_tokens': 6132, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "[Profiling] wrapper took 13.1264 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'direction' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 15, 82)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 9.9233 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'message' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 16, 41)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 9.4057 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 11, 80)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 9.5198 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_rtPaper2_out_port\">\\n      <pChannels name=\"stim_rtPaper2_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"stim_message\">\\n          <entry name=\"data\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RT_App_Paper_2\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@ports.1\"/>\\n    <processes name=\"capture\">\\n      <processExtension name=\"stim_capture_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"capture_message\">\\n          <entry name=\"captureData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"filter\">\\n      <processExtension name=\"capture_filter_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"filter_message\">\\n          <entry name=\"filteredData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"preprocess\">\\n      <processExtension name=\"filter_preprocess_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"preprocess_message\">\\n          <entry name=\"preprocessedData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"analyze\">\\n      <processExtension name=\"preprocess_analyze_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"analyze_message\">\\n          <entry name=\"analyzedData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"control\" processExtension=\"//@nodes.0/@ports.0\">\\n      <processExtension name=\"analyze_control_channel_2\" direction=\"Unidirectional\">\\n        <message name=\"control_message\">\\n          <entry name=\"controlData\" type=\"sc_logic\"/>\\n        </message>\\n      </processExtension>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_rtPaper2_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"5\" rendezVous=\"true\">\\n        <message name=\"display_message\">\\n          <entry name=\"displayData\" type=\"sc_logic\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 671, 'prompt_tokens': 5461, 'total_tokens': 6132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-7e20f7c3-d9b6-4fc9-bb17-27925db7bfe6-0' usage_metadata={'input_tokens': 5461, 'output_tokens': 671, 'total_tokens': 6132, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "[Profiling] wrapper took 4.9200 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'direction' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 15, 82)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 5.0074 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'message' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 16, 41)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 4.9401 seconds\n",
      "file_base: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.04%2004%2520-%2520RT%2520App%2520Paper%25202-representations.aird.hepsy, 11, 80)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 4.9292 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 15.04 04%20-%20RT%20App%20Paper%202-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.8954 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9307 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"HepsyExample\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.2\"/>\\n    <processes name=\"dataAcquisition\" processExtension=\"//@nodes.1/@ports.0\">\\n      <nChannels name=\"acq_proc_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"acq_proc_message\">\\n          <entry name=\"initialData\" type=\"sc_int\"/>\\n          <entry name=\"conditionedData\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"dataProcessing\">\\n      <nChannels name=\"proc_ctrl_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"proc_ctrl_message\">\\n          <entry name=\"processedData\" type=\"sc_bigint\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"dataControl\">\\n      <nChannels name=\"main_disp_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"control_display_message\">\\n          <entry name=\"controlData\" type=\"sc_fixed\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 532, 'prompt_tokens': 5412, 'total_tokens': 5944, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-af5fd583-2440-46b1-be55-917acebc4df5-0' usage_metadata={'input_tokens': 5412, 'output_tokens': 532, 'total_tokens': 5944, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "[Profiling] wrapper took 10.6025 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@3ec71440 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@6fd68f8c (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 16.7962 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@1c054782 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@47635951 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 9.0678 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@processes.2'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, 9, 84)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 8.3280 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"8\" rendezVous=\"true\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"HepsyExample\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.2\"/>\\n    <processes name=\"dataAcquisition\" processExtension=\"//@nodes.1/@ports.0\">\\n      <nChannels name=\"acq_proc_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"acq_proc_message\">\\n          <entry name=\"initialData\" type=\"sc_int\"/>\\n          <entry name=\"conditionedData\" type=\"sc_logic\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"dataProcessing\">\\n      <nChannels name=\"proc_ctrl_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"proc_ctrl_message\">\\n          <entry name=\"processedData\" type=\"sc_bigint\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"dataControl\">\\n      <nChannels name=\"main_disp_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.2/@ports.0\" queueSize=\"8\" rendezVous=\"true\">\\n        <message name=\"control_display_message\">\\n          <entry name=\"controlData\" type=\"sc_fixed\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 532, 'prompt_tokens': 5412, 'total_tokens': 5944, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-af5fd583-2440-46b1-be55-917acebc4df5-0' usage_metadata={'input_tokens': 5412, 'output_tokens': 532, 'total_tokens': 5944, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.1369 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@1ff7f8cc (eClass: org.eclipse.emf.ecore.impl.EClassImpl@1b58c152 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 10.5566 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@7a2b9501 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@6a43ab4c (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 8.6812 seconds\n",
      "file_base: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@2d64a1d1 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@7cfb643e (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.40%2005%2520-%2520Hepsy%2520Example-representations.aird.hepsy, -1, -1)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 4.9595 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 15.40 05%20-%20Hepsy%20Example-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.9326 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9138 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_preproc_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"raw_image_data\">\\n          <entry name=\"imageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"sobel\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.3\"/>\\n    <processes name=\"preproc\">\\n      <pChannels name=\"preproc_sobelH_channel\" pFrom=\"//@nodes.1/@processes.0\" pTo=\"//@nodes.1/@processes.1\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"preproc_data\">\\n          <entry name=\"processedImageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n      <pChannels name=\"preproc_sobelV_channel\" pFrom=\"//@nodes.1/@processes.0\" pTo=\"//@nodes.1/@processes.2\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"preproc_data\">\\n          <entry name=\"processedImageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n     </processes>\\n    <processes name=\"sobel_h\">\\n      <pChannels name=\"sobel_merge_channel\" pFrom=\"//@nodes.1/@processes.1\" pTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"sobel_output_h\">\\n          <entry name=\"gradientDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n    <processes name=\"sobel_v\">\\n      <pChannels name=\"sobel_merge_channel\" pFrom=\"//@nodes.1/@processes.2\" pTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"sobel_output_v\">\\n          <entry name=\"gradientDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n    <processes name=\"edge_merge\">\\n      <pChannels name=\"sobel_display_channel\" pFrom=\"//@nodes.1/@processes.3\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"5\" rendezVous=\"true\">\\n        <message name=\"final_edge_data\">\\n          <entry name=\"edgeDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 724, 'prompt_tokens': 5434, 'total_tokens': 6158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-d39c5539-4810-4bfb-ac55-607c6d0ede89-0' usage_metadata={'input_tokens': 5434, 'output_tokens': 724, 'total_tokens': 6158, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 13.1276 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 15, 143)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 11.0526 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 24, 159)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 13.0084 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 47, 137)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 10.6815 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_preproc_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"raw_image_data\">\\n          <entry name=\"imageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"sobel\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.3\"/>\\n    <processes name=\"preproc\">\\n      <pChannels name=\"preproc_sobelH_channel\" pFrom=\"//@nodes.1/@processes.0\" pTo=\"//@nodes.1/@processes.1\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"preproc_data\">\\n          <entry name=\"processedImageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n      <pChannels name=\"preproc_sobelV_channel\" pFrom=\"//@nodes.1/@processes.0\" pTo=\"//@nodes.1/@processes.2\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"preproc_data\">\\n          <entry name=\"processedImageType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n     </processes>\\n    <processes name=\"sobel_h\">\\n      <pChannels name=\"sobel_merge_channel\" pFrom=\"//@nodes.1/@processes.1\" pTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"sobel_output_h\">\\n          <entry name=\"gradientDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n    <processes name=\"sobel_v\">\\n      <pChannels name=\"sobel_merge_channel\" pFrom=\"//@nodes.1/@processes.2\" pTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"false\">\\n        <message name=\"sobel_output_v\">\\n          <entry name=\"gradientDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n    <processes name=\"edge_merge\">\\n      <pChannels name=\"sobel_display_channel\" pFrom=\"//@nodes.1/@processes.3\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"5\" rendezVous=\"true\">\\n        <message name=\"final_edge_data\">\\n          <entry name=\"edgeDataType\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 724, 'prompt_tokens': 5434, 'total_tokens': 6158, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-d39c5539-4810-4bfb-ac55-607c6d0ede89-0' usage_metadata={'input_tokens': 5434, 'output_tokens': 724, 'total_tokens': 6158, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0118 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 15, 143)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 5.0335 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 24, 159)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.51 06%20-%20Sobel-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 5.0193 seconds\n",
      "file_base: 2024-02-14 15.51 06%20-%20Sobel-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.51 06%20-%20Sobel-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'pChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.51%2006%2520-%2520Sobel-representations.aird.hepsy, 47, 137)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.0411 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 15.51 06%20-%20Sobel-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0351 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9790 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_preproc_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"roberts\">\\n    <ports name=\"system_display_out_port\"/>\\n    <processes name=\"preproc\" processExtension=\"//@nodes.1/@ports.0\"/>\\n    <nChannels name=\"preproc_cross1_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"preproc_cross1_payload\">\\n        <entry name=\"image_data\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"preproc_cross2_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"preproc_cross2_payload\">\\n        <entry name=\"image_data\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <processes name=\"roberts_cross1\"/>\\n    <processes name=\"roberts_cross2\"/>\\n    <nChannels name=\"cross_merge_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"cross1_merge_payload\">\\n        <entry name=\"gradient1_data\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"cross_merge_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"cross2_merge_payload\">\\n        <entry name=\"gradient2_data\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <processes name=\"roberts_merge\" processExtension=\"//@nodes.1/@ports.1\"/>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"roberts_display_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 635, 'prompt_tokens': 5459, 'total_tokens': 6094, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-4b310ee2-197f-41bd-ae8c-783bd7f2c41c-0' usage_metadata={'input_tokens': 5459, 'output_tokens': 635, 'total_tokens': 6094, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "[Profiling] wrapper took 12.7818 seconds\n",
      "file_base: 2024-02-14 15.52 07%20-%20Roberts-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.52 07%20-%20Roberts-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.52%2007%2520-%2520Roberts-representations.aird.hepsy, 33, 77)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.52 07%20-%20Roberts-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 10.0995 seconds\n",
      "file_base: 2024-02-14 15.52 07%20-%20Roberts-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.52 07%20-%20Roberts-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2015.52%2007%2520-%2520Roberts-representations.aird.hepsy, 33, 77)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 15.52 07%20-%20Roberts-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 20.5212 seconds\n",
      "file_base: 2024-02-14 15.52 07%20-%20Roberts-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 15.52 07%20-%20Roberts-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation successful: No errors found.\n",
      "Model is valid.\n",
      "[Profiling] wrapper took 4.9510 seconds\n",
      "Model generated correctly!!!\n",
      "Profiling data for 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 15.52 07%20-%20Roberts-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0139 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9671 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_preproc_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"raw_audio_data\">\\n          <entry name=\"audio_sample\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RastaPlp\">\\n    <ports name=\"system_display_out_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"processed_data\">\\n          <entry name=\"cepstral_coefficients\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n    <processes name=\"preproc\">\\n      <processExtension name=\"preproc_rasta_channel\">\\n        <nChannels name=\"preproc_rasta_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"conditioned_audio_data\">\\n            <entry name=\"conditioned_sample\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"rasta\">\\n      <processExtension name=\"rasta_plp_channel\">\\n        <nChannels name=\"rasta_plp_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"rasta_output_data\">\\n            <entry name=\"rasta_feature\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"plp\">\\n      <processExtension name=\"plp_postproc_channel\">\\n        <nChannels name=\"plp_postproc_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"plp_output_data\">\\n            <entry name=\"plp_coefficients\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 665, 'prompt_tokens': 5419, 'total_tokens': 6084, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-ed93259a-5f9f-4420-817f-8b7114fb6b38-0' usage_metadata={'input_tokens': 5419, 'output_tokens': 665, 'total_tokens': 6084, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "[Profiling] wrapper took 13.9185 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'nChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 22, 143)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 12.4049 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 14, 128)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 9.7093 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 14, 128)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 9.8106 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_preproc_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"raw_audio_data\">\\n          <entry name=\"audio_sample\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"RastaPlp\">\\n    <ports name=\"system_display_out_port\">\\n      <pChannels name=\"display_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n        <message name=\"processed_data\">\\n          <entry name=\"cepstral_coefficients\" type=\"sc_int\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n    <processes name=\"preproc\">\\n      <processExtension name=\"preproc_rasta_channel\">\\n        <nChannels name=\"preproc_rasta_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"conditioned_audio_data\">\\n            <entry name=\"conditioned_sample\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"rasta\">\\n      <processExtension name=\"rasta_plp_channel\">\\n        <nChannels name=\"rasta_plp_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"rasta_output_data\">\\n            <entry name=\"rasta_feature\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n    <processes name=\"plp\">\\n      <processExtension name=\"plp_postproc_channel\">\\n        <nChannels name=\"plp_postproc_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@ports.1\" queueSize=\"8\" rendezVous=\"true\">\\n          <message name=\"plp_output_data\">\\n            <entry name=\"plp_coefficients\" type=\"sc_int\"/>\\n          </message>\\n        </nChannels>\\n      </processExtension>\\n    </processes>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 665, 'prompt_tokens': 5419, 'total_tokens': 6084, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-ed93259a-5f9f-4420-817f-8b7114fb6b38-0' usage_metadata={'input_tokens': 5419, 'output_tokens': 665, 'total_tokens': 6084, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "[Profiling] wrapper took 4.9980 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.FeatureNotFoundException: Feature 'nChannels' not found. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 22, 143)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 5.0220 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 14, 128)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 5.1128 seconds\n",
      "file_base: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2016.25%2008%2520-%2520RASTA-PLP-representations.aird.hepsy, 14, 128)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 4.9484 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 16.25 08%20-%20RASTA-PLP-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0656 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9337 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"10\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"RawImageData\">\\n          <entry name=\"image\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"SUSAN\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.3\"/>\\n    <processes name=\"preproc\" priority=\"1\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.0</processExtension>\\n      <nChannels name=\"preproc_susan_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"PreprocessedData\">\\n          <entry name=\"preprocImage\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"nucleus\" priority=\"2\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.1</processExtension>\\n      <nChannels name=\"nucleus_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"NucleusData\">\\n          <entry name=\"nucleusInfo\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"masking\" priority=\"3\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.2</processExtension>\\n      <nChannels name=\"mask_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\">\\n        <message name=\"MaskedData\">\\n          <entry name=\"maskInfo\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"edgeDetect\" priority=\"4\" criticality=\"1\" processExtension=\"//@nodes.1/@ports.3\"/>\\n    <nChannels name=\"edge_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@ports.4\">\\n      <message name=\"EdgeDetectedData\">\\n        <entry name=\"edges\" type=\"sc_bv\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.4\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"FinalImageData\">\\n          <entry name=\"displayImage\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 821, 'prompt_tokens': 5425, 'total_tokens': 6246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7c785ad-d505-4021-9625-49bba7d886c7-0' usage_metadata={'input_tokens': 5425, 'output_tokens': 821, 'total_tokens': 6246, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "[Profiling] wrapper took 14.2820 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.3'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 38, 103)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 14.8872 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.3'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 39, 103)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 12.4899 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.4'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 39, 103)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 12.6384 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"10\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"RawImageData\">\\n          <entry name=\"image\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"SUSAN\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.3\"/>\\n    <processes name=\"preproc\" priority=\"1\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.0</processExtension>\\n      <nChannels name=\"preproc_susan_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\">\\n        <message name=\"PreprocessedData\">\\n          <entry name=\"preprocImage\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"nucleus\" priority=\"2\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.1</processExtension>\\n      <nChannels name=\"nucleus_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\">\\n        <message name=\"NucleusData\">\\n          <entry name=\"nucleusInfo\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"masking\" priority=\"3\" criticality=\"1\">\\n      <processExtension>//@nodes.1/@ports.2</processExtension>\\n      <nChannels name=\"mask_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\">\\n        <message name=\"MaskedData\">\\n          <entry name=\"maskInfo\" type=\"sc_bv\"/>\\n        </message>\\n      </nChannels>\\n    </processes>\\n    <processes name=\"edgeDetect\" priority=\"4\" criticality=\"1\" processExtension=\"//@nodes.1/@ports.3\"/>\\n    <nChannels name=\"edge_channel\" queueSize=\"5\" rendezVous=\"true\" direction=\"Unidirectional\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@ports.4\">\\n      <message name=\"EdgeDetectedData\">\\n        <entry name=\"edges\" type=\"sc_bv\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"disp_channel\" pFrom=\"//@nodes.1/@ports.4\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"FinalImageData\">\\n          <entry name=\"displayImage\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 821, 'prompt_tokens': 5425, 'total_tokens': 6246, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-b7c785ad-d505-4021-9625-49bba7d886c7-0' usage_metadata={'input_tokens': 5425, 'output_tokens': 821, 'total_tokens': 6246, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0662 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.3'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 38, 103)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 4.9320 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.3'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 39, 103)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.00 09%20-%20Susan-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 5.0213 seconds\n",
      "file_base: 2024-02-14 17.00 09%20-%20Susan-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.00 09%20-%20Susan-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.4'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.00%2009%2520-%2520Susan-representations.aird.hepsy, 39, 103)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.1334 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 17.00 09%20-%20Susan-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.1380 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9324 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"10\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"rawImageData\">\\n          <entry name=\"imageData\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"JPEGEncoder\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.4\"/>\\n    <processes name=\"preproc\">\\n      <processExtension>//@nodes.1/@ports.0</processExtension>\\n    </processes>\\n    <processes name=\"DCT\"/>\\n    <processes name=\"quantization\"/>\\n    <processes name=\"zigzag\"/>\\n    <processes name=\"entropy\" processExtension=\"//@nodes.1/@ports.1\"/>\\n    <nChannels name=\"preproc_dct_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"preprocOutput\">\\n        <entry name=\"conditionedData\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"dct_quant_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"DCTCoefficients\">\\n        <entry name=\"frequencyData\" type=\"sc_fixed\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"quant_zigzag_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"quantizedData\">\\n        <entry name=\"compressedData\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"zigzag_entropy_channel\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"reorderedData\">\\n        <entry name=\"zigzagPatternData\" type=\"sc_bigint\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"jpeg_disp_channel\" queueSize=\"3\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"compressedBitstream\">\\n          <entry name=\"entropyEncodedData\" type=\"sc_lv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 750, 'prompt_tokens': 5479, 'total_tokens': 6229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-cb829616-0dcd-4b49-b907-9db63c62033b-0' usage_metadata={'input_tokens': 5479, 'output_tokens': 750, 'total_tokens': 6229, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "[Profiling] wrapper took 21.0050 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 20, 71)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 11.1046 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@processes.4'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 13, 84)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 22.9649 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 20, 71)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 5.0537 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" queueSize=\"10\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"rawImageData\">\\n          <entry name=\"imageData\" type=\"sc_bv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"JPEGEncoder\">\\n    <ports name=\"system_display_out_port\" portExtension=\"//@nodes.1/@processes.4\"/>\\n    <processes name=\"preproc\">\\n      <processExtension>//@nodes.1/@ports.0</processExtension>\\n    </processes>\\n    <processes name=\"DCT\"/>\\n    <processes name=\"quantization\"/>\\n    <processes name=\"zigzag\"/>\\n    <processes name=\"entropy\" processExtension=\"//@nodes.1/@ports.1\"/>\\n    <nChannels name=\"preproc_dct_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"preprocOutput\">\\n        <entry name=\"conditionedData\" type=\"sc_logic\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"dct_quant_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"DCTCoefficients\">\\n        <entry name=\"frequencyData\" type=\"sc_fixed\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"quant_zigzag_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"quantizedData\">\\n        <entry name=\"compressedData\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"zigzag_entropy_channel\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"5\" rendezVous=\"true\">\\n      <message name=\"reorderedData\">\\n        <entry name=\"zigzagPatternData\" type=\"sc_bigint\"/>\\n      </message>\\n    </nChannels>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"jpeg_disp_channel\" queueSize=\"3\" rendezVous=\"true\" direction=\"Unidirectional\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\">\\n        <message name=\"compressedBitstream\">\\n          <entry name=\"entropyEncodedData\" type=\"sc_lv\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 750, 'prompt_tokens': 5479, 'total_tokens': 6229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-cb829616-0dcd-4b49-b907-9db63c62033b-0' usage_metadata={'input_tokens': 5479, 'output_tokens': 750, 'total_tokens': 6229, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0957 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 20, 71)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 4.9451 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@processes.4'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 13, 84)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 5.0309 seconds\n",
      "file_base: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.1/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.46%2010%2520-%2520JPEG_encoder-representations.aird.hepsy, 20, 71)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.0539 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 17.46 10%20-%20JPEG_encoder-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.9842 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9934 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"jpeg_reduced_disp_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"JPEG Reduced\">\\n    <nChannels name=\"stim_acq_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"stim_msg\">\\n        <entry name=\"rawImageData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"preproc_dct_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"preproc_msg\">\\n        <entry name=\"preprocessedData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"dct_quant_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"dct_msg\">\\n        <entry name=\"dctCoefficients\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"quant_zigzag_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"quant_msg\">\\n        <entry name=\"quantizedCoefficients\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"zigzag_entropy_channel\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"zigzag_msg\">\\n        <entry name=\"zigzagData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <ports name=\"system_display_out_port\">\\n      <pChannels name=\"jpeg_reduced_disp_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n    <processes name=\"preproc\"/>\\n    <processes name=\"DCT\"/>\\n    <processes name=\"quantization\"/>\\n    <processes name=\"zigzag\"/>\\n    <processes name=\"entropy\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 725, 'prompt_tokens': 5467, 'total_tokens': 6192, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-00d7a881-42b7-459d-9b4e-a39db10e82f6-0' usage_metadata={'input_tokens': 5467, 'output_tokens': 725, 'total_tokens': 6192, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "[Profiling] wrapper took 12.7621 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: The feature 'processes' is not a valid feature\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 16.9303 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@17461e2b (eClass: org.eclipse.emf.ecore.impl.EClassImpl@1f1246da (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.58%2011%2520-%2520JPEG%2520Reduced-representations.aird.hepsy, 14, 127)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 14.9880 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.58%2011%2520-%2520JPEG%2520Reduced-representations.aird.hepsy, 10, 106)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 15.9242 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_system_out_port\">\\n      <pChannels name=\"stim_acq_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"jpeg_reduced_disp_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"JPEG Reduced\">\\n    <nChannels name=\"stim_acq_channel\" nFrom=\"//@nodes.0/@ports.0\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"stim_msg\">\\n        <entry name=\"rawImageData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"preproc_dct_channel\" nFrom=\"//@nodes.1/@processes.0\" nTo=\"//@nodes.1/@processes.1\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"preproc_msg\">\\n        <entry name=\"preprocessedData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"dct_quant_channel\" nFrom=\"//@nodes.1/@processes.1\" nTo=\"//@nodes.1/@processes.2\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"dct_msg\">\\n        <entry name=\"dctCoefficients\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"quant_zigzag_channel\" nFrom=\"//@nodes.1/@processes.2\" nTo=\"//@nodes.1/@processes.3\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"quant_msg\">\\n        <entry name=\"quantizedCoefficients\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"zigzag_entropy_channel\" nFrom=\"//@nodes.1/@processes.3\" nTo=\"//@nodes.1/@processes.4\" queueSize=\"10\" rendezVous=\"true\">\\n      <message name=\"zigzag_msg\">\\n        <entry name=\"zigzagData\" type=\"sc_int\"/>\\n      </message>\\n    </nChannels>\\n    <ports name=\"system_display_out_port\">\\n      <pChannels name=\"jpeg_reduced_disp_channel\" pFrom=\"//@nodes.1/@ports.1\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n    <processes name=\"preproc\"/>\\n    <processes name=\"DCT\"/>\\n    <processes name=\"quantization\"/>\\n    <processes name=\"zigzag\"/>\\n    <processes name=\"entropy\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 725, 'prompt_tokens': 5467, 'total_tokens': 6192, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-00d7a881-42b7-459d-9b4e-a39db10e82f6-0' usage_metadata={'input_tokens': 5467, 'output_tokens': 725, 'total_tokens': 6192, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0915 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: The feature 'processes' is not a valid feature\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 5.0821 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@206ec27c (eClass: org.eclipse.emf.ecore.impl.EClassImpl@43314351 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.58%2011%2520-%2520JPEG%2520Reduced-representations.aird.hepsy, 14, 127)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 10.9257 seconds\n",
      "file_base: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2017.58%2011%2520-%2520JPEG%2520Reduced-representations.aird.hepsy, 10, 106)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 4.9600 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 17.58 11%20-%20JPEG%20Reduced-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 5.0506 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 5.0652 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_fir1_out_port\">\\n      <pChannels name=\"stim_fir1_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"10\" rendezVous=\"false\">\\n        <message name=\"stim_fir1_payload\">\\n          <entry name=\"rawSignal\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"gcd_display_channel\" pFrom=\"//@nodes.2/@ports.4\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"gcd_display_payload\">\\n          <entry name=\"gcdResult\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"FIRFIRGCD_ext\">\\n    <ports name=\"fir_ext_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <nChannels name=\"fir1_fir2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"fir1_fir2_payload\">\\n        <entry name=\"filteredSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"fir2_firext_channel\" nFrom=\"//@nodes.2/@processes.1\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"fir2_firext_payload\">\\n        <entry name=\"refinedSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"firext_gcd_channel\" nFrom=\"//@nodes.2/@processes.2\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"firext_gcd_payload\">\\n        <entry name=\"enhancedSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"gcd_display_channel\" nFrom=\"//@nodes.2/@processes.3\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"gcd_display_payload\">\\n        <entry name=\"gcdResult\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <processes name=\"fir1\"/>\\n    <processes name=\"fir2\"/>\\n    <processes name=\"fir_ext\" processExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"gcd\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 715, 'prompt_tokens': 5424, 'total_tokens': 6139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-9cc47d65-41a5-4318-989d-a19b148f45f1-0' usage_metadata={'input_tokens': 5424, 'output_tokens': 715, 'total_tokens': 6139, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "[Profiling] wrapper took 14.6224 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@1e50dc85 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@4b4aae00 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 38, 135)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 11.1108 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@4c1747ec (eClass: org.eclipse.emf.ecore.impl.EClassImpl@68bcfe44 (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 38, 135)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_1.hepsy\n",
      "[Profiling] wrapper took 10.3807 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@ports.1'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 14, 95)\n",
      "[INFO] Model invalid. Will regenerate. Cycle: 1, Attempts: 2\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_1_2.hepsy\n",
      "[Profiling] wrapper took 13.1409 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"Stimulus\">\\n    <ports name=\"stim_fir1_out_port\">\\n      <pChannels name=\"stim_fir1_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.2/@ports.0\" queueSize=\"10\" rendezVous=\"false\">\\n        <message name=\"stim_fir1_payload\">\\n          <entry name=\"rawSignal\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"Display\">\\n    <ports name=\"system_display_in_port\">\\n      <pChannels name=\"gcd_display_channel\" pFrom=\"//@nodes.2/@ports.4\" pTo=\"//@nodes.1/@ports.0\">\\n        <message name=\"gcd_display_payload\">\\n          <entry name=\"gcdResult\" type=\"sc_uint\"/>\\n        </message>\\n      </pChannels>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"FIRFIRGCD_ext\">\\n    <ports name=\"fir_ext_port\" portExtension=\"//@nodes.2/@processes.3\"/>\\n    <nChannels name=\"fir1_fir2_channel\" nFrom=\"//@nodes.2/@processes.0\" nTo=\"//@nodes.2/@processes.1\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"fir1_fir2_payload\">\\n        <entry name=\"filteredSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"fir2_firext_channel\" nFrom=\"//@nodes.2/@processes.1\" nTo=\"//@nodes.2/@processes.2\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"fir2_firext_payload\">\\n        <entry name=\"refinedSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"firext_gcd_channel\" nFrom=\"//@nodes.2/@processes.2\" nTo=\"//@nodes.2/@processes.3\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"firext_gcd_payload\">\\n        <entry name=\"enhancedSignal\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <nChannels name=\"gcd_display_channel\" nFrom=\"//@nodes.2/@processes.3\" nTo=\"//@nodes.1/@ports.0\" queueSize=\"10\" rendezVous=\"false\">\\n      <message name=\"gcd_display_payload\">\\n        <entry name=\"gcdResult\" type=\"sc_uint\"/>\\n      </message>\\n    </nChannels>\\n    <processes name=\"fir1\"/>\\n    <processes name=\"fir2\"/>\\n    <processes name=\"fir_ext\" processExtension=\"//@nodes.2/@ports.0\"/>\\n    <processes name=\"gcd\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 715, 'prompt_tokens': 5424, 'total_tokens': 6139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-9cc47d65-41a5-4318-989d-a19b148f45f1-0' usage_metadata={'input_tokens': 5424, 'output_tokens': 715, 'total_tokens': 6139, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "[Profiling] wrapper took 5.0949 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_2_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@151411d6 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@6b78a5ec (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 38, 135)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_2_0.hepsy\n",
      "[Profiling] wrapper took 12.4518 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_2_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@3470d976 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@771bae9f (name: Port) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 23, 68)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_2_1.hepsy\n",
      "[Profiling] wrapper took 9.4514 seconds\n",
      "file_base: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird_2_2.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.UnresolvedReferenceException: Unresolved reference '//@nodes.2/@ports.2'. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.17%2012%2520-%2520FIRFIRGCD_ext-representations.aird.hepsy, 5, 97)\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "[Profiling] wrapper took 5.0405 seconds\n",
      "[ERROR] Model is still invalid after 2 generation-validation cycles. Stopping.\n",
      "Profiling data for 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 18.17 12%20-%20FIRFIRGCD_ext-representations.aird.hepsy: unknown\n",
      "Start Generating Model for 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "[Profiling] wrapper took 4.9662 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "[Profiling] wrapper took 4.9760 seconds\n",
      "Final Results:content='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<hml:BehaviorSpecification xmi:version=\"2.0\" xmlns:xmi=\"http://www.omg.org/XMI\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:hml=\"org.univaq.hepsy\">\\n  <nodes xsi:type=\"hml:Stimulus\" name=\"stimulus\">\\n    <ports name=\"stim_fir1_out_port\">\\n      <pChannels name=\"stim_fir1_channel\" pFrom=\"//@nodes.0/@ports.0\" pTo=\"//@nodes.1/@ports.0\"/>\\n    </ports>\\n  </nodes>\\n  <nodes xsi:type=\"hml:StructuredNode\" name=\"FIRFIRGCD_HPV\">\\n    <ports name=\"fir1_in\">\\n      <pChannels name=\"fir1_fir2_channel\" pFrom=\"//@nodes.1/@processes.0\" pTo=\"//@nodes.1/@processes.1\"/>\\n    </ports>\\n    <ports name=\"fir2_in\">\\n      <pChannels name=\"fir2_hpv_channel\" pFrom=\"//@nodes.1/@processes.1\" pTo=\"//@nodes.1/@processes.2\"/>\\n    </ports>\\n    <ports name=\"hpv_in\">\\n      <pChannels name=\"hpv_gcd_channel\" pFrom=\"//@nodes.1/@processes.2\" pTo=\"//@nodes.1/@processes.3\"/>\\n    </ports>\\n    <ports name=\"gcd_out\">\\n      <pChannels name=\"gcd_display_channel\" pFrom=\"//@nodes.1/@processes.3\" pTo=\"//@nodes.2/@ports.0\"/>\\n    </ports>\\n    <processes name=\"fir1\" processExtension=\"//@nodes.1/@ports.0\"/>\\n    <processes name=\"fir2\" processExtension=\"//@nodes.1/@ports.1\"/>\\n    <processes name=\"hpv\" processExtension=\"//@nodes.1/@ports.2\"/>\\n    <processes name=\"gcd\" processExtension=\"//@nodes.1/@ports.3\"/>\\n  </nodes>\\n  <nodes xsi:type=\"hml:Display\" name=\"display\">\\n    <ports name=\"system_display_in_port\"/>\\n  </nodes>\\n</hml:BehaviorSpecification>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 492, 'prompt_tokens': 5457, 'total_tokens': 5949, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'finish_reason': 'stop', 'logprobs': None} id='run-d860de4e-2574-4908-8bb6-8af9f85bfd01-0' usage_metadata={'input_tokens': 5457, 'output_tokens': 492, 'total_tokens': 5949, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "Model saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "[Profiling] wrapper took 16.4706 seconds\n",
      "file_base: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird_1_0.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation error: org.eclipse.emf.ecore.xmi.IllegalValueException: Value 'org.eclipse.emf.ecore.impl.DynamicEObjectImpl@10e7f581 (eClass: org.eclipse.emf.ecore.impl.EClassImpl@68caf821 (name: Process) (instanceClassName: null) (abstract: false, interface: false))' is not legal. (file:/C:/Users/vitto/Desktop/github/Re-MASTER-LLM-MODELS/02_SMG/D2_Synthetic_Model_Dataset_FS_MAS_RAG_API/D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/2024-02-14%2018.30%2013%2520-%2520FIRFIRGCD_HPV-representations.aird.hepsy, -1, -1)\n",
      "Model is invalid. Sending to LLM for correction.\n",
      "Processed: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "Corrected model saved to: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      "Metadata saved to: D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird_1_0.hepsy\n",
      "[Profiling] wrapper took 8.9232 seconds\n",
      "file_base: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird, file_ext: .hepsy\n",
      "file_name_metadata: 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird_1_1.hepsy\n",
      "[DEBUG] Validating with:\n",
      " - Model: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\02_SMG\\D2_Synthetic_Model_Dataset_FS_MAS_RAG_API\\D2-HEPSYCODE\\LLM-gpt-4o-2024-08-06-1.0\\2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\n",
      " - Metamodel: C:\\Users\\vitto\\Desktop\\github\\Re-MASTER-LLM-MODELS\\01_MSE\\HEPSYCODE\\workspace\\org.univaq.hepsy\\model\\hepsy.ecore\n",
      "[VALIDATION RESULT] Validation successful: No errors found.\n",
      "Model is valid.\n",
      "[Profiling] wrapper took 5.0377 seconds\n",
      "Model generated correctly!!!\n",
      "Profiling data for 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Model generation result for 2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy: unknown\n",
      "END model GENERATION PROCESS!!!\n",
      "Summary profiling data saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\profiling_summary.csv\n",
      "Global CodeCarbon summary saved to D2-HEPSYCODE/LLM-gpt-4o-2024-08-06-1.0/JSON\\codecarbon_summary.csv\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#       model GENERATION LOOP     #\n",
    "###################################\n",
    "\n",
    "# Global CodeCarbon tracker for the entire application\n",
    "global_cc_tracker = EmissionsTracker(\n",
    "    project_name=\"global_app\",\n",
    "    measure_power_secs=1,\n",
    "    output_dir=CODECARBON_FOLDER,\n",
    "    allow_multiple_runs=True\n",
    "    # api_call_interval=4,\n",
    "    # experiment_id=experiment_id,\n",
    "    # save_to_api=True\n",
    "    # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard\n",
    "    # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "    # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    ")\n",
    "global_cc_tracker.start()\n",
    "\n",
    "# Reset the overall summary for CodeCarbon per file\n",
    "cc_global_summary = []\n",
    "\n",
    "# List to collect summary records for each file (for final summary CSV)\n",
    "summary_records = []\n",
    "\n",
    "app_start_time = time.time()\n",
    "\n",
    "# For each file, add file name and the query to the state.\n",
    "# The cache_context node in the workflow will ensure the refined context is present.\n",
    "input_files = [file_name for file_name in os.listdir(base_model_path) if file_name.endswith(\".hepsy\")]\n",
    "\n",
    "for file_name in input_files:\n",
    "    # Record start time for this file\n",
    "    print(f\"Start Generating Model for {file_name}\")\n",
    "    file_start = time.time()\n",
    "    \n",
    "    # Record the starting index of the global profiling_records list\n",
    "    start_index = len(profiling_records)\n",
    "\n",
    "    # Start a file-level CodeCarbon tracker\n",
    "    file_cc_tracker = EmissionsTracker(\n",
    "        project_name=\"global_file_\" + file_name,\n",
    "        measure_power_secs=1,\n",
    "        output_dir=CODECARBON_FOLDER,\n",
    "        allow_multiple_runs=True,\n",
    "        api_call_interval=4\n",
    "        # experiment_id=experiment_id,\n",
    "        # save_to_api=True\n",
    "        # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard for each file\n",
    "        # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "        # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    "    )\n",
    "    file_cc_tracker.start()\n",
    "    \n",
    "    # Reset the per-node CodeCarbon metrics for this file\n",
    "    cc_metrics_for_file = []\n",
    "    \n",
    "    state = GraphState()\n",
    "    state[\"file_name\"] = file_name         # Provide file name for model generation\n",
    "    # state[\"question\"] = question           # The query generated from the metamodel\n",
    "    # Run the workflow using stream() and take the final output state\n",
    "    result_state = list(app.stream(state, config={\"recursion_limit\": 25}))[-1]\n",
    "    \n",
    "    # Record end time for this file and calculate overall time\n",
    "    file_end = time.time()\n",
    "    overall_time = file_end - file_start\n",
    "\n",
    "    # Stop the file-level CodeCarbon tracker and get global metrics for the file\n",
    "    file_emissions = file_cc_tracker.stop()\n",
    "    # Try to get detailed metrics if available\n",
    "    if hasattr(file_cc_tracker, \"_final_emissions_data\"):\n",
    "        file_metrics = file_cc_tracker._final_emissions_data\n",
    "    else:\n",
    "        file_metrics = {\"total_emissions\": file_emissions}\n",
    "\n",
    "    # Extract profiling records corresponding to this file\n",
    "    file_records = profiling_records[start_index:].copy()\n",
    "    # Append an additional record for the overall file execution time\n",
    "    file_records.append({\"node\": f\"FILE_{file_name}\", \"execution_time\": overall_time})\n",
    "    \n",
    "    # Save the profiling data for this file in a dedicated CSV file if it doesn't already exist\n",
    "    csv_file_path = os.path.join(PROFILING_FOLDER, f\"profiling_{file_name}.csv\")\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "            fieldnames = [\"node\", \"execution_time\"]\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for record in file_records:\n",
    "                writer.writerow(record)\n",
    "        print(f\"Profiling data for {file_name} saved to {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"Profiling file {csv_file_path} already exists. Skipping save.\")\n",
    "    \n",
    "    # Add a summary record for this file\n",
    "    summary_records.append({\"file_name\": file_name, \"execution_time\": overall_time})\n",
    "\n",
    "    ############ CODE CARBON ##############\n",
    "    # Save per-node CodeCarbon metrics along with file-level metrics into a dedicated CSV file,\n",
    "    # with file name starting with \"codecarbon_\"\n",
    "    cc_csv_file = os.path.join(CODECARBON_FOLDER, f\"codecarbon_{file_name}.csv\")\n",
    "    if not os.path.exists(cc_csv_file):\n",
    "        # Prepare a list of rows: one row per node metric, plus one row for overall file metrics.\n",
    "        # We merge the per-node metrics (from cc_metrics_for_file) into a list.\n",
    "        # Note: Each metric row is a dictionary. We also add a row for the file global metrics.\n",
    "        rows = []\n",
    "        for record in cc_metrics_for_file:\n",
    "            # record already contains \"node\" and various CodeCarbon metrics\n",
    "            rows.append(record)\n",
    "        # Append a row for overall file CodeCarbon metrics:\n",
    "        overall_record = {\"node\": f\"FILE_{file_name}\"}\n",
    "        overall_record.update(file_metrics)\n",
    "        rows.append(overall_record)\n",
    "        \n",
    "        # Determine all possible keys across all rows\n",
    "        all_keys = set()\n",
    "        for r in rows:\n",
    "            all_keys.update(r.keys())\n",
    "        all_keys = list(all_keys)\n",
    "        \n",
    "        with open(cc_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=all_keys)\n",
    "            writer.writeheader()\n",
    "            for r in rows:\n",
    "                writer.writerow(r)\n",
    "        print(f\"CodeCarbon metrics for {file_name} saved to {cc_csv_file}\")\n",
    "    else:\n",
    "        print(f\"CodeCarbon file {cc_csv_file} already exists. Skipping save.\")\n",
    "    \n",
    "    # Append summary record for this file (global CodeCarbon metrics)\n",
    "    cc_global_summary.append({\"file_name\": file_name, **file_metrics})\n",
    "\n",
    "    ############## RAG EVALUATION ################\n",
    "    \n",
    "    skip_router_value = result_state[\"model_to_MSE\"][\"skip_router\"]\n",
    "    # skip_router_value = result_state.get(\"skip_router\", False)\n",
    "    print(\"skip_router:\", skip_router_value)\n",
    "\n",
    "    evaluation_metrics = result_state[\"model_to_MSE\"].get(\"evaluation_metrics\")\n",
    "    # evaluation_metrics = result_state.get(\"evaluation_metrics\", {})\n",
    "    print(\"evaluation_metrics:\", evaluation_metrics)\n",
    "\n",
    "    bert_score_metrics = result_state[\"model_to_MSE\"].get(\"bert_score\")\n",
    "    # bert_score_metrics = result_state.get(\"bert_score\", {})\n",
    "    print(\"bert_score_metrics:\", bert_score_metrics)\n",
    "\n",
    "    web_bert_score_metrics = result_state[\"model_to_MSE\"].get(\"web_bert_score\")\n",
    "    # web_bert_score_metrics = result_state.get(\"web_bert_score\", {})\n",
    "    print(\"evaluation_metrics:\", web_bert_score_metrics)\n",
    "\n",
    "    if not skip_router_value:\n",
    "        # Save evaluation results to CSV for this file (if evaluation metrics exist)\n",
    "        evaluation_data = {\"file_name\": file_name}\n",
    "        \n",
    "        # Use get() with a default empty dict to ensure we update with available metrics\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"evaluation_metrics\", {}))\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"bert_score\", {}))\n",
    "        evaluation_data.update(result_state[\"model_to_MSE\"].get(\"web_bert_score\", {}))\n",
    "        \n",
    "        eval_csv_file = os.path.join(EVALUATION_FOLDER, f\"evaluation_{file_name}.csv\")\n",
    "        with open(eval_csv_file, \"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=evaluation_data.keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerow(evaluation_data)\n",
    "        print(f\"Evaluation results for {file_name} saved to {eval_csv_file}\")\n",
    "    \n",
    "    print(f\"Model generation result for {file_name}: {result_state.get('model_status', 'unknown')}\")\n",
    "\n",
    "# Record end time of the entire application and calculate total time\n",
    "app_end_time = time.time()\n",
    "total_app_time = app_end_time - app_start_time\n",
    "summary_records.append({\"file_name\": \"TOTAL_APP\", \"execution_time\": total_app_time})\n",
    "\n",
    "global_summary = global_cc_tracker.stop()\n",
    "if hasattr(global_cc_tracker, \"_final_emissions_data\"):\n",
    "    global_metrics = global_cc_tracker._final_emissions_data\n",
    "else:\n",
    "    global_metrics = {\"total_emissions\": global_summary}\n",
    "cc_global_summary.append({\"file_name\": \"TOTAL_APP\", **global_metrics})\n",
    "print(\"END model GENERATION PROCESS!!!\")\n",
    "\n",
    "# Save the final summary CSV with overall times per file if it doesn't already exist\n",
    "final_csv_file = os.path.join(PROFILING_FOLDER, \"profiling_summary.csv\")\n",
    "if not os.path.exists(final_csv_file):\n",
    "    with open(final_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        fieldnames = [\"file_name\", \"execution_time\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in summary_records:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Summary profiling data saved to {final_csv_file}\")\n",
    "else:\n",
    "    print(f\"Summary profiling CSV {final_csv_file} already exists. Skipping save.\")\n",
    "\n",
    "# Save the global CodeCarbon summary into a CSV file\n",
    "global_csv_file = os.path.join(CODECARBON_FOLDER, \"codecarbon_summary.csv\")\n",
    "if not os.path.exists(global_csv_file):\n",
    "    fieldnames = set()\n",
    "    for record in cc_global_summary:\n",
    "        fieldnames.update(record.keys())\n",
    "    fieldnames = list(fieldnames)\n",
    "    with open(global_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in cc_global_summary:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Global CodeCarbon summary saved to {global_csv_file}\")\n",
    "else:\n",
    "    print(f\"Global CodeCarbon summary file {global_csv_file} already exists. Skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e31d-edf7-4c87-b023-2585e61c183b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
