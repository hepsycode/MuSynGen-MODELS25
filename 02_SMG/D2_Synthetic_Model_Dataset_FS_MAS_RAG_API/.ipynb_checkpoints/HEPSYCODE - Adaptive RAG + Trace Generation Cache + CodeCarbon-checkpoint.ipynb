{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5841d78-9230-49e8-b9fc-ec27e72288af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting ':' delimiter: line 109 column 27 (char 2589)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 151\u001b[0m\n\u001b[0;32m    149\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m LLM  \u001b[38;5;66;03m# Use LLM name as the model name\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m LLM_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOllama\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     llm_params \u001b[38;5;241m=\u001b[39m \u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    152\u001b[0m     llm_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m temperature\n\u001b[0;32m    153\u001b[0m     llm_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_url\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m base_url\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "###################################\n",
    "#           LIBRARIES             #\n",
    "###################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import uuid\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET  # For parsing the Ecore file\n",
    "\n",
    "from codecarbon import EmissionsTracker  # Import CodeCarbon\n",
    "\n",
    "# LangChain and related libraries\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.llms import Ollama\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.tools.base import Tool\n",
    "from typing import Callable\n",
    "\n",
    "###################################\n",
    "#         CONFIGURATION           #\n",
    "###################################\n",
    "\n",
    "# Configuration file paths (llm_config_anthropic, llm_config_google, llm_config_groq, llm_config_mistral, llm_config_ollama, llm_config_openai)\n",
    "CONFIG_FILE = \"config/llm_config_ollama.json\"\n",
    "MODELS_FILE = \"config/llm_models.json\"\n",
    "CONFIG_RAG_FILE = \"config/llm_config_openai_rag.json\"\n",
    "CONFIG_RAG_TAVILY_FILE = \"config/secrets-master-llm.json\"\n",
    "VECTOR_DB_TYPE = \"FAISS\" # FAISS, CHROMA\n",
    "CSV_FILE_PATH = \"config/BASE_URL.csv\"\n",
    "LLM_TYPE = 'Ollama' # 'Others', 'Ollama'\n",
    "RAG_CHAT = 'LangChain' # 'OpenAI', 'LangChain' (Same Model as the Trace Generation)\n",
    "\n",
    "# Global variable to force context regeneration regardless of REFINED_CONTEXT_PATH presence\n",
    "FORCE_CONTEXT_GEN = False  # Set to True to force context generation even if REFINED_CONTEXT_PATH exists\n",
    "\n",
    "# File path to save the refined context (persistent cache)\n",
    "REFINED_CONTEXT_PATH = \"config/HEPSYCODE_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/CAEX_refined_context.json\"\n",
    "# REFINED_CONTEXT_PATH = \"config/BPMN_Designer_refined_context.json\"\n",
    "\n",
    "# Define an array with all the topics/tools for retrieval\n",
    "vectorstore_topics = [\n",
    "    \"CAEX/AutomationML\",\n",
    "    \"BPMN Designer\",\n",
    "    # \"HEPSYCODE\",\n",
    "    # \"Additional Tool 1\",\n",
    "    # \"Additional Tool 2\",\n",
    "    # Add more topics as needed\n",
    "]\n",
    "\n",
    "# Profiling Folder\n",
    "PROFILING_FOLDER = f\"D2-HEPSYCODE/XES-MORGAN-LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(PROFILING_FOLDER):\n",
    "    os.makedirs(PROFILING_FOLDER)\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"profiling.csv\")\n",
    "\n",
    "# CodeCarbon Folder\n",
    "CODECARBON_FOLDER  = f\"D2-HEPSYCODE/XES-MORGAN-LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(CODECARBON_FOLDER ):\n",
    "    os.makedirs(CODECARBON_FOLDER )\n",
    "PROFILING_CSV_FILE = os.path.join(PROFILING_FOLDER, \"codecarbon_summary.csv\")\n",
    "\n",
    "# Folder to save evaluation results per file\n",
    "EVALUATION_FOLDER = f\"D2-HEPSYCODE/XES-MORGAN-LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "if not os.path.exists(EVALUATION_FOLDER):\n",
    "    os.makedirs(EVALUATION_FOLDER)\n",
    "\n",
    "###################################\n",
    "#         UTILITY FUNCTIONS       #\n",
    "###################################\n",
    "\n",
    "# Function to load configuration from a JSON file\n",
    "def load_config(config_file):\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file {config_file} not found.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Function to load file content\n",
    "def load_file_content(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to save content to a file\n",
    "def save_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Function to save metadata to a file (in JSON format)\n",
    "def save_metadata(file_path, metadata):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "###################################\n",
    "#         LLM CONFIGURATION       #\n",
    "###################################\n",
    "\n",
    "# Load LLM configuration\n",
    "config = load_config(CONFIG_FILE)\n",
    "models_config = load_config(MODELS_FILE)\n",
    "\n",
    "# Extract LLM parameters from configuration\n",
    "LLM = config.get(\"llm\")\n",
    "if not LLM:\n",
    "    raise ValueError(\"LLM name must be specified in the configuration file.\")\n",
    "\n",
    "PRICE_PER_INPUT_TOKEN = config.get(\"price_per_input_token\")\n",
    "PRICE_PER_OUTPUT_TOKEN = config.get(\"price_per_output_token\")\n",
    "temperature = config.get(\"temperature\")\n",
    "max_retries = config.get(\"max_retries\")\n",
    "api_key = config.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "base_url = config.get(\"base_url\")\n",
    "\n",
    "# Determine LLM type and initialize LLM instance\n",
    "llm_config = models_config.get(LLM, None)\n",
    "if llm_config and LLM_TYPE != 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"max_retries\"] = max_retries\n",
    "    llm_params[\"api_key\"] = api_key\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    # Dynamically initialize the LLM class\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM  # Use LLM name as the model name\n",
    "elif LLM_TYPE == 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM\n",
    "else:\n",
    "    raise ValueError(f\"Model configuration for '{LLM}' not found in {MODELS_FILE}.\")\n",
    "\n",
    "###################################\n",
    "#     FEW-SHOT CONFIGURATION      #\n",
    "###################################\n",
    "\n",
    "# Define file paths for static resources and output directories\n",
    "example_model_path = \"../../01-02-03_MSE/HEPSYCODE/HEPSYCODE-Models/D1/HEPSY/2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.hepsy\"\n",
    "example_xes_trace_path = \"../../04_Trace_Parser/D1_HEPSYCODE/XES-MORGAN/2024-02-14 18.30 13%20-%20FIRFIRGCD_HPV-representations.aird.xes\"\n",
    "\n",
    "# Path to the metamodel (Ecore file)\n",
    "metamodel_path = \"../../01-02-03_MSE/HEPSYCODE/org.univaq.hepsy/model/hepsy.ecore\"\n",
    "\n",
    "# Path to the model folders (Hepsy file)\n",
    "base_model_path = \"../../01-02-03_MSE/HEPSYCODE/HEPSYCODE-Models/D1/HEPSY/\"\n",
    "\n",
    "# Path to the Output Directory\n",
    "base_output_dir = f\"D2-HEPSYCODE/XES-MORGAN-LLM-{model_name.lower()}-{temperature}\"\n",
    "base_output_json_dir = f\"D2-HEPSYCODE/XES-MORGAN-LLM-{model_name.lower()}-{temperature}/JSON\"\n",
    "\n",
    "###################################\n",
    "#         GLOBAL PROFILING        #\n",
    "###################################\n",
    "\n",
    "# Global list to collect CodeCarbon metrics for each node call (per file)\n",
    "cc_metrics_for_file = []  # This will be reset for each file\n",
    "\n",
    "# Global list for overall CodeCarbon summary per file\n",
    "cc_summary_records = []\n",
    "\n",
    "# Global list to save profiling data\n",
    "profiling_records = []\n",
    "\n",
    "###################################\n",
    "#      TIMING NODE PROFILING      #\n",
    "###################################\n",
    "\n",
    "def timing_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator to profile a node function.\n",
    "    Appends a record with the node name and its execution time (in seconds) to profiling_records.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        profiling_records.append({\"node\": func.__name__, \"execution_time\": elapsed})\n",
    "        print(f\"[Profiling] {func.__name__} took {elapsed:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#    CODECARBON NODE DECORATOR    #\n",
    "###################################\n",
    "\n",
    "# os.environ[\"CODECARBON_API_KEY\"] = \"CODECARBON_API_KEY\"\n",
    "# os.environ[\"CODECARBON_API_URL\"] = \"https://api.codecarbon.io\"\n",
    "# os.environ[\"CODECARBON_EXPERIMENT_ID\"] = \"UUID\"\n",
    "\n",
    "def cc_profile_node(func):\n",
    "    \"\"\"\n",
    "    Decorator that wraps a node function with CodeCarbon tracking.\n",
    "    It starts a tracker before calling the node and stops it right after.\n",
    "    The resulting metrics are appended to the global cc_metrics_for_file list.\n",
    "    \"\"\"\n",
    "    def wrapper(state, *args, **kwargs):\n",
    "        # Create a CodeCarbon tracker for this node\n",
    "        tracker = EmissionsTracker(\n",
    "            project_name=f\"cc_{func.__name__}\",\n",
    "            measure_power_secs=1,\n",
    "            output_dir=CODECARBON_FOLDER,  # You can adjust output_dir as needed (\".\")\n",
    "            allow_multiple_runs=True\n",
    "            # api_call_interval=4,\n",
    "            # experiment_id=experiment_id,\n",
    "            # save_to_api=True\n",
    "        )\n",
    "        tracker.start()\n",
    "        result = func(state, *args, **kwargs)\n",
    "        emissions = tracker.stop()\n",
    "        # Try to extract detailed metrics if available (from the internal attribute)\n",
    "        if hasattr(tracker, \"_final_emissions_data\"):\n",
    "            metrics = tracker._final_emissions_data\n",
    "        else:\n",
    "            metrics = {\"total_emissions\": emissions}\n",
    "        # Append the node's CodeCarbon metrics to the global list\n",
    "        cc_metrics_for_file.append({\n",
    "            \"node\": func.__name__,\n",
    "            **metrics  # Flatten the metrics dictionary\n",
    "        })\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "###################################\n",
    "#       PROFILE & CC DECORATORS   #\n",
    "###################################\n",
    "\n",
    "# (Assuming you already have a @profile_node decorator for timing, as in your code.)\n",
    "# Here we combine both decorators so that each node is profiled for time and CodeCarbon metrics.\n",
    "# The order of decorators means that cc_profile_node will wrap the function first.\n",
    "def profile_node(func):\n",
    "    return timing_profile_node(cc_profile_node(func))\n",
    "\n",
    "###################################\n",
    "#       LOAD URLS FROM CSV        #\n",
    "###################################\n",
    "\n",
    "def load_urls_from_csv(csv_file_path):\n",
    "    urls = []\n",
    "    try:\n",
    "        with open(csv_file_path, 'r', newline='', encoding='utf-8') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if row:  # Ensure the row is not empty\n",
    "                    urls.append(row[0].strip())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file '{csv_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "    return urls\n",
    "\n",
    "# Load base URLs for the vector database from CSV\n",
    "BASE_URLS = load_urls_from_csv(CSV_FILE_PATH)\n",
    "if not BASE_URLS:\n",
    "    raise ValueError(\"No URLs were loaded from the CSV file.\")\n",
    "else:\n",
    "    print(f\"Loaded {len(BASE_URLS)} URLs from '{CSV_FILE_PATH}'.\")\n",
    "\n",
    "###################################\n",
    "# RAG AGENT SETUP (Chroma/FAISS)  #\n",
    "###################################\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "if VECTOR_DB_TYPE == \"CHROMA\":\n",
    "    # Directory for persisting the Chroma vector store.\n",
    "    CHROMA_PERSIST_DIR = \"chroma_db\"\n",
    "    \n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    # Initialize OpenAIEmbeddings\n",
    "    embd = OpenAIEmbeddings(openai_api_key=api_key_rag)\n",
    "    \n",
    "    # Build or load the Chroma vector store\n",
    "    if os.path.exists(CHROMA_PERSIST_DIR) and os.listdir(CHROMA_PERSIST_DIR):\n",
    "        print(\"Loading existing Chroma vector store from disk...\")\n",
    "        vectorstore = Chroma(\n",
    "            persist_directory=CHROMA_PERSIST_DIR,\n",
    "            embedding_function=embd,\n",
    "            collection_name=\"rag-chroma\"\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "    else:\n",
    "        print(\"Creating new Chroma vector store...\")\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=500, chunk_overlap=0\n",
    "        )\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=doc_splits,\n",
    "            collection_name=\"rag-chroma\",\n",
    "            embedding=embd,\n",
    "            persist_directory=CHROMA_PERSIST_DIR\n",
    "        )\n",
    "        retriever = vectorstore.as_retriever()\n",
    "elif VECTOR_DB_TYPE == \"FAISS\":\n",
    "\n",
    "    # Load RAG configuration\n",
    "    config_rag = load_config(CONFIG_RAG_FILE)\n",
    "    api_key_rag = config_rag.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "    \n",
    "    EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"  \n",
    "    HUGGINGFACE_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    \n",
    "    faiss_folder = \"faiss\"\n",
    "    if not os.path.exists(faiss_folder):\n",
    "        os.makedirs(faiss_folder)\n",
    "        print(f\"Folder '{faiss_folder}' created.\")\n",
    "    else:\n",
    "        print(f\"The folder '{faiss_folder}' already exists.\")\n",
    "    \n",
    "    DATABASE_PATH = os.path.join(faiss_folder, \"faiss_index.index\")\n",
    "    METADATA_PATH = os.path.join(faiss_folder, \"metadata.json\")\n",
    "    \n",
    "    embedding = HuggingFaceEmbeddings(model_name=HUGGINGFACE_MODEL_NAME)\n",
    "    \n",
    "    if os.path.exists(DATABASE_PATH):\n",
    "        print(\"Loading existing FAISS index from disk...\")\n",
    "        vectorstore = FAISS.load_local(DATABASE_PATH, embedding, allow_dangerous_deserialization=True)\n",
    "        if os.path.exists(METADATA_PATH):\n",
    "            with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                metadata = json.load(f)\n",
    "    else:\n",
    "        print(\"Creating new FAISS vector store...\")\n",
    "        from langchain_community.document_loaders import WebBaseLoader\n",
    "        docs = [WebBaseLoader(url).load() for url in BASE_URLS]\n",
    "        docs_list = [item for sublist in docs for item in sublist]\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "        doc_splits = text_splitter.split_documents(docs_list)\n",
    "        vectorstore = FAISS.from_documents(doc_splits, embedding)\n",
    "        vectorstore.save_local(DATABASE_PATH)\n",
    "        metadata = [doc.metadata for doc in doc_splits]\n",
    "        with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, indent=4)\n",
    "        \n",
    "    retriever = vectorstore.as_retriever()    \n",
    "\n",
    "###################################\n",
    "#         ROUTER NODE             #\n",
    "###################################\n",
    "\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model for routing the user query\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Route the user query to either a vectorstore or web search.\"\n",
    "    )\n",
    "\n",
    "# Initialize RAG LLM and router\n",
    "LLM_RAG = config_rag.get(\"llm\")\n",
    "LLM_RAG_TEMP = config_rag.get(\"temperature\")\n",
    "\n",
    "# llm_rag = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "llm_rag = llm_LangChain\n",
    "structured_llm_router = llm_rag.with_structured_output(RouteQuery)\n",
    "\n",
    "# Join the topics into a single string, separated by commas\n",
    "topics_str = \", \".join(vectorstore_topics)\n",
    "\n",
    "# Create router prompt\n",
    "router_system_prompt = (\n",
    "    \"You are an expert at routing user queries to either a vectorstore or web search. \"\n",
    "    \"The vectorstore contains documents related to {topics_str}.\"\n",
    "    \"Use the vectorstore for questions on these topics; otherwise, use web search.\"\n",
    ")\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", router_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "###################################\n",
    "#      RETRIEVAL GRADER NODE      #\n",
    "###################################\n",
    "\n",
    "# Data model for grading document relevance\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates whether the document is relevant ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm_rag.with_structured_output(GradeDocuments)\n",
    "\n",
    "grader_system_prompt = (\n",
    "    \"You are a grader assessing the relevance of a retrieved document to a user query. \"\n",
    "    \"If the document contains keywords or semantic content related to the user query, grade it as relevant. \"\n",
    "    \"Output a binary score 'yes' or 'no'.\"\n",
    ")\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grader_system_prompt),\n",
    "        (\"human\", \"Retrieved document:\\n\\n{document}\\n\\nUser query:\\n{question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "###################################\n",
    "#        GENERATION CHAIN         #\n",
    "###################################\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# Set up in-memory cache to avoid repeating expensive LLM calls.\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "context_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an expert in information retrieval and content synthesis. Your task is to refine and enhance context \"\n",
    "                \"from multiple sources by generating a cohesive, well-structured, and detailed context that combines information \"\n",
    "                \"from various retrieved documents.\\n\\n\"\n",
    "                \"Responsibilities:\\n\"\n",
    "                \"1. Synthesize information from multiple sources into a unified explanation.\\n\"\n",
    "                \"2. Expand on the query with relevant details from the retrieved content.\\n\"\n",
    "                \"3. Format the refined context with clear structure and professional language.\\n\"\n",
    "                \"4. Incorporate metadata for traceability.\\n\"\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            (\n",
    "                \"Question: {question}\\n\\n\"\n",
    "                \"The following are the retrieved documents and metadata:\\n\\n{context}\\n\\n\"\n",
    "                \"Using this information, generate a refined and comprehensive context.\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if RAG_CHAT == 'OpenAI':\n",
    "    llm_for_context = ChatOpenAI(model=LLM_RAG, temperature=LLM_RAG_TEMP)\n",
    "elif RAG_CHAT == 'LangChain':\n",
    "    llm_for_context = llm_LangChain\n",
    "    \n",
    "rag_chain = context_prompt_template | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#     HALLUCINATION GRADER        #\n",
    "###################################\n",
    "\n",
    "# Data model for grading hallucination\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer is grounded in facts ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_hallucination = llm_rag.with_structured_output(GradeHallucinations)\n",
    "\n",
    "hallucination_system_prompt = (\n",
    "    \"You are a grader assessing whether the LLM generation is grounded in the retrieved facts. \"\n",
    "    \"Output a binary score 'yes' if the answer is supported by the facts, otherwise 'no'.\"\n",
    ")\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", hallucination_system_prompt),\n",
    "        (\"human\", \"Facts:\\n\\n{documents}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "hallucination_grader = hallucination_prompt | structured_llm_hallucination\n",
    "\n",
    "###################################\n",
    "#         ANSWER GRADER           #\n",
    "###################################\n",
    "\n",
    "# Data model for grading answer relevance\n",
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicates if the answer addresses the question ('yes' or 'no').\"\n",
    "    )\n",
    "\n",
    "structured_llm_answer = llm_rag.with_structured_output(GradeAnswer)\n",
    "\n",
    "answer_system_prompt = (\n",
    "    \"You are a grader assessing whether an LLM-generated answer addresses the user query. \"\n",
    "    \"Output a binary score 'yes' if it does, otherwise 'no'.\"\n",
    ")\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_system_prompt),\n",
    "        (\"human\", \"User Query:\\n{question}\\n\\nLLM Generation:\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "answer_grader = answer_prompt | structured_llm_answer\n",
    "\n",
    "###################################\n",
    "#       QUESTION REWRITER         #\n",
    "###################################\n",
    "\n",
    "rewrite_system_prompt = (\n",
    "    \"You are a question rewriter. Given an input question, produce an improved version optimized for vectorstore retrieval. \"\n",
    "    \"Focus on the underlying semantic intent.\"\n",
    ")\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rewrite_system_prompt),\n",
    "        (\"human\", \"Original question:\\n{question}\\n\\nRewrite the question:\"),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = rewrite_prompt | llm_for_context | StrOutputParser()\n",
    "\n",
    "###################################\n",
    "#           WEB SEARCH            #\n",
    "###################################\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "config_tavily = load_config(CONFIG_RAG_TAVILY_FILE)\n",
    "os.environ[\"TAVILY_API_KEY\"] = config_tavily.get(\"tavily_api_key\")\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "###################################\n",
    "#       GRAPH STATE DEFINITION    #\n",
    "###################################\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict, total=False): \n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[Any]\n",
    "    file_name: str      # For trace generation node\n",
    "    context_llm: str    # The refined context\n",
    "    trace_status: str\n",
    "    xes_trace: str\n",
    "    metadata: Dict[str, Any]\n",
    "    branch: str         # Indicates the branch: \"retrieve\" or \"web_search\"\n",
    "    evaluation_metrics: Dict[str, float]\n",
    "    bert_score: Dict[str, float]\n",
    "    web_bert_score: Dict[str, float]\n",
    "    skip_router: bool   # If True, skip the routing and proceed directly to cache_context_node\n",
    "\n",
    "###################################\n",
    "# FUNCTION: GENERATE QUERY FROM METAMODEL #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_from_metamodel(metamodel_path):\n",
    "    \"\"\"\n",
    "    Reads the metamodel (Ecore file), extracts basic information (package name, nsURI, and classifiers),\n",
    "    and constructs a query based solely on the extracted information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(metamodel_path)\n",
    "        root = tree.getroot()\n",
    "        # The root is typically an EPackage with attributes\n",
    "        package_name = root.attrib.get(\"name\", \"UnknownPackage\")\n",
    "        ns_uri = root.attrib.get(\"nsURI\", \"Unknown nsURI\")\n",
    "        # Extract all classifiers (e.g., EClass, EEnum, etc.)\n",
    "        classifiers = []\n",
    "        for classifier in root.findall(\"{http://www.eclipse.org/emf/2002/Ecore}eClassifiers\"):\n",
    "            classifiers.append(classifier.attrib.get(\"name\", \"UnnamedClassifier\"))\n",
    "        classifiers_str = \", \".join(classifiers) if classifiers else \"None\"\n",
    "        # Build a generic query based solely on the metamodel information\n",
    "        query = (\n",
    "            f\"Metamodel Analysis Query:\\n\"\n",
    "            f\"Package Name: {package_name}\\n\"\n",
    "            f\"Namespace URI: {ns_uri}\\n\"\n",
    "            f\"Classifiers: {classifiers_str}\\n\"\n",
    "            \"Based solely on the metamodel information provided above, generate a minimal context for a tool based on this metamodel. \"\n",
    "            \"The context should only include the tool's name, which must be directly derived from the package name.\"\n",
    "        )\n",
    "        return query\n",
    "    except Exception as e:\n",
    "        print(\"Error generating query from metamodel:\", e)\n",
    "        return \"Metamodel analysis query could not be generated.\"\n",
    "\n",
    "# The query for generating the context is now created based on the metamodel\n",
    "# question = generate_query_from_metamodel(metamodel_path)\n",
    "# print(question)\n",
    "\n",
    "###################################\n",
    "#        EVALUATION NODES         #\n",
    "###################################\n",
    "\n",
    "# (1) LLM-based Evaluation for RAG output (vectorstore branch)\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RAGEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the facts.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the question.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the context used.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved context.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of the context.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the context.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_rag_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the RAG output (vectorstore branch) based on metrics such as:\n",
    "    Faithfulness, Answer Relevance, Context Precision, Context Accuracy,\n",
    "    Context Recall, and Context F1.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE RAG OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of RAG outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, and Context F1. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer:\\n{generation}\\n\\nContext:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(RAGEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during evaluation of RAG output:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (2) BERTScore Evaluation for RAG output (vectorstore branch)\n",
    "@profile_node\n",
    "def evaluate_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty. Skipping BERTScore evaluation.\")\n",
    "        state[\"bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    bert_precision = P[0].item()\n",
    "    bert_recall = R[0].item()\n",
    "    bert_f1 = F1[0].item()\n",
    "    state[\"bert_score\"] = {\"precision\": bert_precision, \"recall\": bert_recall, \"f1\": bert_f1}\n",
    "    print(\"BERTScore metrics:\", state[\"bert_score\"])\n",
    "    return state\n",
    "\n",
    "# (3) LLM-based Evaluation for Web Search output\n",
    "# Here, we introduce an additional metric \"accuracy\" along with the previous ones.\n",
    "class WebEvaluationMetrics(BaseModel):\n",
    "    faithfulness: float = Field(..., description=\"Score (0-1) indicating how faithful the answer is to the web sources.\")\n",
    "    answer_relevance: float = Field(..., description=\"Score (0-1) indicating how well the answer addresses the query.\")\n",
    "    context_precision: float = Field(..., description=\"Score (0-1) representing the precision of the web search results.\")\n",
    "    context_accuracy: float = Field(..., description=\"Score (0-1) representing the accuracy of the retrieved web content.\")\n",
    "    context_recall: float = Field(..., description=\"Score (0-1) representing the recall of relevant web information.\")\n",
    "    context_f1: float = Field(..., description=\"Score (0-1) representing the F1 measure of the web search results.\")\n",
    "    accuracy: float = Field(..., description=\"Score (0-1) indicating the overall accuracy of the generated context based on web sources.\")\n",
    "\n",
    "@profile_node\n",
    "def evaluate_web_search_output(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Node to evaluate the output of the web search branch.\n",
    "    It uses the same metrics as the RAG evaluation plus an extra metric 'accuracy'.\n",
    "    The reference is the concatenated web search source content.\n",
    "    \"\"\"\n",
    "    print(\"--- EVALUATE WEB SEARCH OUTPUT METRICS ---\")\n",
    "    question_val = state.get(\"question\", \"\")\n",
    "    generation = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    context_text = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    eval_input = {\n",
    "         \"question\": question_val,\n",
    "         \"generation\": generation,\n",
    "         \"context\": context_text\n",
    "    }\n",
    "    \n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", (\n",
    "            \"You are an expert evaluator of web search outputs. Evaluate the output based on the following metrics: \"\n",
    "            \"Faithfulness, Answer Relevance, Context Precision, Context Accuracy, Context Recall, Context F1, and Accuracy. \"\n",
    "            \"For each metric, assign a score between 0 and 1. \"\n",
    "            \"Respond in JSON format with keys: faithfulness, answer_relevance, context_precision, \"\n",
    "            \"context_accuracy, context_recall, context_f1, accuracy.\"\n",
    "        )),\n",
    "        (\"user\", \"Question:\\n{question}\\n\\nGenerated Answer/Context:\\n{generation}\\n\\nWeb Search Sources:\\n{context}\\n\\nProvide the evaluation:\")\n",
    "    ])\n",
    "    \n",
    "    structured_eval = llm_rag.with_structured_output(WebEvaluationMetrics)\n",
    "    eval_chain = eval_prompt | structured_eval\n",
    "    try:\n",
    "         eval_metrics = eval_chain.invoke(eval_input)\n",
    "         state[\"evaluation_metrics\"] = eval_metrics.dict()\n",
    "         print(\"Web search evaluation metrics:\", state[\"evaluation_metrics\"])\n",
    "    except Exception as e:\n",
    "         print(\"Error during web search evaluation:\", e)\n",
    "         state[\"evaluation_metrics\"] = {}\n",
    "    return state\n",
    "\n",
    "# (4) BERTScore Evaluation for Web Search output\n",
    "@profile_node\n",
    "def evaluate_web_bert_score(state: GraphState) -> GraphState:\n",
    "    print(\"--- EVALUATE WEB BERT SCORE ---\")\n",
    "    try:\n",
    "        from bert_score import score\n",
    "    except ImportError:\n",
    "        print(\"Please install bert-score using 'pip install bert-score'\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "\n",
    "    candidate = state.get(\"generation\", \"\")\n",
    "    documents = state.get(\"documents\", [])\n",
    "    reference = \"\\n\".join([doc.page_content for doc in documents]) if documents else \"\"\n",
    "    \n",
    "    if not candidate or not reference:\n",
    "        print(\"Candidate or reference text is empty for web search. Skipping BERTScore evaluation.\")\n",
    "        state[\"web_bert_score\"] = None\n",
    "        return state\n",
    "    \n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=True)\n",
    "    web_bert_precision = P[0].item()\n",
    "    web_bert_recall = R[0].item()\n",
    "    web_bert_f1 = F1[0].item()\n",
    "    state[\"web_bert_score\"] = {\"precision\": web_bert_precision, \"recall\": web_bert_recall, \"f1\": web_bert_f1}\n",
    "    print(\"Web BERTScore metrics:\", state[\"web_bert_score\"])\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#        DECIDE TO GENERATE       #\n",
    "###################################\n",
    "\n",
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    print(\"--- DECIDE TO GENERATE ---\")\n",
    "    filtered_documents = state.get(\"documents\", [])\n",
    "    if not filtered_documents:\n",
    "        if branch == \"retrieve\":\n",
    "            print(\"--- No relevant documents found in vectorstore; transforming query to improve retrieval ---\")\n",
    "            return \"transform_query\"\n",
    "        else:  # branch == \"web_search\"\n",
    "            print(\"--- No documents found via web search; proceeding with generation using empty context ---\")\n",
    "            return \"generate\"\n",
    "    else:\n",
    "        print(\"--- Relevant documents found, generating answer ---\")\n",
    "        return \"generate\"\n",
    "\n",
    "###################################\n",
    "#        CACHE NODE (LangGraph)   #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def cache_context_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that checks if a refined context is already available.\n",
    "    If present in the state or in the file cache, it uses that value.\n",
    "    Otherwise, it generates the refined context using the rag_chain,\n",
    "    caches it (in state and on disk), and returns the state.\n",
    "    \"\"\"\n",
    "    if \"context_llm\" in state and state[\"context_llm\"]:\n",
    "        print(\"Using refined context already present in state.\")\n",
    "        return state\n",
    "\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        try:\n",
    "            with open(REFINED_CONTEXT_PATH, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            state[\"context_llm\"] = data.get(\"context\", \"\")\n",
    "            print(\"Loaded refined context from file cache (LangGraph node).\")\n",
    "            return state\n",
    "        except Exception as e:\n",
    "            print(\"Error loading refined context from file in cache node:\", e)\n",
    "\n",
    "    print(\"Generating refined context in LangGraph cache node...\")\n",
    "    refined_context = rag_chain.invoke({\"question\": state[\"question\"], \"context\": \"\"})\n",
    "    state[\"context_llm\"] = refined_context\n",
    "    try:\n",
    "        with open(REFINED_CONTEXT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"context\": refined_context}, f, indent=4, ensure_ascii=False)\n",
    "        print(\"Refined context cached to file from LangGraph node.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error caching refined context to file in cache node:\", e)\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#          GRAPH NODES            #\n",
    "###################################\n",
    "\n",
    "@profile_node\n",
    "def generate_query_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node that generates the query from the metamodel.\n",
    "    If the refined context file exists, skip query generation and mark state to bypass router.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(REFINED_CONTEXT_PATH) and not FORCE_CONTEXT_GEN:\n",
    "        print(\"Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\")\n",
    "        state[\"skip_router\"] = True  # Flag to skip routing\n",
    "    else:\n",
    "        state[\"skip_router\"] = False  # Flag to skip routing\n",
    "        state[\"question\"] = generate_query_from_metamodel(metamodel_path)\n",
    "        print(\"Generated query from metamodel:\", state[\"question\"])\n",
    "    return state\n",
    "\n",
    "# Node: Retrieve documents using the vectorstore\n",
    "@profile_node\n",
    "def retrieve(state: GraphState) -> GraphState:\n",
    "    print(\"--- RETRIEVE ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = retriever.invoke(question_val)\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "# Node: Perform web search (remains separate)\n",
    "@profile_node\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    print(\"--- WEB SEARCH ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    docs = web_search_tool.invoke({\"query\": question_val})\n",
    "\n",
    "    # Combine web search results into a single Document\n",
    "    \"\"\"\n",
    "    web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state\n",
    "    \"\"\"\n",
    "    # Check the type of docs and extract content accordingly.\n",
    "    if isinstance(docs, str):\n",
    "        # If docs is a string, use it directly.\n",
    "        web_results_content = docs\n",
    "    elif isinstance(docs, list):\n",
    "        # If docs is a list, check the type of its elements.\n",
    "        if docs and isinstance(docs[0], dict) and \"content\" in docs[0]:\n",
    "            web_results_content = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "        else:\n",
    "            # Assume it's a list of strings.\n",
    "            web_results_content = \"\\n\".join(docs)\n",
    "    else:\n",
    "        # Fallback: convert docs to string.\n",
    "        web_results_content = str(docs)\n",
    "    \n",
    "    from langchain.schema import Document\n",
    "    web_results_doc = Document(page_content=web_results_content)\n",
    "    state[\"documents\"] = [web_results_doc]\n",
    "    return state    \n",
    "\n",
    "# Merged Node: Generate answer using the RAG chain (used for both branches)\n",
    "def generate(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question_val})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Generate answer using web search results\n",
    "@profile_node\n",
    "def generate_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- GENERATE (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# Node: Grade documents for relevance\n",
    "@profile_node\n",
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    print(\"--- GRADE DOCUMENTS ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question_val, \"document\": d.page_content})\n",
    "        if score.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Document is relevant ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- Document is not relevant ---\")\n",
    "    state[\"documents\"] = filtered_docs\n",
    "    return state\n",
    "\n",
    "# Merged Node: Transform the query (for both branches)\n",
    "@profile_node\n",
    "def transform_query(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (RAG) ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question_val})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Node: Transform the query for web search\n",
    "@profile_node\n",
    "def transform_query_web(state: GraphState) -> GraphState:\n",
    "    print(\"--- TRANSFORM QUERY (Web) ---\")\n",
    "    question = state[\"question\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    print(better_question)\n",
    "    state[\"question\"] = better_question\n",
    "    return state\n",
    "\n",
    "# Conditional routing after transformation: based on branch in state\n",
    "\"\"\"\n",
    "def route_after_transform(state: GraphState) -> str:\n",
    "    if state.get(\"branch\") == \"retrieve\":\n",
    "        return \"retrieve\"\n",
    "    elif state.get(\"branch\") == \"web_search\":\n",
    "        return \"web_search\"\n",
    "    return \"retrieve\"\n",
    "\"\"\"\n",
    "\n",
    "# Node: Grade the generation against the documents and question\n",
    "@profile_node\n",
    "def grade_generation_v_documents_and_question(state: GraphState) -> str:\n",
    "    print(\"--- GRADE GENERATION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # Evaluate if the generation is supported by the retrieved documents.\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    if score.binary_score.lower() == \"yes\":\n",
    "        print(\"--- Generation is grounded in documents ---\")\n",
    "        score_answer = answer_grader.invoke({\"question\": question_val, \"generation\": generation})\n",
    "        if score_answer.binary_score.lower() == \"yes\":\n",
    "            print(\"--- Generation addresses the question ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"--- Generation does not address the question ---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"--- Generation is not supported by documents, retrying ---\")\n",
    "        return \"not useful\"\n",
    "\n",
    "# Node: Trace Generation  generate XES trace and JSON metadata from a single file.\n",
    "@profile_node\n",
    "def trace_generation_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    LangGraph node for generating the trace and JSON metadata\n",
    "    from a single file using the refined context.\n",
    "    \n",
    "    Expected state:\n",
    "      - \"file_name\": the file to process.\n",
    "      - \"context_llm\": the refined context.\n",
    "    \"\"\"\n",
    "    file_name = state[\"file_name\"]\n",
    "    context_llm = state[\"context_llm\"]\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    \n",
    "    output_trace_path = os.path.join(base_output_dir, file_name.replace(\".hepsy\", \".xes\"))\n",
    "    metadata_path = os.path.join(base_output_json_dir, file_name.replace(\".hepsy\", \".json\"))\n",
    "    \n",
    "    # Skip processing if the output files already exist\n",
    "    if os.path.exists(output_trace_path) and os.path.exists(metadata_path):\n",
    "        print(f\"Skipping {file_name} as output files already exist.\")\n",
    "        state[\"trace_status\"] = \"skipped\"\n",
    "        return state\n",
    "\n",
    "    # Load the model file\n",
    "    input_file_path = os.path.join(base_model_path, file_name)\n",
    "    model_content = load_file_content(input_file_path)\n",
    "    \n",
    "    # Load static content files\n",
    "    metamodel_content = load_file_content(metamodel_path)\n",
    "    example_model_content = load_file_content(example_model_path)\n",
    "    example_trace_content = load_file_content(example_xes_trace_path)\n",
    "    \n",
    "    # Define system prompt for trace generation\n",
    "    system_prompt = (\n",
    "        \"**System Prompt:**\\n\\n\"\n",
    "        \"You are an expert in analyzing models. Assist the user by generating a trace based solely on the provided context and static resources.\\n\\n\"\n",
    "        \"Responsibilities:\\n\"\n",
    "        \"1. Analyze the provided metamodel and example model.\\n\"\n",
    "        \"2. Generate a trace based on the input model.\\n\"\n",
    "        \"3. Output only the trace events without additional commentary.\\n\"\n",
    "    )\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", (\n",
    "                f\"Context:\\n{context_llm}\\n\\n\"\n",
    "                \"Metamodel:\\n\\n{metamodel_content}\\n\\n\"\n",
    "                \"Example Model:\\n\\n{example_model_content}\\n\\n\"\n",
    "                \"Example Trace:\\n\\n{example_trace_content}\\n\\n\"\n",
    "                \"Generate a trace for the following model:\\n\\n{model_content}\\n\\n\"\n",
    "                \"Output should include events with their associated details. Do not add comments or extra quotation marks.\"\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Invoke the LLM chain for trace generation\n",
    "    start_time_llm = time.time()\n",
    "    response_chain = chat_prompt | llm_LangChain\n",
    "    result = response_chain.invoke({\n",
    "        \"context\": context_llm,\n",
    "        \"metamodel_content\": metamodel_content,\n",
    "        \"example_model_content\": example_model_content,\n",
    "        \"example_trace_content\": example_trace_content,\n",
    "        \"model_content\": model_content,\n",
    "    })\n",
    "    end_time_llm = time.time()\n",
    "    execution_time = end_time_llm - start_time_llm\n",
    "    \n",
    "    # Extract the trace from the result\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        trace_output = result.content.strip()\n",
    "    else:\n",
    "        trace_output = result.strip()\n",
    "    \n",
    "    # Build metadata for the response\n",
    "    if LLM_TYPE != 'Ollama':\n",
    "        metadata = {\n",
    "            \"response_length\": len(trace_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"usage\": result.usage_metadata,\n",
    "            \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN +\n",
    "                         result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    else:\n",
    "        metadata = {\n",
    "            \"response_length\": len(trace_output),\n",
    "            \"execution_time\": execution_time,\n",
    "            \"temperature\": temperature,\n",
    "            \"model_name\": model_name\n",
    "        }\n",
    "    \n",
    "    # Save the trace and metadata to output files\n",
    "    save_to_file(output_trace_path, trace_output)\n",
    "    save_metadata(metadata_path, metadata)\n",
    "    \n",
    "    print(f\"Processed: {file_name}\")\n",
    "    print(f\"Trace saved to: {output_trace_path}\")\n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    state[\"trace_status\"] = \"processed\"\n",
    "    state[\"xes_trace\"] = trace_output\n",
    "    state[\"metadata\"] = metadata\n",
    "    return state\n",
    "\n",
    "###################################\n",
    "#       GRAPH WORKFLOW SETUP      #\n",
    "###################################\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Initialize the state graph using our GraphState type\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "\n",
    "# Add the new node to the workflow\n",
    "workflow.add_node(\"generate_query\", generate_query_node)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)             # Merged generate node\n",
    "workflow.add_node(\"generate_web\", generate_web)\n",
    "workflow.add_node(\"transform_query\", transform_query) # Merged transform node\n",
    "workflow.add_node(\"transform_query_web\", transform_query_web)\n",
    "workflow.add_node(\"cache_context\", cache_context_node)  # Caching node\n",
    "workflow.add_node(\"trace_generation\", trace_generation_node)\n",
    "\n",
    "# Add evaluation nodes for vectorstore branch\n",
    "workflow.add_node(\"evaluate_rag_output\", evaluate_rag_output)\n",
    "workflow.add_node(\"evaluate_bert_score\", evaluate_bert_score)\n",
    "\n",
    "# Add evaluation nodes for web search branch\n",
    "workflow.add_node(\"evaluate_web_search_output\", evaluate_web_search_output)\n",
    "workflow.add_node(\"evaluate_web_bert_score\", evaluate_web_bert_score)\n",
    "\n",
    "# Starting node: route question decides between web_search and vectorstore (retrieve)\n",
    "def route_question(state: GraphState) -> str:\n",
    "    # If the flag is present, skip the routing and return a special key (\"skip\")\n",
    "    if state.get(\"skip_router\", False):\n",
    "        print(\"Skipping routing; moving directly to cache_context.\")\n",
    "        return \"skip\"\n",
    "        \n",
    "    print(\"--- ROUTE QUESTION ---\")\n",
    "    question_val = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question_val, \"topics_str\": topics_str})\n",
    "    # Normalize the datasource value.\n",
    "    datasource = source.datasource.lower().strip()\n",
    "    if datasource == \"vectorstore\":\n",
    "        print(\"--- Routing to vectorstore ---\")\n",
    "        state[\"branch\"] = \"retrieve\"\n",
    "        return \"vectorstore\"\n",
    "    elif datasource == \"web_search\":\n",
    "        print(\"--- Routing to web search ---\")\n",
    "        state[\"branch\"] = \"web_search\"\n",
    "        return \"web_search\"\n",
    "    state[\"branch\"] = \"retrieve\"\n",
    "    return \"vectorstore\"\n",
    "\n",
    "# Add an edge from the START node to the new \"generate_query\" node\n",
    "workflow.add_edge(START, \"generate_query\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"skip\": \"cache_context\", # If the flag is active, go directly to cache_context_node\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"vectorstore\": \"retrieve\",  # Key now matches the returned normalized value\n",
    "    },\n",
    ")\n",
    "\n",
    "# For the web search branch, send directly to generate.\n",
    "workflow.add_edge(\"web_search\", \"generate_web\")\n",
    "\n",
    "# For the retrieve branch, first go to grade_documents.\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# After grading, decide whether to generate or transform.\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    lambda state: decide_to_generate(state),\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_edge(\"transform_query_web\", \"web_search\")\n",
    "\n",
    "# After generate/generate_web, grade the generation.\n",
    "# If the generation is \"useful\", route to the caching node.\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate\",\n",
    "        \"useful\": \"evaluate_rag_output\",\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_rag_output\", \"evaluate_bert_score\")\n",
    "workflow.add_edge(\"evaluate_bert_score\", \"cache_context\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_web\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        # \"not supported\": \"generate_web\",\n",
    "        \"useful\": \"evaluate_web_search_output\",\n",
    "        \"not useful\": \"transform_query_web\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"evaluate_web_search_output\", \"evaluate_web_bert_score\")\n",
    "workflow.add_edge(\"evaluate_web_bert_score\", \"cache_context\")\n",
    "\n",
    "# After caching, flow to trace generation.\n",
    "workflow.add_edge(\"cache_context\", \"trace_generation\")\n",
    "workflow.add_edge(\"trace_generation\", END)  # End the workflow after trace generation\n",
    "\n",
    "# Compile the workflow graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Optionally visualize the graph (requires additional dependencies)\n",
    "try:\n",
    "    from IPython.display import display, Markdown, Image\n",
    "    # Retrieve the graph and set its configuration\n",
    "    graph = app.get_graph()\n",
    "    graph.mermaid_config = {\"graph_direction\": \"TD\"}\n",
    "\n",
    "    # Generate the PNG image bytes from the graph\n",
    "    png_bytes = graph.draw_mermaid_png()\n",
    "\n",
    "    # Save the image to disk as 'graph.png'\n",
    "    with open(\"graph.png\", \"wb\") as f:\n",
    "        f.write(png_bytes)\n",
    "    print(\"The graph has been saved as 'graph.png'.\")\n",
    "    \n",
    "    display(Markdown(\"### LangGraph Visualization ###\"))\n",
    "    display(Image(graph.draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"Graph rendering failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f643811-682a-4136-aa1a-e638d0aa2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:38] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:37.886206+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:38] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:42] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:42.238227+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:42] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:42] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:43] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:43.130839+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:43] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:46] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:46.258908+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:46] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:46] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:47] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:47.353117+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:47] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:47] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:48:48] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:48.237444+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:48] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitto\\anaconda3\\lib\\site-packages\\codecarbon\\output_methods\\file.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:48] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:48.435425+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:48] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:48] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 5.3272 seconds\n",
      "Skipping routing; moving directly to cache_context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:50] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:50.306267+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:50] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:50] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:51] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:51.382144+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:51] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:51] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:53] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:53.534736+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:53] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded refined context from file cache (LangGraph node).\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:53.958092+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:54] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:48:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:54.328580+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[Profiling] wrapper took 5.8659 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:54] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:54] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:48:55] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:55.417508+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:55] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:55] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:58] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:58.359464+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:58] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:58] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:48:59] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:59.444821+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:48:59] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:48:59] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:48:59] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:48:59.417800+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:48:59] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:02] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:02.382925+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:02] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:02] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:03] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:03.477971+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:03] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:03] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:03] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:03.728969+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:03] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:03] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:06] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:06.429065+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:06] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:06] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:07] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:07.770646+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:07] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:07] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:07] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:07.518872+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:07] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:07] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:11] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:10.472964+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:11] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:11] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:11] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:11.552885+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:11] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:11] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:11.808055+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:12] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:12.483399+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy\n",
      "Trace saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.xes\n",
      "Metadata saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.json\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:12] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:12.675715+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:12] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 18.1393 seconds\n",
      "<class 'str'>\n",
      "Profiling data for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\profiling_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\codecarbon_2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Trace generation result for 2024-02-13 16.44 00%20-%20DigitalCam%20Nominal-representations.aird.hepsy: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:14] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:14.500162+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:14] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:14] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:18] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:17.806523+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:18] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:18] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:18.528198+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:18] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:18] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:22] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:22.151309+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:22] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:22] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:22] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:22.552926+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:22] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:22] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:23] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:23.051995+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:23] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:23] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:23.250415+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:23] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:23] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 5.3221 seconds\n",
      "Skipping routing; moving directly to cache_context.\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:26] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:26.190489+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:26] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:26] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:27] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:26.593674+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:27] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:27] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:28] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:28.306442+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:28] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded refined context from file cache (LangGraph node).\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:28] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:28.522023+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:28] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:28] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 5.3486 seconds\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:30] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:30.227557+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:30] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:30] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:30] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:30.620169+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:30] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:30] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:33] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:33.706558+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:33] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:34] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:34.260227+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:34] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:34] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:34] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:34.656235+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:34] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:34] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:37.983913+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:38] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:38] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:38.291359+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:38.699954+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:38] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:42] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:42.028211+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:42] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:42.341624+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:42] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:42.741144+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:42] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:46] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:46.069966+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:46] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:46] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:46] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:46.376623+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:46] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:46] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:46] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:46.787118+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:46] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:46] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:50] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:50.110980+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:50] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:50] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:50] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:50.423979+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:50] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:50] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:49:51] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:50.817452+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:51] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:51] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:54.124172+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:54] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:54] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:54] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:54.447719+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:54] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:54] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:55] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:54.847115+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Processed: 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy\n",
      "Trace saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.xes\n",
      "Metadata saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.json\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:55] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:54.893223+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 26.2819 seconds\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:55] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:55.089703+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:55] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling data for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\profiling_2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\codecarbon_2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Trace generation result for 2024-02-13 16.59 00%20-%20DigitalCam%20Parallel-representations.aird.hepsy: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:59] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:49:58.873337+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:49:59] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:49:59] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:00] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:00.175040+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:00] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:03] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:02.911488+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:03] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:03] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:04] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:04.383029+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:04] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:04] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:07] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:06.736496+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined context file exists. Skipping query generation; proceeding directly to cache_context_node.\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:07] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:06.945029+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:07.110029+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:07] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 7.1610 seconds\n",
      "Skipping routing; moving directly to cache_context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:08] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:08.423804+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:08] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:08] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:11] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:10.973019+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:11] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:11] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:12] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:12.459145+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:12] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:12] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:13] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:12.859994+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:13] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Loaded refined context from file cache (LangGraph node).\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:13] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:13.057974+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:13] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:13] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 5.7139 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:15] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:15.013213+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:15] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:15] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:16] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:16.505599+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:16] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:16] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:18] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:18.214366+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:18] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:19] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:19.040218+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:19] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:19] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:20] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:20.546771+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:20] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:20] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:22] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:22.781003+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:22] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:22] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:23] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:23.078510+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:23] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:23] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:24] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:24.563222+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:24] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:24] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:27] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:26.811264+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:27] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:27] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:27] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:27.106096+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:27] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:27] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:29] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:28.600331+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:29] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:29] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:31] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:30.850754+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:31] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:31] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:31] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:31.143144+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:31] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:31] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:32] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:32.627836+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:32] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:32] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:35] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:34.882452+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:35] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:35] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:35] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:35.182103+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:35] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:35] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:36] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:36.666534+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:36] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:36] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:39] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:38.921878+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:39] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:39] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:39] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:39.201695+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:39] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:39] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:40] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:40.707500+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:40] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:40] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:43] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:42.959950+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:43] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:43] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:43] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:43.242485+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:43] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:43] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:43] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:43.689998+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy\n",
      "Trace saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.xes\n",
      "Metadata saved to: D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.json\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:43] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:43] ApiClient.add_emission still no run_id, aborting for this time !\n",
      "[codecarbon ERROR @ 17:50:44] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:43.895795+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:44] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:44] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Profiling] wrapper took 30.6368 seconds\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:44] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:44.078787+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:44] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:44] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling data for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\profiling_2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy.csv\n",
      "CodeCarbon metrics for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy saved to D2-HEPSYCODE/XES-MORGAN-LLM-mistral-large-latest-0.0/JSON\\codecarbon_2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy.csv\n",
      "skip_router: True\n",
      "evaluation_metrics: None\n",
      "bert_score_metrics: None\n",
      "evaluation_metrics: None\n",
      "Trace generation result for 2024-02-13 17.34 01%20-%20FIRFIRGCD-representations.aird.hepsy: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:47] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:47.275767+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:47] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:47] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:49] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:49.204181+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:49] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 17:50:51] ApiClient Error when calling the API on https://api.codecarbon.io/runs with : {\"timestamp\": \"2025-02-16T17:50:51.302097+01:00\", \"experiment_id\": \"your experiment id\", \"os\": \"Windows-10-10.0.19045-SP0\", \"python_version\": \"3.9.19\", \"codecarbon_version\": \"2.8.3\", \"cpu_count\": 16, \"cpu_model\": \"11th Gen Intel(R) Core(TM) i9-11950H @ 2.60GHz\", \"gpu_count\": 1, \"gpu_model\": \"1 x NVIDIA RTX A2000 Laptop GPU\", \"longitude\": 13.0, \"latitude\": 41.7, \"region\": null, \"provider\": null, \"ram_total_size\": 31.671497344970703, \"tracking_mode\": \"machine\"}\n",
      "[codecarbon ERROR @ 17:50:51] ApiClient API return http code 422 and answer : {\"detail\":[{\"loc\":[\"body\",\"experiment_id\"],\"msg\":\"value is not a valid uuid\",\"type\":\"type_error.uuid\"}]}\n",
      "[codecarbon ERROR @ 17:50:51] ApiClient.add_emission still no run_id, aborting for this time !\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m file_name         \u001b[38;5;66;03m# Provide file name for trace generation\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# state[\"question\"] = question           # The query generated from the metamodel\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Run the workflow using stream() and take the final output state\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m result_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Record end time for this file and calculate overall time\u001b[39;00m\n\u001b[0;32m     65\u001b[0m file_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[27], line 185\u001b[0m, in \u001b[0;36mtiming_profile_node.<locals>.wrapper\u001b[1;34m(state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    184\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 185\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    187\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n",
      "Cell \u001b[1;32mIn[27], line 208\u001b[0m, in \u001b[0;36mcc_profile_node.<locals>.wrapper\u001b[1;34m(state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Create a CodeCarbon tracker for this node\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     tracker \u001b[38;5;241m=\u001b[39m \u001b[43mEmissionsTracker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcc_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeasure_power_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCODECARBON_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can adjust output_dir as needed (\".\")\u001b[39;49;00m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_multiple_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_call_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour experiment id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     tracker\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    218\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\codecarbon\\emissions_tracker.py:336\u001b[0m, in \u001b[0;36mBaseEmissionsTracker.__init__\u001b[1;34m(self, project_name, measure_power_secs, api_call_interval, api_endpoint, api_key, output_dir, output_file, save_to_file, save_to_api, save_to_logger, logging_logger, save_to_prometheus, save_to_logfire, prometheus_url, output_handlers, gpu_ids, emissions_endpoint, experiment_id, experiment_name, co2_signal_api_token, tracking_mode, log_level, on_csv_write, logger_preamble, default_cpu_power, pue, allow_multiple_runs)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler \u001b[38;5;241m=\u001b[39m PeriodicScheduler(\n\u001b[0;32m    330\u001b[0m     function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measure_power_and_energy,\n\u001b[0;32m    331\u001b[0m     interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measure_power_secs,\n\u001b[0;32m    332\u001b[0m )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_source \u001b[38;5;241m=\u001b[39m DataSource()\n\u001b[1;32m--> 336\u001b[0m cloud: CloudMetadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cloud_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cloud\u001b[38;5;241m.\u001b[39mis_on_private_infra:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_geo_metadata()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\codecarbon\\emissions_tracker.py:874\u001b[0m, in \u001b[0;36mEmissionsTracker._get_cloud_metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_cloud_metadata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CloudMetadata:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 874\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud \u001b[38;5;241m=\u001b[39m \u001b[43mCloudMetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_utils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\codecarbon\\external\\geography.py:40\u001b[0m, in \u001b[0;36mCloudMetadata.from_utils\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(google_region_regex, zone)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m extract_region_for_provider: Dict[\u001b[38;5;28mstr\u001b[39m, Callable] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maws\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: extract_gcp_region(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     38\u001b[0m }\n\u001b[1;32m---> 40\u001b[0m cloud_metadata: Dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_env_cloud_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cloud_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m cloud_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m {}:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, region\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\codecarbon\\core\\cloud.py:57\u001b[0m, in \u001b[0;36mget_env_cloud_details\u001b[1;34m(timeout)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     params \u001b[38;5;241m=\u001b[39m CLOUD_METADATA_MAPPING[provider]\n\u001b[1;32m---> 57\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     61\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1280\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1040\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1038\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m \n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:980\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 980\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_connected_to_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#       TRACE GENERATION LOOP     #\n",
    "###################################\n",
    "\n",
    "# Global CodeCarbon tracker for the entire application\n",
    "global_cc_tracker = EmissionsTracker(\n",
    "    project_name=\"global_app\",\n",
    "    measure_power_secs=1,\n",
    "    output_dir=CODECARBON_FOLDER,\n",
    "    allow_multiple_runs=True\n",
    "    # api_call_interval=4,\n",
    "    # experiment_id=experiment_id,\n",
    "    # save_to_api=True\n",
    "    # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard\n",
    "    # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "    # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    ")\n",
    "global_cc_tracker.start()\n",
    "\n",
    "# Reset the overall summary for CodeCarbon per file\n",
    "cc_global_summary = []\n",
    "\n",
    "# List to collect summary records for each file (for final summary CSV)\n",
    "summary_records = []\n",
    "\n",
    "app_start_time = time.time()\n",
    "\n",
    "# For each file, add file name and the query to the state.\n",
    "# The cache_context node in the workflow will ensure the refined context is present.\n",
    "input_files = [file_name for file_name in os.listdir(base_model_path) if file_name.endswith(\".hepsy\")]\n",
    "\n",
    "for file_name in input_files:\n",
    "    # Record start time for this file\n",
    "    file_start = time.time()\n",
    "    \n",
    "    # Record the starting index of the global profiling_records list\n",
    "    start_index = len(profiling_records)\n",
    "\n",
    "    # Start a file-level CodeCarbon tracker\n",
    "    file_cc_tracker = EmissionsTracker(\n",
    "        project_name=\"global_file_\" + file_name,\n",
    "        measure_power_secs=1,\n",
    "        output_dir=CODECARBON_FOLDER,\n",
    "        allow_multiple_runs=True,\n",
    "        api_call_interval=4\n",
    "        # experiment_id=experiment_id,\n",
    "        # save_to_api=True\n",
    "        # log_to_api=True                     # Enable logging to the CodeCarbon online dashboard for each file\n",
    "        # api_key=codecarbon_api_key,          # Provide your CodeCarbon API key here\n",
    "        # api_url=\"https://api.codecarbon.io\"   # (Optional) Specify the API endpoint if different from the default\n",
    "    )\n",
    "    file_cc_tracker.start()\n",
    "    \n",
    "    # Reset the per-node CodeCarbon metrics for this file\n",
    "    cc_metrics_for_file = []\n",
    "    \n",
    "    state = GraphState()\n",
    "    state[\"file_name\"] = file_name         # Provide file name for trace generation\n",
    "    # state[\"question\"] = question           # The query generated from the metamodel\n",
    "    # Run the workflow using stream() and take the final output state\n",
    "    result_state = list(app.stream(state, config={\"recursion_limit\": 25}))[-1]\n",
    "    \n",
    "    # Record end time for this file and calculate overall time\n",
    "    file_end = time.time()\n",
    "    overall_time = file_end - file_start\n",
    "\n",
    "    # Stop the file-level CodeCarbon tracker and get global metrics for the file\n",
    "    file_emissions = file_cc_tracker.stop()\n",
    "    # Try to get detailed metrics if available\n",
    "    if hasattr(file_cc_tracker, \"_final_emissions_data\"):\n",
    "        file_metrics = file_cc_tracker._final_emissions_data\n",
    "    else:\n",
    "        file_metrics = {\"total_emissions\": file_emissions}\n",
    "\n",
    "    # Extract profiling records corresponding to this file\n",
    "    file_records = profiling_records[start_index:].copy()\n",
    "    # Append an additional record for the overall file execution time\n",
    "    file_records.append({\"node\": f\"FILE_{file_name}\", \"execution_time\": overall_time})\n",
    "    \n",
    "    # Save the profiling data for this file in a dedicated CSV file if it doesn't already exist\n",
    "    csv_file_path = os.path.join(PROFILING_FOLDER, f\"profiling_{file_name}.csv\")\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "            fieldnames = [\"node\", \"execution_time\"]\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for record in file_records:\n",
    "                writer.writerow(record)\n",
    "        print(f\"Profiling data for {file_name} saved to {csv_file_path}\")\n",
    "    else:\n",
    "        print(f\"Profiling file {csv_file_path} already exists. Skipping save.\")\n",
    "    \n",
    "    # Add a summary record for this file\n",
    "    summary_records.append({\"file_name\": file_name, \"execution_time\": overall_time})\n",
    "\n",
    "    ############ CODE CARBON ##############\n",
    "    # Save per-node CodeCarbon metrics along with file-level metrics into a dedicated CSV file,\n",
    "    # with file name starting with \"codecarbon_\"\n",
    "    cc_csv_file = os.path.join(CODECARBON_FOLDER, f\"codecarbon_{file_name}.csv\")\n",
    "    if not os.path.exists(cc_csv_file):\n",
    "        # Prepare a list of rows: one row per node metric, plus one row for overall file metrics.\n",
    "        # We merge the per-node metrics (from cc_metrics_for_file) into a list.\n",
    "        # Note: Each metric row is a dictionary. We also add a row for the file global metrics.\n",
    "        rows = []\n",
    "        for record in cc_metrics_for_file:\n",
    "            # record already contains \"node\" and various CodeCarbon metrics\n",
    "            rows.append(record)\n",
    "        # Append a row for overall file CodeCarbon metrics:\n",
    "        overall_record = {\"node\": f\"FILE_{file_name}\"}\n",
    "        overall_record.update(file_metrics)\n",
    "        rows.append(overall_record)\n",
    "        \n",
    "        # Determine all possible keys across all rows\n",
    "        all_keys = set()\n",
    "        for r in rows:\n",
    "            all_keys.update(r.keys())\n",
    "        all_keys = list(all_keys)\n",
    "        \n",
    "        with open(cc_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=all_keys)\n",
    "            writer.writeheader()\n",
    "            for r in rows:\n",
    "                writer.writerow(r)\n",
    "        print(f\"CodeCarbon metrics for {file_name} saved to {cc_csv_file}\")\n",
    "    else:\n",
    "        print(f\"CodeCarbon file {cc_csv_file} already exists. Skipping save.\")\n",
    "    \n",
    "    # Append summary record for this file (global CodeCarbon metrics)\n",
    "    cc_global_summary.append({\"file_name\": file_name, **file_metrics})\n",
    "\n",
    "    ############## RAG EVALUATION ################\n",
    "    \n",
    "    skip_router_value = result_state[\"trace_generation\"][\"skip_router\"]\n",
    "    print(\"skip_router:\", skip_router_value)\n",
    "\n",
    "    evaluation_metrics = result_state[\"trace_generation\"].get(\"evaluation_metrics\")\n",
    "    print(\"evaluation_metrics:\", evaluation_metrics)\n",
    "\n",
    "    bert_score_metrics = result_state[\"trace_generation\"].get(\"bert_score\")\n",
    "    print(\"bert_score_metrics:\", bert_score_metrics)\n",
    "\n",
    "    web_bert_score_metrics = result_state[\"trace_generation\"].get(\"web_bert_score\")\n",
    "    print(\"evaluation_metrics:\", web_bert_score_metrics)\n",
    "\n",
    "    if not skip_router_value:\n",
    "        # Save evaluation results to CSV for this file (if evaluation metrics exist)\n",
    "        evaluation_data = {\"file_name\": file_name}\n",
    "        \n",
    "        # Use get() with a default empty dict to ensure we update with available metrics\n",
    "        evaluation_data.update(result_state[\"trace_generation\"].get(\"evaluation_metrics\", {}))\n",
    "        evaluation_data.update(result_state[\"trace_generation\"].get(\"bert_score\", {}))\n",
    "        evaluation_data.update(result_state[\"trace_generation\"].get(\"web_bert_score\", {}))\n",
    "        \n",
    "        eval_csv_file = os.path.join(EVALUATION_FOLDER, f\"evaluation_{file_name}.csv\")\n",
    "        with open(eval_csv_file, \"w\", newline=\"\") as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=evaluation_data.keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerow(evaluation_data)\n",
    "        print(f\"Evaluation results for {file_name} saved to {eval_csv_file}\")\n",
    "    \n",
    "    print(f\"Trace generation result for {file_name}: {result_state.get('trace_status', 'unknown')}\")\n",
    "\n",
    "# Record end time of the entire application and calculate total time\n",
    "app_end_time = time.time()\n",
    "total_app_time = app_end_time - app_start_time\n",
    "summary_records.append({\"file_name\": \"TOTAL_APP\", \"execution_time\": total_app_time})\n",
    "\n",
    "global_summary = global_cc_tracker.stop()\n",
    "if hasattr(global_cc_tracker, \"_final_emissions_data\"):\n",
    "    global_metrics = global_cc_tracker._final_emissions_data\n",
    "else:\n",
    "    global_metrics = {\"total_emissions\": global_summary}\n",
    "cc_global_summary.append({\"file_name\": \"TOTAL_APP\", **global_metrics})\n",
    "print(\"END TRACE GENERATION PROCESS!!!\")\n",
    "\n",
    "# Save the final summary CSV with overall times per file if it doesn't already exist\n",
    "final_csv_file = os.path.join(PROFILING_FOLDER, \"profiling_summary.csv\")\n",
    "if not os.path.exists(final_csv_file):\n",
    "    with open(final_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        fieldnames = [\"file_name\", \"execution_time\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in summary_records:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Summary profiling data saved to {final_csv_file}\")\n",
    "else:\n",
    "    print(f\"Summary profiling CSV {final_csv_file} already exists. Skipping save.\")\n",
    "\n",
    "# Save the global CodeCarbon summary into a CSV file\n",
    "global_csv_file = os.path.join(CODECARBON_FOLDER, \"codecarbon_summary.csv\")\n",
    "if not os.path.exists(global_csv_file):\n",
    "    fieldnames = set()\n",
    "    for record in cc_global_summary:\n",
    "        fieldnames.update(record.keys())\n",
    "    fieldnames = list(fieldnames)\n",
    "    with open(global_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in cc_global_summary:\n",
    "            writer.writerow(record)\n",
    "    print(f\"Global CodeCarbon summary saved to {global_csv_file}\")\n",
    "else:\n",
    "    print(f\"Global CodeCarbon summary file {global_csv_file} already exists. Skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e31d-edf7-4c87-b023-2585e61c183b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
